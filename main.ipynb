{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 数据加载\n",
    "为了训练匹配模型，一般需要准备三个数据集：训练集 train.tsv、验证集dev.tsv、测试集test.tsv。此案例我们使用 PaddleNLP 内置的语义数据集 [LCQMC](http://icrc.hitsz.edu.cn/Article/show/171.html) 来进行训练、评估、预测。\n",
    "\n",
    "训练集: 用来训练模型参数的数据集，模型直接根据训练集来调整自身参数以获得更好的分类效果。\n",
    "\n",
    "验证集: 用于在训练过程中检验模型的状态，收敛情况。验证集通常用于调整超参数，根据几组模型验证集上的表现，决定采用哪组超参数。\n",
    "\n",
    "测试集: 用来计算模型的各项评估指标，验证模型泛化能力。\n",
    "\n",
    "[LCQMC](http://icrc.hitsz.edu.cn/Article/show/171.html) 数据集是公开的语义匹配权威数据集。PaddleNLP 已经内置该数据集，一键即可加载。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2021-11-23T16:34:07.807527Z",
     "iopub.status.busy": "2021-11-23T16:34:07.807195Z",
     "iopub.status.idle": "2021-11-23T16:34:09.660353Z",
     "shell.execute_reply": "2021-11-23T16:34:09.659517Z",
     "shell.execute_reply.started": "2021-11-23T16:34:07.807503Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: paddle-ernie in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (0.2.0.dev1)\n",
      "Requirement already satisfied: tqdm in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddle-ernie) (4.27.0)\n",
      "Requirement already satisfied: requests in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddle-ernie) (2.22.0)\n",
      "Requirement already satisfied: pathlib2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddle-ernie) (2.3.6)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->paddle-ernie) (1.25.6)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->paddle-ernie) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->paddle-ernie) (2019.9.11)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->paddle-ernie) (2.8)\n",
      "Requirement already satisfied: six in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pathlib2->paddle-ernie) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "# !pip install -U paddlepaddle -i https://mirror.baidu.com/pypi/simple\n",
    "\n",
    "# 正式开始实验之前首先通过如下命令安装最新版本的 paddlenlp\n",
    "# !pip install --upgrade paddlenlp -i https://pypi.org/simple\n",
    "\n",
    "!pip install paddle-ernie\n",
    "!rm -Rf checkpoint/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2021-11-23T16:34:09.662872Z",
     "iopub.status.busy": "2021-11-23T16:34:09.662402Z",
     "iopub.status.idle": "2021-11-23T16:34:11.946749Z",
     "shell.execute_reply": "2021-11-23T16:34:11.945958Z",
     "shell.execute_reply.started": "2021-11-23T16:34:09.662840Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from tqdm.notebook import tqdm\n",
    "\n",
    "import paddle\n",
    "import paddle.nn as nn\n",
    "import paddle.nn.functional as F\n",
    "from paddlenlp.datasets import load_dataset\n",
    "import paddlenlp\n",
    "from paddlenlp.transformers import BertForSequenceClassification, BertTokenizer\n",
    "from ernie.tokenizing_ernie import ErnieTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-23T16:34:11.948588Z",
     "iopub.status.busy": "2021-11-23T16:34:11.948051Z",
     "iopub.status.idle": "2021-11-23T16:34:20.260020Z",
     "shell.execute_reply": "2021-11-23T16:34:20.259212Z",
     "shell.execute_reply.started": "2021-11-23T16:34:11.948549Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-11-24 00:34:11,951] [    INFO] - Already cached /home/aistudio/.paddlenlp/models/ernie-gram-zh/vocab.txt\n",
      "[2021-11-24 00:34:11,965] [    INFO] - Already cached /home/aistudio/.paddlenlp/models/ernie-gram-zh/ernie_gram_zh.pdparams\n",
      "W1124 00:34:11.967811   440 device_context.cc:447] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 10.1, Runtime API Version: 10.1\n",
      "W1124 00:34:11.972581   440 device_context.cc:465] device: 0, cuDNN Version: 7.6.\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 1\n",
    "# EPOCHS = 5\n",
    "# EPOCHS = 20\n",
    "# EPOCHS = 50\n",
    "\n",
    "# BATCH_SIZE = 14\n",
    "# BATCH_SIZE = 32\n",
    "BATCH_SIZE = 40\n",
    "# BATCH_SIZE = 50\n",
    "# BATCH_SIZE = 64\n",
    "\n",
    "# LR = 5E-5\n",
    "LR = 1E-5\n",
    "\n",
    "MAX_SEQ_LENGTH = 512\n",
    "# MAX_SEQ_LENGTH = 1024\n",
    "\n",
    "# EVAL = True\n",
    "EVAL = False\n",
    "TEST_SIZE = 0.1\n",
    "\n",
    "# EVAL_STEP = 100\n",
    "# EVAL_STEP = 500\n",
    "# EVAL_STEP = 1000\n",
    "EVAL_STEP = 5000\n",
    "\n",
    "# TRAIN_CSV = 'org619885.csv'\n",
    "# TRAIN_CSV = 'bug618504.csv'\n",
    "# TRAIN_CSV = 'crop618504.csv'\n",
    "TRAIN_CSV = 'chs_619885.csv'\n",
    "\n",
    "# TEST_CSV = 'test_public.csv'\n",
    "TEST_CSV = 'chs_test_public.csv'\n",
    "\n",
    "tokenizer = paddlenlp.transformers.ErnieGramTokenizer.from_pretrained('ernie-gram-zh')\n",
    "pretrained_model = paddlenlp.transformers.ErnieGramModel.from_pretrained('ernie-gram-zh')\n",
    "# tokenizer = paddlenlp.transformers.ErnieTokenizer.from_pretrained('ernie-1.0')\n",
    "# pretrained_model = paddlenlp.transformers.ErnieModel.from_pretrained('ernie-1.0')\n",
    "# tokenizer = paddlenlp.transformers.BertTokenizer.from_pretrained('bert-base-chinese')\n",
    "# pretrained_model = paddlenlp.transformers.BertModel.from_pretrained('bert-base-chinese')\n",
    "# tokenizer = paddlenlp.transformers.AlbertTokenizer.from_pretrained('albert-chinese-base')\n",
    "# pretrained_model = paddlenlp.transformers.AlbertModel.from_pretrained('albert-chinese-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-23T16:34:20.261833Z",
     "iopub.status.busy": "2021-11-23T16:34:20.261354Z",
     "iopub.status.idle": "2021-11-23T16:35:20.568343Z",
     "shell.execute_reply": "2021-11-23T16:35:20.567702Z",
     "shell.execute_reply.started": "2021-11-23T16:34:20.261804Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "619885\n"
     ]
    }
   ],
   "source": [
    "# 一键加载 Lcqmc 的训练集、验证集\n",
    "# train_ds, dev_ds = load_dataset(\"lcqmc\", splits=[\"train\", \"dev\"])\n",
    "\n",
    "\n",
    "def read(data_path):\n",
    "    for idx, row in data_path.iterrows():\n",
    "        yield {'query': row.Test_text, 'title': row.Reference_text, 'label': row.sentiment}\n",
    "\n",
    "\n",
    "train_df = pd.read_csv(f'data/data117130/{TRAIN_CSV}')\n",
    "\n",
    "if EVAL:\n",
    "    train_df, val_df = train_test_split(train_df, test_size=TEST_SIZE, random_state=777,  shuffle=True)\n",
    "\n",
    "# data_path为read()方法的参数\n",
    "train_ds = load_dataset(read, data_path=train_df, lazy=False)\n",
    "\n",
    "if EVAL:\n",
    "    dev_ds = load_dataset(read, data_path=val_df, lazy=False)\n",
    "    print(len(train_ds), len(dev_ds))\n",
    "else:\n",
    "    print(len(train_ds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 数据预处理\n",
    "\n",
    "通过 PaddleNLP 加载进来的 [LCQMC](http://icrc.hitsz.edu.cn/Article/show/171.html) 数据集是原始的明文数据集，这部分我们来实现组 batch、tokenize 等预处理逻辑，将原始明文数据转换成网络训练的输入数据。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 定义样本转换函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2021-11-23T16:35:20.569839Z",
     "iopub.status.busy": "2021-11-23T16:35:20.569442Z",
     "iopub.status.idle": "2021-11-23T16:35:20.574415Z",
     "shell.execute_reply": "2021-11-23T16:35:20.573894Z",
     "shell.execute_reply.started": "2021-11-23T16:35:20.569811Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# 将 1 条明文数据的 query、title 拼接起来，根据预训练模型的 tokenizer 将明文转换为 ID 数据\n",
    "# 返回 input_ids 和 token_type_ids\n",
    "\n",
    "def convert_example(example, tokenizer, max_seq_length=512, is_test=False):\n",
    "\n",
    "    query, title = example[\"query\"], example[\"title\"]\n",
    "\n",
    "    encoded_inputs = tokenizer(text=query, text_pair=title, max_seq_len=max_seq_length)\n",
    "\n",
    "    input_ids = encoded_inputs[\"input_ids\"]\n",
    "    token_type_ids = encoded_inputs[\"token_type_ids\"]\n",
    "\n",
    "    if not is_test:\n",
    "        label = np.array([example[\"label\"]], dtype=\"int64\")\n",
    "        return input_ids, token_type_ids, label\n",
    "    # 在预测或者评估阶段，不返回 label 字段\n",
    "    else:\n",
    "        return input_ids, token_type_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2021-11-23T16:35:20.575509Z",
     "iopub.status.busy": "2021-11-23T16:35:20.575180Z",
     "iopub.status.idle": "2021-11-23T16:35:20.590272Z",
     "shell.execute_reply": "2021-11-23T16:35:20.589705Z",
     "shell.execute_reply.started": "2021-11-23T16:35:20.575487Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "### 对训练集的第 1 条数据进行转换\n",
    "input_ids, token_type_ids, label = convert_example(train_ds[0], tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2021-11-23T16:35:20.591293Z",
     "iopub.status.busy": "2021-11-23T16:35:20.590995Z",
     "iopub.status.idle": "2021-11-23T16:35:20.594005Z",
     "shell.execute_reply": "2021-11-23T16:35:20.593475Z",
     "shell.execute_reply.started": "2021-11-23T16:35:20.591272Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# 为了后续方便使用，我们使用python偏函数（partial）给 convert_example 赋予一些默认参数\n",
    "from functools import partial\n",
    "\n",
    "# 训练集和验证集的样本转换函数\n",
    "trans_func = partial(convert_example, tokenizer=tokenizer, max_seq_length=MAX_SEQ_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 组装 Batch 数据 & Padding\n",
    "\n",
    "上一小节，我们完成了对单条样本的转换，本节我们需要将样本组合成 Batch 数据，对于不等长的数据还需要进行 Padding 操作，便于 GPU 训练。\n",
    "\n",
    "PaddleNLP 提供了许多关于 NLP 任务中构建有效的数据 pipeline 的常用 API\n",
    "\n",
    "| API                             | 简介                                       |\n",
    "| ------------------------------- | :----------------------------------------- |\n",
    "| `paddlenlp.data.Stack`          | 堆叠N个具有相同shape的输入数据来构建一个batch |\n",
    "| `paddlenlp.data.Pad`            | 将长度不同的多个句子padding到统一长度，取N个输入数据中的最大长度 |\n",
    "| `paddlenlp.data.Tuple`          | 将多个batchify函数包装在一起 |\n",
    "\n",
    "更多数据处理操作详见： [https://paddlenlp.readthedocs.io/zh/latest/data_prepare/data_preprocess.html](https://paddlenlp.readthedocs.io/zh/latest/data_prepare/data_preprocess.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2021-11-23T16:35:20.595011Z",
     "iopub.status.busy": "2021-11-23T16:35:20.594702Z",
     "iopub.status.idle": "2021-11-23T16:35:20.600176Z",
     "shell.execute_reply": "2021-11-23T16:35:20.599704Z",
     "shell.execute_reply.started": "2021-11-23T16:35:20.594991Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from paddlenlp.data import Stack, Pad, Tuple\n",
    "a = [1, 2, 3, 4]\n",
    "b = [3, 4, 5, 6]\n",
    "c = [5, 6, 7, 8]\n",
    "result = Stack()([a, b, c])\n",
    "# print(\"Stacked Data: \\n\", result)\n",
    "# print()\n",
    "\n",
    "a = [1, 2, 3, 4]\n",
    "b = [5, 6, 7]\n",
    "c = [8, 9]\n",
    "result = Pad(pad_val=0)([a, b, c])\n",
    "# print(\"Padded Data: \\n\", result)\n",
    "# print()\n",
    "\n",
    "data = [\n",
    "        [[1, 2, 3, 4], [1]],\n",
    "        [[5, 6, 7], [0]],\n",
    "        [[8, 9], [1]],\n",
    "       ]\n",
    "batchify_fn = Tuple(Pad(pad_val=0), Stack())\n",
    "ids, labels = batchify_fn(data)\n",
    "# print(\"ids: \\n\", ids)\n",
    "# print()\n",
    "# print(\"labels: \\n\", labels)\n",
    "# print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2021-11-23T16:35:20.601177Z",
     "iopub.status.busy": "2021-11-23T16:35:20.600901Z",
     "iopub.status.idle": "2021-11-23T16:35:20.604518Z",
     "shell.execute_reply": "2021-11-23T16:35:20.603976Z",
     "shell.execute_reply.started": "2021-11-23T16:35:20.601156Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# 我们的训练数据会返回 input_ids, token_type_ids, labels 3 个字段\n",
    "# 因此针对这 3 个字段需要分别定义 3 个组 batch 操作\n",
    "batchify_fn = lambda samples, fn=Tuple(\n",
    "    Pad(axis=0, pad_val=tokenizer.pad_token_id),  # input_ids\n",
    "    Pad(axis=0, pad_val=tokenizer.pad_token_type_id),  # token_type_ids\n",
    "    Stack(dtype=\"int64\")  # label\n",
    "): [data for data in fn(samples)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 定义 Dataloader\n",
    "下面我们基于组 batchify_fn 函数和样本转换函数 trans_func 来构造训练集的 DataLoader, 支持多卡训练\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2021-11-23T16:35:20.605585Z",
     "iopub.status.busy": "2021-11-23T16:35:20.605214Z",
     "iopub.status.idle": "2021-11-23T16:35:20.609758Z",
     "shell.execute_reply": "2021-11-23T16:35:20.609211Z",
     "shell.execute_reply.started": "2021-11-23T16:35:20.605563Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# 定义分布式 Sampler: 自动对训练数据进行切分，支持多卡并行训练\n",
    "batch_sampler = paddle.io.DistributedBatchSampler(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# 基于 train_ds 定义 train_data_loader\n",
    "# 因为我们使用了分布式的 DistributedBatchSampler, train_data_loader 会自动对训练数据进行切分\n",
    "train_data_loader = paddle.io.DataLoader(\n",
    "        dataset=train_ds.map(trans_func),\n",
    "        batch_sampler=batch_sampler,\n",
    "        collate_fn=batchify_fn,\n",
    "        return_list=True)\n",
    "\n",
    "\n",
    "# 针对验证集数据加载，我们使用单卡进行评估，所以采用 paddle.io.BatchSampler 即可\n",
    "# 定义 dev_data_loader\n",
    "if EVAL:\n",
    "        batch_sampler = paddle.io.BatchSampler(dev_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
    "        dev_data_loader = paddle.io.DataLoader(\n",
    "                dataset=dev_ds.map(trans_func),\n",
    "                batch_sampler=batch_sampler,\n",
    "                collate_fn=batchify_fn,\n",
    "                return_list=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 模型搭建\n",
    "\n",
    "自从 2018 年 10 月以来，NLP 个领域的任务都通过 Pretrain + Finetune 的模式相比传统 DNN 方法在效果上取得了显著的提升，本节我们以百度开源的预训练模型 ERNIE-Gram 为基础模型，在此之上构建 Point-wise 语义匹配网络。\n",
    "\n",
    "首先我们来定义网络结构:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2021-11-23T16:35:20.611976Z",
     "iopub.status.busy": "2021-11-23T16:35:20.611603Z",
     "iopub.status.idle": "2021-11-23T16:35:20.618180Z",
     "shell.execute_reply": "2021-11-23T16:35:20.617717Z",
     "shell.execute_reply.started": "2021-11-23T16:35:20.611955Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class PointwiseMatching(nn.Layer):\n",
    "    # 此处的 pretained_model 在本例中会被 ERNIE-Gram 预训练模型初始化\n",
    "    def __init__(self, pretrained_model, dropout=None):\n",
    "        super().__init__()\n",
    "        self.ptm = pretrained_model\n",
    "        self.dropout = nn.Dropout(dropout if dropout is not None else 0.1)\n",
    "\n",
    "        # 语义匹配任务: 相似、不相似 2 分类任务\n",
    "        self.classifier = nn.Linear(self.ptm.config[\"hidden_size\"], 2)\n",
    "\n",
    "    def forward(self,\n",
    "                input_ids,\n",
    "                token_type_ids=None,\n",
    "                position_ids=None,\n",
    "                attention_mask=None):\n",
    "\n",
    "        # 此处的 Input_ids 由两条文本的 token ids 拼接而成\n",
    "        # token_type_ids 表示两段文本的类型编码\n",
    "        # 返回的 cls_embedding 就表示这两段文本经过模型的计算之后而得到的语义表示向量\n",
    "        _, cls_embedding = self.ptm(input_ids, token_type_ids, position_ids, attention_mask)\n",
    "        cls_embedding = self.dropout(cls_embedding)\n",
    "\n",
    "        # 基于文本对的语义表示向量进行 2 分类任务\n",
    "        logits = self.classifier(cls_embedding)\n",
    "        probs = F.softmax(logits)\n",
    "\n",
    "        return probs\n",
    "\n",
    "# 定义 Point-wise 语义匹配网络\n",
    "model = PointwiseMatching(pretrained_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 模型训练 & 评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2021-11-23T16:35:20.619241Z",
     "iopub.status.busy": "2021-11-23T16:35:20.618870Z",
     "iopub.status.idle": "2021-11-23T16:35:20.625475Z",
     "shell.execute_reply": "2021-11-23T16:35:20.624979Z",
     "shell.execute_reply.started": "2021-11-23T16:35:20.619219Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from paddlenlp.transformers import LinearDecayWithWarmup\n",
    "\n",
    "num_training_steps = len(train_data_loader) * EPOCHS\n",
    "\n",
    "# 定义 learning_rate_scheduler，负责在训练过程中对 lr 进行调度\n",
    "lr_scheduler = LinearDecayWithWarmup(LR, num_training_steps, 0.0)\n",
    "\n",
    "# Generate parameter names needed to perform weight decay.\n",
    "# All bias and LayerNorm parameters are excluded.\n",
    "decay_params = [\n",
    "    p.name for n, p in model.named_parameters()\n",
    "    if not any(nd in n for nd in [\"bias\", \"norm\"])\n",
    "]\n",
    "\n",
    "# 定义 Optimizer\n",
    "optimizer = paddle.optimizer.AdamW(\n",
    "    learning_rate=lr_scheduler,\n",
    "    parameters=model.parameters(),\n",
    "    weight_decay=0.0,\n",
    "    apply_decay_param_fun=lambda x: x in decay_params)\n",
    "\n",
    "# 采用交叉熵 损失函数\n",
    "criterion = paddle.nn.loss.CrossEntropyLoss()\n",
    "\n",
    "# 评估的时候采用准确率指标\n",
    "metric = paddle.metric.Accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2021-11-23T16:35:20.626619Z",
     "iopub.status.busy": "2021-11-23T16:35:20.626273Z",
     "iopub.status.idle": "2021-11-23T16:35:20.631548Z",
     "shell.execute_reply": "2021-11-23T16:35:20.630979Z",
     "shell.execute_reply.started": "2021-11-23T16:35:20.626598Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# 因为训练过程中同时要在验证集进行模型评估，因此我们先定义评估函数\n",
    "\n",
    "@paddle.no_grad()\n",
    "def evaluate(model, criterion, metric, data_loader, phase=\"dev\"):\n",
    "    model.eval()\n",
    "    metric.reset()\n",
    "    losses = []\n",
    "    for batch in data_loader:\n",
    "        input_ids, token_type_ids, labels = batch\n",
    "        probs = model(input_ids=input_ids, token_type_ids=token_type_ids)\n",
    "        loss = criterion(probs, labels)\n",
    "        losses.append(loss.numpy())\n",
    "        correct = metric.compute(probs, labels)\n",
    "        metric.update(correct)\n",
    "        accu = metric.accumulate()\n",
    "    print(\"eval {} loss: {:.5}, accu: {:.5}\".format(phase, np.mean(losses), accu))\n",
    "    model.train()\n",
    "    metric.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2021-11-23T16:35:20.632480Z",
     "iopub.status.busy": "2021-11-23T16:35:20.632234Z",
     "iopub.status.idle": "2021-11-23T21:34:41.007780Z",
     "shell.execute_reply": "2021-11-23T21:34:41.007101Z",
     "shell.execute_reply.started": "2021-11-23T16:35:20.632460Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 10, epoch: 1, batch: 10, loss: 0.67182, accu: 0.52250, speed: 0.81 step/s\n",
      "global step 20, epoch: 1, batch: 20, loss: 0.69528, accu: 0.55000, speed: 0.89 step/s\n",
      "global step 30, epoch: 1, batch: 30, loss: 0.57852, accu: 0.60000, speed: 0.89 step/s\n",
      "global step 40, epoch: 1, batch: 40, loss: 0.49860, accu: 0.64625, speed: 0.88 step/s\n",
      "global step 50, epoch: 1, batch: 50, loss: 0.46105, accu: 0.68050, speed: 0.88 step/s\n",
      "global step 60, epoch: 1, batch: 60, loss: 0.47143, accu: 0.71167, speed: 0.88 step/s\n",
      "global step 70, epoch: 1, batch: 70, loss: 0.39744, accu: 0.73857, speed: 0.88 step/s\n",
      "global step 80, epoch: 1, batch: 80, loss: 0.38737, accu: 0.75750, speed: 0.87 step/s\n",
      "global step 90, epoch: 1, batch: 90, loss: 0.36538, accu: 0.77389, speed: 0.87 step/s\n",
      "global step 100, epoch: 1, batch: 100, loss: 0.46263, accu: 0.78850, speed: 0.87 step/s\n",
      "global step 110, epoch: 1, batch: 110, loss: 0.37279, accu: 0.80114, speed: 0.87 step/s\n",
      "global step 120, epoch: 1, batch: 120, loss: 0.41953, accu: 0.81021, speed: 0.87 step/s\n",
      "global step 130, epoch: 1, batch: 130, loss: 0.37562, accu: 0.82000, speed: 0.87 step/s\n",
      "global step 140, epoch: 1, batch: 140, loss: 0.42871, accu: 0.82786, speed: 0.87 step/s\n",
      "global step 150, epoch: 1, batch: 150, loss: 0.38564, accu: 0.83617, speed: 0.87 step/s\n",
      "global step 160, epoch: 1, batch: 160, loss: 0.39458, accu: 0.84375, speed: 0.87 step/s\n",
      "global step 170, epoch: 1, batch: 170, loss: 0.34546, accu: 0.84971, speed: 0.87 step/s\n",
      "global step 180, epoch: 1, batch: 180, loss: 0.41601, accu: 0.85431, speed: 0.87 step/s\n",
      "global step 190, epoch: 1, batch: 190, loss: 0.38874, accu: 0.85974, speed: 0.87 step/s\n",
      "global step 200, epoch: 1, batch: 200, loss: 0.34007, accu: 0.86387, speed: 0.87 step/s\n",
      "global step 210, epoch: 1, batch: 210, loss: 0.34387, accu: 0.86869, speed: 0.87 step/s\n",
      "global step 220, epoch: 1, batch: 220, loss: 0.36335, accu: 0.87239, speed: 0.87 step/s\n",
      "global step 230, epoch: 1, batch: 230, loss: 0.31426, accu: 0.87565, speed: 0.87 step/s\n",
      "global step 240, epoch: 1, batch: 240, loss: 0.35283, accu: 0.87885, speed: 0.87 step/s\n",
      "global step 250, epoch: 1, batch: 250, loss: 0.31409, accu: 0.88220, speed: 0.87 step/s\n",
      "global step 260, epoch: 1, batch: 260, loss: 0.36582, accu: 0.88404, speed: 0.87 step/s\n",
      "global step 270, epoch: 1, batch: 270, loss: 0.40180, accu: 0.88602, speed: 0.87 step/s\n",
      "global step 280, epoch: 1, batch: 280, loss: 0.35151, accu: 0.88848, speed: 0.87 step/s\n",
      "global step 290, epoch: 1, batch: 290, loss: 0.32561, accu: 0.89060, speed: 0.87 step/s\n",
      "global step 300, epoch: 1, batch: 300, loss: 0.32187, accu: 0.89250, speed: 0.87 step/s\n",
      "global step 310, epoch: 1, batch: 310, loss: 0.33886, accu: 0.89419, speed: 0.86 step/s\n",
      "global step 320, epoch: 1, batch: 320, loss: 0.31480, accu: 0.89617, speed: 0.87 step/s\n",
      "global step 330, epoch: 1, batch: 330, loss: 0.31967, accu: 0.89803, speed: 0.87 step/s\n",
      "global step 340, epoch: 1, batch: 340, loss: 0.31618, accu: 0.90007, speed: 0.86 step/s\n",
      "global step 350, epoch: 1, batch: 350, loss: 0.38266, accu: 0.90107, speed: 0.86 step/s\n",
      "global step 360, epoch: 1, batch: 360, loss: 0.38089, accu: 0.90264, speed: 0.87 step/s\n",
      "global step 370, epoch: 1, batch: 370, loss: 0.31446, accu: 0.90399, speed: 0.86 step/s\n",
      "global step 380, epoch: 1, batch: 380, loss: 0.42518, accu: 0.90500, speed: 0.86 step/s\n",
      "global step 390, epoch: 1, batch: 390, loss: 0.34314, accu: 0.90641, speed: 0.87 step/s\n",
      "global step 400, epoch: 1, batch: 400, loss: 0.36017, accu: 0.90787, speed: 0.86 step/s\n",
      "global step 410, epoch: 1, batch: 410, loss: 0.36306, accu: 0.90902, speed: 0.86 step/s\n",
      "global step 420, epoch: 1, batch: 420, loss: 0.43148, accu: 0.91024, speed: 0.86 step/s\n",
      "global step 430, epoch: 1, batch: 430, loss: 0.35060, accu: 0.91151, speed: 0.86 step/s\n",
      "global step 440, epoch: 1, batch: 440, loss: 0.31402, accu: 0.91261, speed: 0.86 step/s\n",
      "global step 450, epoch: 1, batch: 450, loss: 0.31753, accu: 0.91372, speed: 0.87 step/s\n",
      "global step 460, epoch: 1, batch: 460, loss: 0.35838, accu: 0.91457, speed: 0.86 step/s\n",
      "global step 470, epoch: 1, batch: 470, loss: 0.34871, accu: 0.91574, speed: 0.86 step/s\n",
      "global step 480, epoch: 1, batch: 480, loss: 0.31376, accu: 0.91693, speed: 0.86 step/s\n",
      "global step 490, epoch: 1, batch: 490, loss: 0.38805, accu: 0.91786, speed: 0.86 step/s\n",
      "global step 500, epoch: 1, batch: 500, loss: 0.38863, accu: 0.91870, speed: 0.86 step/s\n",
      "global step 510, epoch: 1, batch: 510, loss: 0.34928, accu: 0.91936, speed: 0.86 step/s\n",
      "global step 520, epoch: 1, batch: 520, loss: 0.34703, accu: 0.92034, speed: 0.86 step/s\n",
      "global step 530, epoch: 1, batch: 530, loss: 0.36375, accu: 0.92104, speed: 0.86 step/s\n",
      "global step 540, epoch: 1, batch: 540, loss: 0.34616, accu: 0.92162, speed: 0.86 step/s\n",
      "global step 550, epoch: 1, batch: 550, loss: 0.34725, accu: 0.92227, speed: 0.86 step/s\n",
      "global step 560, epoch: 1, batch: 560, loss: 0.36359, accu: 0.92295, speed: 0.86 step/s\n",
      "global step 570, epoch: 1, batch: 570, loss: 0.33856, accu: 0.92368, speed: 0.86 step/s\n",
      "global step 580, epoch: 1, batch: 580, loss: 0.33960, accu: 0.92448, speed: 0.86 step/s\n",
      "global step 590, epoch: 1, batch: 590, loss: 0.48210, accu: 0.92492, speed: 0.86 step/s\n",
      "global step 600, epoch: 1, batch: 600, loss: 0.33870, accu: 0.92479, speed: 0.86 step/s\n",
      "global step 610, epoch: 1, batch: 610, loss: 0.31510, accu: 0.92500, speed: 0.86 step/s\n",
      "global step 620, epoch: 1, batch: 620, loss: 0.36476, accu: 0.92536, speed: 0.86 step/s\n",
      "global step 630, epoch: 1, batch: 630, loss: 0.31806, accu: 0.92583, speed: 0.86 step/s\n",
      "global step 640, epoch: 1, batch: 640, loss: 0.35971, accu: 0.92633, speed: 0.86 step/s\n",
      "global step 650, epoch: 1, batch: 650, loss: 0.32044, accu: 0.92692, speed: 0.86 step/s\n",
      "global step 660, epoch: 1, batch: 660, loss: 0.38812, accu: 0.92742, speed: 0.86 step/s\n",
      "global step 670, epoch: 1, batch: 670, loss: 0.33818, accu: 0.92802, speed: 0.86 step/s\n",
      "global step 680, epoch: 1, batch: 680, loss: 0.34193, accu: 0.92871, speed: 0.86 step/s\n",
      "global step 690, epoch: 1, batch: 690, loss: 0.34928, accu: 0.92935, speed: 0.86 step/s\n",
      "global step 700, epoch: 1, batch: 700, loss: 0.31344, accu: 0.92982, speed: 0.86 step/s\n",
      "global step 710, epoch: 1, batch: 710, loss: 0.34578, accu: 0.93049, speed: 0.86 step/s\n",
      "global step 720, epoch: 1, batch: 720, loss: 0.32965, accu: 0.93090, speed: 0.86 step/s\n",
      "global step 730, epoch: 1, batch: 730, loss: 0.36732, accu: 0.93144, speed: 0.86 step/s\n",
      "global step 740, epoch: 1, batch: 740, loss: 0.31405, accu: 0.93193, speed: 0.86 step/s\n",
      "global step 750, epoch: 1, batch: 750, loss: 0.35254, accu: 0.93237, speed: 0.86 step/s\n",
      "global step 760, epoch: 1, batch: 760, loss: 0.31695, accu: 0.93280, speed: 0.86 step/s\n",
      "global step 770, epoch: 1, batch: 770, loss: 0.35363, accu: 0.93328, speed: 0.86 step/s\n",
      "global step 780, epoch: 1, batch: 780, loss: 0.31374, accu: 0.93353, speed: 0.86 step/s\n",
      "global step 790, epoch: 1, batch: 790, loss: 0.31580, accu: 0.93380, speed: 0.86 step/s\n",
      "global step 800, epoch: 1, batch: 800, loss: 0.33956, accu: 0.93431, speed: 0.86 step/s\n",
      "global step 810, epoch: 1, batch: 810, loss: 0.36490, accu: 0.93463, speed: 0.86 step/s\n",
      "global step 820, epoch: 1, batch: 820, loss: 0.33705, accu: 0.93491, speed: 0.86 step/s\n",
      "global step 830, epoch: 1, batch: 830, loss: 0.35765, accu: 0.93518, speed: 0.86 step/s\n",
      "global step 840, epoch: 1, batch: 840, loss: 0.31361, accu: 0.93548, speed: 0.86 step/s\n",
      "global step 850, epoch: 1, batch: 850, loss: 0.36120, accu: 0.93571, speed: 0.86 step/s\n",
      "global step 860, epoch: 1, batch: 860, loss: 0.31335, accu: 0.93619, speed: 0.86 step/s\n",
      "global step 870, epoch: 1, batch: 870, loss: 0.39461, accu: 0.93638, speed: 0.86 step/s\n",
      "global step 880, epoch: 1, batch: 880, loss: 0.31382, accu: 0.93676, speed: 0.86 step/s\n",
      "global step 890, epoch: 1, batch: 890, loss: 0.31413, accu: 0.93722, speed: 0.86 step/s\n",
      "global step 900, epoch: 1, batch: 900, loss: 0.36330, accu: 0.93772, speed: 0.86 step/s\n",
      "global step 910, epoch: 1, batch: 910, loss: 0.32522, accu: 0.93816, speed: 0.86 step/s\n",
      "global step 920, epoch: 1, batch: 920, loss: 0.36340, accu: 0.93856, speed: 0.86 step/s\n",
      "global step 930, epoch: 1, batch: 930, loss: 0.31337, accu: 0.93892, speed: 0.86 step/s\n",
      "global step 940, epoch: 1, batch: 940, loss: 0.36442, accu: 0.93931, speed: 0.86 step/s\n",
      "global step 950, epoch: 1, batch: 950, loss: 0.37980, accu: 0.93953, speed: 0.86 step/s\n",
      "global step 960, epoch: 1, batch: 960, loss: 0.33917, accu: 0.93977, speed: 0.86 step/s\n",
      "global step 970, epoch: 1, batch: 970, loss: 0.36338, accu: 0.93992, speed: 0.86 step/s\n",
      "global step 980, epoch: 1, batch: 980, loss: 0.34592, accu: 0.94023, speed: 0.86 step/s\n",
      "global step 990, epoch: 1, batch: 990, loss: 0.34407, accu: 0.94043, speed: 0.86 step/s\n",
      "global step 1000, epoch: 1, batch: 1000, loss: 0.31339, accu: 0.94063, speed: 0.86 step/s\n",
      "global step 1010, epoch: 1, batch: 1010, loss: 0.31350, accu: 0.94094, speed: 0.86 step/s\n",
      "global step 1020, epoch: 1, batch: 1020, loss: 0.32887, accu: 0.94118, speed: 0.86 step/s\n",
      "global step 1030, epoch: 1, batch: 1030, loss: 0.36330, accu: 0.94141, speed: 0.86 step/s\n",
      "global step 1040, epoch: 1, batch: 1040, loss: 0.33843, accu: 0.94166, speed: 0.86 step/s\n",
      "global step 1050, epoch: 1, batch: 1050, loss: 0.36053, accu: 0.94186, speed: 0.86 step/s\n",
      "global step 1060, epoch: 1, batch: 1060, loss: 0.31374, accu: 0.94212, speed: 0.86 step/s\n",
      "global step 1070, epoch: 1, batch: 1070, loss: 0.38902, accu: 0.94234, speed: 0.86 step/s\n",
      "global step 1080, epoch: 1, batch: 1080, loss: 0.33530, accu: 0.94250, speed: 0.86 step/s\n",
      "global step 1090, epoch: 1, batch: 1090, loss: 0.33845, accu: 0.94287, speed: 0.86 step/s\n",
      "global step 1100, epoch: 1, batch: 1100, loss: 0.31330, accu: 0.94318, speed: 0.86 step/s\n",
      "global step 1110, epoch: 1, batch: 1110, loss: 0.33986, accu: 0.94345, speed: 0.86 step/s\n",
      "global step 1120, epoch: 1, batch: 1120, loss: 0.31926, accu: 0.94366, speed: 0.86 step/s\n",
      "global step 1130, epoch: 1, batch: 1130, loss: 0.31434, accu: 0.94381, speed: 0.86 step/s\n",
      "global step 1140, epoch: 1, batch: 1140, loss: 0.36330, accu: 0.94408, speed: 0.86 step/s\n",
      "global step 1150, epoch: 1, batch: 1150, loss: 0.31605, accu: 0.94443, speed: 0.86 step/s\n",
      "global step 1160, epoch: 1, batch: 1160, loss: 0.33901, accu: 0.94470, speed: 0.86 step/s\n",
      "global step 1170, epoch: 1, batch: 1170, loss: 0.38845, accu: 0.94485, speed: 0.86 step/s\n",
      "global step 1180, epoch: 1, batch: 1180, loss: 0.36576, accu: 0.94508, speed: 0.86 step/s\n",
      "global step 1190, epoch: 1, batch: 1190, loss: 0.31467, accu: 0.94525, speed: 0.86 step/s\n",
      "global step 1200, epoch: 1, batch: 1200, loss: 0.33831, accu: 0.94556, speed: 0.86 step/s\n",
      "global step 1210, epoch: 1, batch: 1210, loss: 0.36624, accu: 0.94564, speed: 0.86 step/s\n",
      "global step 1220, epoch: 1, batch: 1220, loss: 0.31412, accu: 0.94590, speed: 0.86 step/s\n",
      "global step 1230, epoch: 1, batch: 1230, loss: 0.33551, accu: 0.94614, speed: 0.86 step/s\n",
      "global step 1240, epoch: 1, batch: 1240, loss: 0.34151, accu: 0.94639, speed: 0.86 step/s\n",
      "global step 1250, epoch: 1, batch: 1250, loss: 0.33883, accu: 0.94664, speed: 0.86 step/s\n",
      "global step 1260, epoch: 1, batch: 1260, loss: 0.31394, accu: 0.94688, speed: 0.86 step/s\n",
      "global step 1270, epoch: 1, batch: 1270, loss: 0.33861, accu: 0.94707, speed: 0.86 step/s\n",
      "global step 1280, epoch: 1, batch: 1280, loss: 0.31332, accu: 0.94717, speed: 0.86 step/s\n",
      "global step 1290, epoch: 1, batch: 1290, loss: 0.38639, accu: 0.94723, speed: 0.86 step/s\n",
      "global step 1300, epoch: 1, batch: 1300, loss: 0.31335, accu: 0.94740, speed: 0.86 step/s\n",
      "global step 1310, epoch: 1, batch: 1310, loss: 0.36323, accu: 0.94748, speed: 0.86 step/s\n",
      "global step 1320, epoch: 1, batch: 1320, loss: 0.37863, accu: 0.94763, speed: 0.86 step/s\n",
      "global step 1330, epoch: 1, batch: 1330, loss: 0.31340, accu: 0.94795, speed: 0.86 step/s\n",
      "global step 1340, epoch: 1, batch: 1340, loss: 0.31349, accu: 0.94819, speed: 0.86 step/s\n",
      "global step 1350, epoch: 1, batch: 1350, loss: 0.34683, accu: 0.94839, speed: 0.86 step/s\n",
      "global step 1360, epoch: 1, batch: 1360, loss: 0.33844, accu: 0.94862, speed: 0.86 step/s\n",
      "global step 1370, epoch: 1, batch: 1370, loss: 0.31344, accu: 0.94876, speed: 0.86 step/s\n",
      "global step 1380, epoch: 1, batch: 1380, loss: 0.38829, accu: 0.94897, speed: 0.86 step/s\n",
      "global step 1390, epoch: 1, batch: 1390, loss: 0.37279, accu: 0.94912, speed: 0.86 step/s\n",
      "global step 1400, epoch: 1, batch: 1400, loss: 0.31339, accu: 0.94929, speed: 0.86 step/s\n",
      "global step 1410, epoch: 1, batch: 1410, loss: 0.31351, accu: 0.94943, speed: 0.86 step/s\n",
      "global step 1420, epoch: 1, batch: 1420, loss: 0.37186, accu: 0.94952, speed: 0.86 step/s\n",
      "global step 1430, epoch: 1, batch: 1430, loss: 0.36273, accu: 0.94967, speed: 0.86 step/s\n",
      "global step 1440, epoch: 1, batch: 1440, loss: 0.40961, accu: 0.94974, speed: 0.86 step/s\n",
      "global step 1450, epoch: 1, batch: 1450, loss: 0.38828, accu: 0.94986, speed: 0.86 step/s\n",
      "global step 1460, epoch: 1, batch: 1460, loss: 0.38795, accu: 0.94991, speed: 0.86 step/s\n",
      "global step 1470, epoch: 1, batch: 1470, loss: 0.36337, accu: 0.95007, speed: 0.86 step/s\n",
      "global step 1480, epoch: 1, batch: 1480, loss: 0.31546, accu: 0.95032, speed: 0.86 step/s\n",
      "global step 1490, epoch: 1, batch: 1490, loss: 0.36330, accu: 0.95045, speed: 0.86 step/s\n",
      "global step 1500, epoch: 1, batch: 1500, loss: 0.33833, accu: 0.95062, speed: 0.86 step/s\n",
      "global step 1510, epoch: 1, batch: 1510, loss: 0.33598, accu: 0.95076, speed: 0.86 step/s\n",
      "global step 1520, epoch: 1, batch: 1520, loss: 0.37027, accu: 0.95099, speed: 0.86 step/s\n",
      "global step 1530, epoch: 1, batch: 1530, loss: 0.31334, accu: 0.95123, speed: 0.86 step/s\n",
      "global step 1540, epoch: 1, batch: 1540, loss: 0.34004, accu: 0.95136, speed: 0.86 step/s\n",
      "global step 1550, epoch: 1, batch: 1550, loss: 0.33236, accu: 0.95153, speed: 0.86 step/s\n",
      "global step 1560, epoch: 1, batch: 1560, loss: 0.33845, accu: 0.95170, speed: 0.86 step/s\n",
      "global step 1570, epoch: 1, batch: 1570, loss: 0.33848, accu: 0.95180, speed: 0.86 step/s\n",
      "global step 1580, epoch: 1, batch: 1580, loss: 0.36350, accu: 0.95187, speed: 0.86 step/s\n",
      "global step 1590, epoch: 1, batch: 1590, loss: 0.31334, accu: 0.95209, speed: 0.86 step/s\n",
      "global step 1600, epoch: 1, batch: 1600, loss: 0.36331, accu: 0.95206, speed: 0.86 step/s\n",
      "global step 1610, epoch: 1, batch: 1610, loss: 0.31329, accu: 0.95213, speed: 0.86 step/s\n",
      "global step 1620, epoch: 1, batch: 1620, loss: 0.33831, accu: 0.95230, speed: 0.86 step/s\n",
      "global step 1630, epoch: 1, batch: 1630, loss: 0.33026, accu: 0.95247, speed: 0.86 step/s\n",
      "global step 1640, epoch: 1, batch: 1640, loss: 0.36330, accu: 0.95264, speed: 0.86 step/s\n",
      "global step 1650, epoch: 1, batch: 1650, loss: 0.33831, accu: 0.95277, speed: 0.86 step/s\n",
      "global step 1660, epoch: 1, batch: 1660, loss: 0.31391, accu: 0.95288, speed: 0.86 step/s\n",
      "global step 1670, epoch: 1, batch: 1670, loss: 0.31375, accu: 0.95289, speed: 0.86 step/s\n",
      "global step 1680, epoch: 1, batch: 1680, loss: 0.31380, accu: 0.95299, speed: 0.86 step/s\n",
      "global step 1690, epoch: 1, batch: 1690, loss: 0.31337, accu: 0.95311, speed: 0.86 step/s\n",
      "global step 1700, epoch: 1, batch: 1700, loss: 0.33835, accu: 0.95316, speed: 0.86 step/s\n",
      "global step 1710, epoch: 1, batch: 1710, loss: 0.32136, accu: 0.95326, speed: 0.86 step/s\n",
      "global step 1720, epoch: 1, batch: 1720, loss: 0.33842, accu: 0.95333, speed: 0.86 step/s\n",
      "global step 1730, epoch: 1, batch: 1730, loss: 0.31335, accu: 0.95350, speed: 0.86 step/s\n",
      "global step 1740, epoch: 1, batch: 1740, loss: 0.36338, accu: 0.95355, speed: 0.86 step/s\n",
      "global step 1750, epoch: 1, batch: 1750, loss: 0.32750, accu: 0.95363, speed: 0.86 step/s\n",
      "global step 1760, epoch: 1, batch: 1760, loss: 0.35688, accu: 0.95381, speed: 0.86 step/s\n",
      "global step 1770, epoch: 1, batch: 1770, loss: 0.33805, accu: 0.95387, speed: 0.86 step/s\n",
      "global step 1780, epoch: 1, batch: 1780, loss: 0.33829, accu: 0.95396, speed: 0.86 step/s\n",
      "global step 1790, epoch: 1, batch: 1790, loss: 0.36328, accu: 0.95404, speed: 0.86 step/s\n",
      "global step 1800, epoch: 1, batch: 1800, loss: 0.34045, accu: 0.95419, speed: 0.86 step/s\n",
      "global step 1810, epoch: 1, batch: 1810, loss: 0.36325, accu: 0.95428, speed: 0.86 step/s\n",
      "global step 1820, epoch: 1, batch: 1820, loss: 0.33829, accu: 0.95440, speed: 0.86 step/s\n",
      "global step 1830, epoch: 1, batch: 1830, loss: 0.34483, accu: 0.95447, speed: 0.86 step/s\n",
      "global step 1840, epoch: 1, batch: 1840, loss: 0.36327, accu: 0.95454, speed: 0.86 step/s\n",
      "global step 1850, epoch: 1, batch: 1850, loss: 0.36578, accu: 0.95459, speed: 0.86 step/s\n",
      "global step 1860, epoch: 1, batch: 1860, loss: 0.33832, accu: 0.95464, speed: 0.86 step/s\n",
      "global step 1870, epoch: 1, batch: 1870, loss: 0.33838, accu: 0.95477, speed: 0.86 step/s\n",
      "global step 1880, epoch: 1, batch: 1880, loss: 0.31360, accu: 0.95485, speed: 0.86 step/s\n",
      "global step 1890, epoch: 1, batch: 1890, loss: 0.32061, accu: 0.95499, speed: 0.86 step/s\n",
      "global step 1900, epoch: 1, batch: 1900, loss: 0.33245, accu: 0.95508, speed: 0.86 step/s\n",
      "global step 1910, epoch: 1, batch: 1910, loss: 0.33849, accu: 0.95522, speed: 0.86 step/s\n",
      "global step 1920, epoch: 1, batch: 1920, loss: 0.33827, accu: 0.95529, speed: 0.86 step/s\n",
      "global step 1930, epoch: 1, batch: 1930, loss: 0.31330, accu: 0.95543, speed: 0.86 step/s\n",
      "global step 1940, epoch: 1, batch: 1940, loss: 0.33828, accu: 0.95555, speed: 0.86 step/s\n",
      "global step 1950, epoch: 1, batch: 1950, loss: 0.33829, accu: 0.95567, speed: 0.86 step/s\n",
      "global step 1960, epoch: 1, batch: 1960, loss: 0.31328, accu: 0.95582, speed: 0.86 step/s\n",
      "global step 1970, epoch: 1, batch: 1970, loss: 0.31331, accu: 0.95593, speed: 0.86 step/s\n",
      "global step 1980, epoch: 1, batch: 1980, loss: 0.38819, accu: 0.95598, speed: 0.86 step/s\n",
      "global step 1990, epoch: 1, batch: 1990, loss: 0.31432, accu: 0.95613, speed: 0.86 step/s\n",
      "global step 2000, epoch: 1, batch: 2000, loss: 0.33856, accu: 0.95620, speed: 0.86 step/s\n",
      "global step 2010, epoch: 1, batch: 2010, loss: 0.32293, accu: 0.95631, speed: 0.86 step/s\n",
      "global step 2020, epoch: 1, batch: 2020, loss: 0.33828, accu: 0.95641, speed: 0.86 step/s\n",
      "global step 2030, epoch: 1, batch: 2030, loss: 0.31669, accu: 0.95639, speed: 0.86 step/s\n",
      "global step 2040, epoch: 1, batch: 2040, loss: 0.31453, accu: 0.95651, speed: 0.86 step/s\n",
      "global step 2050, epoch: 1, batch: 2050, loss: 0.36355, accu: 0.95660, speed: 0.86 step/s\n",
      "global step 2060, epoch: 1, batch: 2060, loss: 0.36101, accu: 0.95671, speed: 0.86 step/s\n",
      "global step 2070, epoch: 1, batch: 2070, loss: 0.36224, accu: 0.95679, speed: 0.86 step/s\n",
      "global step 2080, epoch: 1, batch: 2080, loss: 0.33828, accu: 0.95681, speed: 0.86 step/s\n",
      "global step 2090, epoch: 1, batch: 2090, loss: 0.34031, accu: 0.95688, speed: 0.86 step/s\n",
      "global step 2100, epoch: 1, batch: 2100, loss: 0.33894, accu: 0.95699, speed: 0.86 step/s\n",
      "global step 2110, epoch: 1, batch: 2110, loss: 0.38258, accu: 0.95697, speed: 0.86 step/s\n",
      "global step 2120, epoch: 1, batch: 2120, loss: 0.38718, accu: 0.95693, speed: 0.86 step/s\n",
      "global step 2130, epoch: 1, batch: 2130, loss: 0.31331, accu: 0.95696, speed: 0.86 step/s\n",
      "global step 2140, epoch: 1, batch: 2140, loss: 0.38460, accu: 0.95703, speed: 0.86 step/s\n",
      "global step 2150, epoch: 1, batch: 2150, loss: 0.33829, accu: 0.95713, speed: 0.86 step/s\n",
      "global step 2160, epoch: 1, batch: 2160, loss: 0.33828, accu: 0.95719, speed: 0.86 step/s\n",
      "global step 2170, epoch: 1, batch: 2170, loss: 0.33828, accu: 0.95728, speed: 0.86 step/s\n",
      "global step 2180, epoch: 1, batch: 2180, loss: 0.37830, accu: 0.95732, speed: 0.86 step/s\n",
      "global step 2190, epoch: 1, batch: 2190, loss: 0.31335, accu: 0.95739, speed: 0.86 step/s\n",
      "global step 2200, epoch: 1, batch: 2200, loss: 0.33827, accu: 0.95745, speed: 0.86 step/s\n",
      "global step 2210, epoch: 1, batch: 2210, loss: 0.32970, accu: 0.95752, speed: 0.86 step/s\n",
      "global step 2220, epoch: 1, batch: 2220, loss: 0.38890, accu: 0.95758, speed: 0.86 step/s\n",
      "global step 2230, epoch: 1, batch: 2230, loss: 0.33829, accu: 0.95766, speed: 0.86 step/s\n",
      "global step 2240, epoch: 1, batch: 2240, loss: 0.41515, accu: 0.95761, speed: 0.86 step/s\n",
      "global step 2250, epoch: 1, batch: 2250, loss: 0.34334, accu: 0.95773, speed: 0.86 step/s\n",
      "global step 2260, epoch: 1, batch: 2260, loss: 0.36443, accu: 0.95774, speed: 0.86 step/s\n",
      "global step 2270, epoch: 1, batch: 2270, loss: 0.34099, accu: 0.95780, speed: 0.86 step/s\n",
      "global step 2280, epoch: 1, batch: 2280, loss: 0.32911, accu: 0.95781, speed: 0.86 step/s\n",
      "global step 2290, epoch: 1, batch: 2290, loss: 0.40686, accu: 0.95776, speed: 0.86 step/s\n",
      "global step 2300, epoch: 1, batch: 2300, loss: 0.36333, accu: 0.95778, speed: 0.86 step/s\n",
      "global step 2310, epoch: 1, batch: 2310, loss: 0.31364, accu: 0.95791, speed: 0.86 step/s\n",
      "global step 2320, epoch: 1, batch: 2320, loss: 0.31330, accu: 0.95797, speed: 0.86 step/s\n",
      "global step 2330, epoch: 1, batch: 2330, loss: 0.36327, accu: 0.95806, speed: 0.86 step/s\n",
      "global step 2340, epoch: 1, batch: 2340, loss: 0.31388, accu: 0.95817, speed: 0.86 step/s\n",
      "global step 2350, epoch: 1, batch: 2350, loss: 0.33834, accu: 0.95826, speed: 0.86 step/s\n",
      "global step 2360, epoch: 1, batch: 2360, loss: 0.31348, accu: 0.95828, speed: 0.86 step/s\n",
      "global step 2370, epoch: 1, batch: 2370, loss: 0.31328, accu: 0.95833, speed: 0.86 step/s\n",
      "global step 2380, epoch: 1, batch: 2380, loss: 0.33842, accu: 0.95842, speed: 0.86 step/s\n",
      "global step 2390, epoch: 1, batch: 2390, loss: 0.35453, accu: 0.95847, speed: 0.86 step/s\n",
      "global step 2400, epoch: 1, batch: 2400, loss: 0.33262, accu: 0.95855, speed: 0.86 step/s\n",
      "global step 2410, epoch: 1, batch: 2410, loss: 0.33829, accu: 0.95866, speed: 0.86 step/s\n",
      "global step 2420, epoch: 1, batch: 2420, loss: 0.33712, accu: 0.95872, speed: 0.86 step/s\n",
      "global step 2430, epoch: 1, batch: 2430, loss: 0.31441, accu: 0.95880, speed: 0.86 step/s\n",
      "global step 2440, epoch: 1, batch: 2440, loss: 0.33601, accu: 0.95890, speed: 0.86 step/s\n",
      "global step 2450, epoch: 1, batch: 2450, loss: 0.33542, accu: 0.95898, speed: 0.86 step/s\n",
      "global step 2460, epoch: 1, batch: 2460, loss: 0.38549, accu: 0.95908, speed: 0.86 step/s\n",
      "global step 2470, epoch: 1, batch: 2470, loss: 0.36324, accu: 0.95912, speed: 0.86 step/s\n",
      "global step 2480, epoch: 1, batch: 2480, loss: 0.33829, accu: 0.95921, speed: 0.86 step/s\n",
      "global step 2490, epoch: 1, batch: 2490, loss: 0.33818, accu: 0.95929, speed: 0.86 step/s\n",
      "global step 2500, epoch: 1, batch: 2500, loss: 0.33830, accu: 0.95937, speed: 0.86 step/s\n",
      "global step 2510, epoch: 1, batch: 2510, loss: 0.33824, accu: 0.95941, speed: 0.86 step/s\n",
      "global step 2520, epoch: 1, batch: 2520, loss: 0.31331, accu: 0.95950, speed: 0.86 step/s\n",
      "global step 2530, epoch: 1, batch: 2530, loss: 0.36329, accu: 0.95949, speed: 0.86 step/s\n",
      "global step 2540, epoch: 1, batch: 2540, loss: 0.31331, accu: 0.95956, speed: 0.86 step/s\n",
      "global step 2550, epoch: 1, batch: 2550, loss: 0.33829, accu: 0.95966, speed: 0.86 step/s\n",
      "global step 2560, epoch: 1, batch: 2560, loss: 0.31337, accu: 0.95973, speed: 0.86 step/s\n",
      "global step 2570, epoch: 1, batch: 2570, loss: 0.32329, accu: 0.95981, speed: 0.86 step/s\n",
      "global step 2580, epoch: 1, batch: 2580, loss: 0.34196, accu: 0.95984, speed: 0.86 step/s\n",
      "global step 2590, epoch: 1, batch: 2590, loss: 0.36326, accu: 0.95989, speed: 0.86 step/s\n",
      "global step 2600, epoch: 1, batch: 2600, loss: 0.31327, accu: 0.95993, speed: 0.86 step/s\n",
      "global step 2610, epoch: 1, batch: 2610, loss: 0.31327, accu: 0.95998, speed: 0.86 step/s\n",
      "global step 2620, epoch: 1, batch: 2620, loss: 0.31328, accu: 0.96003, speed: 0.86 step/s\n",
      "global step 2630, epoch: 1, batch: 2630, loss: 0.31331, accu: 0.96005, speed: 0.86 step/s\n",
      "global step 2640, epoch: 1, batch: 2640, loss: 0.38825, accu: 0.96008, speed: 0.86 step/s\n",
      "global step 2650, epoch: 1, batch: 2650, loss: 0.36327, accu: 0.96013, speed: 0.86 step/s\n",
      "global step 2660, epoch: 1, batch: 2660, loss: 0.31327, accu: 0.96020, speed: 0.86 step/s\n",
      "global step 2670, epoch: 1, batch: 2670, loss: 0.38835, accu: 0.96023, speed: 0.86 step/s\n",
      "global step 2680, epoch: 1, batch: 2680, loss: 0.31329, accu: 0.96030, speed: 0.86 step/s\n",
      "global step 2690, epoch: 1, batch: 2690, loss: 0.31328, accu: 0.96041, speed: 0.86 step/s\n",
      "global step 2700, epoch: 1, batch: 2700, loss: 0.33809, accu: 0.96046, speed: 0.86 step/s\n",
      "global step 2710, epoch: 1, batch: 2710, loss: 0.33829, accu: 0.96052, speed: 0.86 step/s\n",
      "global step 2720, epoch: 1, batch: 2720, loss: 0.36546, accu: 0.96059, speed: 0.86 step/s\n",
      "global step 2730, epoch: 1, batch: 2730, loss: 0.36330, accu: 0.96064, speed: 0.86 step/s\n",
      "global step 2740, epoch: 1, batch: 2740, loss: 0.36327, accu: 0.96065, speed: 0.86 step/s\n",
      "global step 2750, epoch: 1, batch: 2750, loss: 0.31374, accu: 0.96070, speed: 0.86 step/s\n",
      "global step 2760, epoch: 1, batch: 2760, loss: 0.36332, accu: 0.96074, speed: 0.86 step/s\n",
      "global step 2770, epoch: 1, batch: 2770, loss: 0.33829, accu: 0.96078, speed: 0.86 step/s\n",
      "global step 2780, epoch: 1, batch: 2780, loss: 0.33826, accu: 0.96086, speed: 0.86 step/s\n",
      "global step 2790, epoch: 1, batch: 2790, loss: 0.33815, accu: 0.96091, speed: 0.86 step/s\n",
      "global step 2800, epoch: 1, batch: 2800, loss: 0.31355, accu: 0.96096, speed: 0.86 step/s\n",
      "global step 2810, epoch: 1, batch: 2810, loss: 0.36328, accu: 0.96101, speed: 0.86 step/s\n",
      "global step 2820, epoch: 1, batch: 2820, loss: 0.39204, accu: 0.96103, speed: 0.86 step/s\n",
      "global step 2830, epoch: 1, batch: 2830, loss: 0.33828, accu: 0.96110, speed: 0.86 step/s\n",
      "global step 2840, epoch: 1, batch: 2840, loss: 0.33981, accu: 0.96114, speed: 0.86 step/s\n",
      "global step 2850, epoch: 1, batch: 2850, loss: 0.33833, accu: 0.96118, speed: 0.86 step/s\n",
      "global step 2860, epoch: 1, batch: 2860, loss: 0.36327, accu: 0.96124, speed: 0.86 step/s\n",
      "global step 2870, epoch: 1, batch: 2870, loss: 0.36328, accu: 0.96125, speed: 0.86 step/s\n",
      "global step 2880, epoch: 1, batch: 2880, loss: 0.31328, accu: 0.96127, speed: 0.86 step/s\n",
      "global step 2890, epoch: 1, batch: 2890, loss: 0.31336, accu: 0.96132, speed: 0.86 step/s\n",
      "global step 2900, epoch: 1, batch: 2900, loss: 0.33819, accu: 0.96140, speed: 0.86 step/s\n",
      "global step 2910, epoch: 1, batch: 2910, loss: 0.33833, accu: 0.96139, speed: 0.86 step/s\n",
      "global step 2920, epoch: 1, batch: 2920, loss: 0.31336, accu: 0.96146, speed: 0.86 step/s\n",
      "global step 2930, epoch: 1, batch: 2930, loss: 0.31330, accu: 0.96155, speed: 0.86 step/s\n",
      "global step 2940, epoch: 1, batch: 2940, loss: 0.31403, accu: 0.96162, speed: 0.86 step/s\n",
      "global step 2950, epoch: 1, batch: 2950, loss: 0.31330, accu: 0.96164, speed: 0.86 step/s\n",
      "global step 2960, epoch: 1, batch: 2960, loss: 0.33204, accu: 0.96168, speed: 0.86 step/s\n",
      "global step 2970, epoch: 1, batch: 2970, loss: 0.31358, accu: 0.96175, speed: 0.86 step/s\n",
      "global step 2980, epoch: 1, batch: 2980, loss: 0.36300, accu: 0.96182, speed: 0.86 step/s\n",
      "global step 2990, epoch: 1, batch: 2990, loss: 0.31330, accu: 0.96189, speed: 0.86 step/s\n",
      "global step 3000, epoch: 1, batch: 3000, loss: 0.33828, accu: 0.96195, speed: 0.86 step/s\n",
      "global step 3010, epoch: 1, batch: 3010, loss: 0.31330, accu: 0.96199, speed: 0.86 step/s\n",
      "global step 3020, epoch: 1, batch: 3020, loss: 0.31493, accu: 0.96200, speed: 0.86 step/s\n",
      "global step 3030, epoch: 1, batch: 3030, loss: 0.33848, accu: 0.96204, speed: 0.86 step/s\n",
      "global step 3040, epoch: 1, batch: 3040, loss: 0.31336, accu: 0.96209, speed: 0.86 step/s\n",
      "global step 3050, epoch: 1, batch: 3050, loss: 0.31328, accu: 0.96218, speed: 0.86 step/s\n",
      "global step 3060, epoch: 1, batch: 3060, loss: 0.33827, accu: 0.96225, speed: 0.86 step/s\n",
      "global step 3070, epoch: 1, batch: 3070, loss: 0.31392, accu: 0.96231, speed: 0.86 step/s\n",
      "global step 3080, epoch: 1, batch: 3080, loss: 0.45825, accu: 0.96234, speed: 0.86 step/s\n",
      "global step 3090, epoch: 1, batch: 3090, loss: 0.33829, accu: 0.96234, speed: 0.86 step/s\n",
      "global step 3100, epoch: 1, batch: 3100, loss: 0.33922, accu: 0.96236, speed: 0.86 step/s\n",
      "global step 3110, epoch: 1, batch: 3110, loss: 0.31328, accu: 0.96240, speed: 0.86 step/s\n",
      "global step 3120, epoch: 1, batch: 3120, loss: 0.31329, accu: 0.96241, speed: 0.86 step/s\n",
      "global step 3130, epoch: 1, batch: 3130, loss: 0.33952, accu: 0.96249, speed: 0.86 step/s\n",
      "global step 3140, epoch: 1, batch: 3140, loss: 0.31333, accu: 0.96258, speed: 0.86 step/s\n",
      "global step 3150, epoch: 1, batch: 3150, loss: 0.33808, accu: 0.96260, speed: 0.86 step/s\n",
      "global step 3160, epoch: 1, batch: 3160, loss: 0.35790, accu: 0.96260, speed: 0.86 step/s\n",
      "global step 3170, epoch: 1, batch: 3170, loss: 0.31330, accu: 0.96267, speed: 0.86 step/s\n",
      "global step 3180, epoch: 1, batch: 3180, loss: 0.33829, accu: 0.96274, speed: 0.86 step/s\n",
      "global step 3190, epoch: 1, batch: 3190, loss: 0.31330, accu: 0.96281, speed: 0.86 step/s\n",
      "global step 3200, epoch: 1, batch: 3200, loss: 0.33830, accu: 0.96287, speed: 0.86 step/s\n",
      "global step 3210, epoch: 1, batch: 3210, loss: 0.31831, accu: 0.96293, speed: 0.86 step/s\n",
      "global step 3220, epoch: 1, batch: 3220, loss: 0.31330, accu: 0.96301, speed: 0.86 step/s\n",
      "global step 3230, epoch: 1, batch: 3230, loss: 0.37688, accu: 0.96305, speed: 0.86 step/s\n",
      "global step 3240, epoch: 1, batch: 3240, loss: 0.31858, accu: 0.96308, speed: 0.86 step/s\n",
      "global step 3250, epoch: 1, batch: 3250, loss: 0.33828, accu: 0.96313, speed: 0.86 step/s\n",
      "global step 3260, epoch: 1, batch: 3260, loss: 0.31337, accu: 0.96319, speed: 0.86 step/s\n",
      "global step 3270, epoch: 1, batch: 3270, loss: 0.35429, accu: 0.96320, speed: 0.86 step/s\n",
      "global step 3280, epoch: 1, batch: 3280, loss: 0.35926, accu: 0.96322, speed: 0.86 step/s\n",
      "global step 3290, epoch: 1, batch: 3290, loss: 0.31328, accu: 0.96331, speed: 0.86 step/s\n",
      "global step 3300, epoch: 1, batch: 3300, loss: 0.38855, accu: 0.96336, speed: 0.86 step/s\n",
      "global step 3310, epoch: 1, batch: 3310, loss: 0.31380, accu: 0.96344, speed: 0.86 step/s\n",
      "global step 3320, epoch: 1, batch: 3320, loss: 0.36326, accu: 0.96349, speed: 0.86 step/s\n",
      "global step 3330, epoch: 1, batch: 3330, loss: 0.36328, accu: 0.96354, speed: 0.86 step/s\n",
      "global step 3340, epoch: 1, batch: 3340, loss: 0.36320, accu: 0.96356, speed: 0.86 step/s\n",
      "global step 3350, epoch: 1, batch: 3350, loss: 0.31329, accu: 0.96360, speed: 0.86 step/s\n",
      "global step 3360, epoch: 1, batch: 3360, loss: 0.31333, accu: 0.96365, speed: 0.86 step/s\n",
      "global step 3370, epoch: 1, batch: 3370, loss: 0.34443, accu: 0.96372, speed: 0.86 step/s\n",
      "global step 3380, epoch: 1, batch: 3380, loss: 0.33830, accu: 0.96376, speed: 0.86 step/s\n",
      "global step 3390, epoch: 1, batch: 3390, loss: 0.33846, accu: 0.96381, speed: 0.86 step/s\n",
      "global step 3400, epoch: 1, batch: 3400, loss: 0.32893, accu: 0.96385, speed: 0.86 step/s\n",
      "global step 3410, epoch: 1, batch: 3410, loss: 0.38649, accu: 0.96391, speed: 0.86 step/s\n",
      "global step 3420, epoch: 1, batch: 3420, loss: 0.31331, accu: 0.96397, speed: 0.86 step/s\n",
      "global step 3430, epoch: 1, batch: 3430, loss: 0.33545, accu: 0.96403, speed: 0.86 step/s\n",
      "global step 3440, epoch: 1, batch: 3440, loss: 0.34341, accu: 0.96409, speed: 0.86 step/s\n",
      "global step 3450, epoch: 1, batch: 3450, loss: 0.31330, accu: 0.96414, speed: 0.86 step/s\n",
      "global step 3460, epoch: 1, batch: 3460, loss: 0.33828, accu: 0.96418, speed: 0.86 step/s\n",
      "global step 3470, epoch: 1, batch: 3470, loss: 0.31381, accu: 0.96421, speed: 0.86 step/s\n",
      "global step 3480, epoch: 1, batch: 3480, loss: 0.33827, accu: 0.96422, speed: 0.86 step/s\n",
      "global step 3490, epoch: 1, batch: 3490, loss: 0.33817, accu: 0.96428, speed: 0.86 step/s\n",
      "global step 3500, epoch: 1, batch: 3500, loss: 0.39984, accu: 0.96429, speed: 0.86 step/s\n",
      "global step 3510, epoch: 1, batch: 3510, loss: 0.31330, accu: 0.96430, speed: 0.86 step/s\n",
      "global step 3520, epoch: 1, batch: 3520, loss: 0.33881, accu: 0.96436, speed: 0.86 step/s\n",
      "global step 3530, epoch: 1, batch: 3530, loss: 0.31330, accu: 0.96443, speed: 0.86 step/s\n",
      "global step 3540, epoch: 1, batch: 3540, loss: 0.36280, accu: 0.96447, speed: 0.86 step/s\n",
      "global step 3550, epoch: 1, batch: 3550, loss: 0.31331, accu: 0.96449, speed: 0.87 step/s\n",
      "global step 3560, epoch: 1, batch: 3560, loss: 0.33854, accu: 0.96452, speed: 0.87 step/s\n",
      "global step 3570, epoch: 1, batch: 3570, loss: 0.31357, accu: 0.96455, speed: 0.87 step/s\n",
      "global step 3580, epoch: 1, batch: 3580, loss: 0.38850, accu: 0.96456, speed: 0.86 step/s\n",
      "global step 3590, epoch: 1, batch: 3590, loss: 0.33829, accu: 0.96462, speed: 0.87 step/s\n",
      "global step 3600, epoch: 1, batch: 3600, loss: 0.33782, accu: 0.96466, speed: 0.86 step/s\n",
      "global step 3610, epoch: 1, batch: 3610, loss: 0.31337, accu: 0.96471, speed: 0.86 step/s\n",
      "global step 3620, epoch: 1, batch: 3620, loss: 0.31332, accu: 0.96474, speed: 0.86 step/s\n",
      "global step 3630, epoch: 1, batch: 3630, loss: 0.33882, accu: 0.96480, speed: 0.86 step/s\n",
      "global step 3640, epoch: 1, batch: 3640, loss: 0.31351, accu: 0.96484, speed: 0.86 step/s\n",
      "global step 3650, epoch: 1, batch: 3650, loss: 0.31546, accu: 0.96490, speed: 0.86 step/s\n",
      "global step 3660, epoch: 1, batch: 3660, loss: 0.35860, accu: 0.96491, speed: 0.86 step/s\n",
      "global step 3670, epoch: 1, batch: 3670, loss: 0.33884, accu: 0.96497, speed: 0.86 step/s\n",
      "global step 3680, epoch: 1, batch: 3680, loss: 0.33828, accu: 0.96501, speed: 0.86 step/s\n",
      "global step 3690, epoch: 1, batch: 3690, loss: 0.36324, accu: 0.96505, speed: 0.86 step/s\n",
      "global step 3700, epoch: 1, batch: 3700, loss: 0.31327, accu: 0.96511, speed: 0.86 step/s\n",
      "global step 3710, epoch: 1, batch: 3710, loss: 0.34183, accu: 0.96518, speed: 0.86 step/s\n",
      "global step 3720, epoch: 1, batch: 3720, loss: 0.36325, accu: 0.96522, speed: 0.86 step/s\n",
      "global step 3730, epoch: 1, batch: 3730, loss: 0.33827, accu: 0.96527, speed: 0.86 step/s\n",
      "global step 3740, epoch: 1, batch: 3740, loss: 0.36233, accu: 0.96530, speed: 0.86 step/s\n",
      "global step 3750, epoch: 1, batch: 3750, loss: 0.31327, accu: 0.96535, speed: 0.86 step/s\n",
      "global step 3760, epoch: 1, batch: 3760, loss: 0.36458, accu: 0.96540, speed: 0.86 step/s\n",
      "global step 3770, epoch: 1, batch: 3770, loss: 0.31327, accu: 0.96546, speed: 0.86 step/s\n",
      "global step 3780, epoch: 1, batch: 3780, loss: 0.31327, accu: 0.96550, speed: 0.86 step/s\n",
      "global step 3790, epoch: 1, batch: 3790, loss: 0.31393, accu: 0.96553, speed: 0.86 step/s\n",
      "global step 3800, epoch: 1, batch: 3800, loss: 0.36329, accu: 0.96560, speed: 0.86 step/s\n",
      "global step 3810, epoch: 1, batch: 3810, loss: 0.36326, accu: 0.96563, speed: 0.86 step/s\n",
      "global step 3820, epoch: 1, batch: 3820, loss: 0.31327, accu: 0.96566, speed: 0.86 step/s\n",
      "global step 3830, epoch: 1, batch: 3830, loss: 0.31327, accu: 0.96570, speed: 0.86 step/s\n",
      "global step 3840, epoch: 1, batch: 3840, loss: 0.36331, accu: 0.96572, speed: 0.86 step/s\n",
      "global step 3850, epoch: 1, batch: 3850, loss: 0.33819, accu: 0.96572, speed: 0.86 step/s\n",
      "global step 3860, epoch: 1, batch: 3860, loss: 0.31327, accu: 0.96576, speed: 0.86 step/s\n",
      "global step 3870, epoch: 1, batch: 3870, loss: 0.33827, accu: 0.96581, speed: 0.86 step/s\n",
      "global step 3880, epoch: 1, batch: 3880, loss: 0.31327, accu: 0.96587, speed: 0.86 step/s\n",
      "global step 3890, epoch: 1, batch: 3890, loss: 0.33828, accu: 0.96594, speed: 0.86 step/s\n",
      "global step 3900, epoch: 1, batch: 3900, loss: 0.31328, accu: 0.96599, speed: 0.86 step/s\n",
      "global step 3910, epoch: 1, batch: 3910, loss: 0.33827, accu: 0.96600, speed: 0.86 step/s\n",
      "global step 3920, epoch: 1, batch: 3920, loss: 0.31327, accu: 0.96602, speed: 0.86 step/s\n",
      "global step 3930, epoch: 1, batch: 3930, loss: 0.31434, accu: 0.96605, speed: 0.86 step/s\n",
      "global step 3940, epoch: 1, batch: 3940, loss: 0.36348, accu: 0.96607, speed: 0.86 step/s\n",
      "global step 3950, epoch: 1, batch: 3950, loss: 0.31327, accu: 0.96606, speed: 0.86 step/s\n",
      "global step 3960, epoch: 1, batch: 3960, loss: 0.33828, accu: 0.96608, speed: 0.86 step/s\n",
      "global step 3970, epoch: 1, batch: 3970, loss: 0.38724, accu: 0.96610, speed: 0.86 step/s\n",
      "global step 3980, epoch: 1, batch: 3980, loss: 0.31327, accu: 0.96611, speed: 0.86 step/s\n",
      "global step 3990, epoch: 1, batch: 3990, loss: 0.31327, accu: 0.96616, speed: 0.86 step/s\n",
      "global step 4000, epoch: 1, batch: 4000, loss: 0.31328, accu: 0.96620, speed: 0.86 step/s\n",
      "global step 4010, epoch: 1, batch: 4010, loss: 0.31329, accu: 0.96622, speed: 0.86 step/s\n",
      "global step 4020, epoch: 1, batch: 4020, loss: 0.31449, accu: 0.96627, speed: 0.86 step/s\n",
      "global step 4030, epoch: 1, batch: 4030, loss: 0.31335, accu: 0.96631, speed: 0.86 step/s\n",
      "global step 4040, epoch: 1, batch: 4040, loss: 0.33827, accu: 0.96635, speed: 0.86 step/s\n",
      "global step 4050, epoch: 1, batch: 4050, loss: 0.33826, accu: 0.96635, speed: 0.86 step/s\n",
      "global step 4060, epoch: 1, batch: 4060, loss: 0.33827, accu: 0.96638, speed: 0.86 step/s\n",
      "global step 4070, epoch: 1, batch: 4070, loss: 0.31328, accu: 0.96640, speed: 0.86 step/s\n",
      "global step 4080, epoch: 1, batch: 4080, loss: 0.31327, accu: 0.96643, speed: 0.86 step/s\n",
      "global step 4090, epoch: 1, batch: 4090, loss: 0.31328, accu: 0.96647, speed: 0.86 step/s\n",
      "global step 4100, epoch: 1, batch: 4100, loss: 0.33829, accu: 0.96649, speed: 0.86 step/s\n",
      "global step 4110, epoch: 1, batch: 4110, loss: 0.36327, accu: 0.96648, speed: 0.86 step/s\n",
      "global step 4120, epoch: 1, batch: 4120, loss: 0.33292, accu: 0.96647, speed: 0.86 step/s\n",
      "global step 4130, epoch: 1, batch: 4130, loss: 0.31655, accu: 0.96650, speed: 0.86 step/s\n",
      "global step 4140, epoch: 1, batch: 4140, loss: 0.31328, accu: 0.96655, speed: 0.86 step/s\n",
      "global step 4150, epoch: 1, batch: 4150, loss: 0.31330, accu: 0.96659, speed: 0.86 step/s\n",
      "global step 4160, epoch: 1, batch: 4160, loss: 0.31328, accu: 0.96665, speed: 0.86 step/s\n",
      "global step 4170, epoch: 1, batch: 4170, loss: 0.33836, accu: 0.96667, speed: 0.86 step/s\n",
      "global step 4180, epoch: 1, batch: 4180, loss: 0.31328, accu: 0.96671, speed: 0.86 step/s\n",
      "global step 4190, epoch: 1, batch: 4190, loss: 0.33827, accu: 0.96672, speed: 0.86 step/s\n",
      "global step 4200, epoch: 1, batch: 4200, loss: 0.31329, accu: 0.96677, speed: 0.86 step/s\n",
      "global step 4210, epoch: 1, batch: 4210, loss: 0.33829, accu: 0.96682, speed: 0.86 step/s\n",
      "global step 4220, epoch: 1, batch: 4220, loss: 0.33832, accu: 0.96685, speed: 0.86 step/s\n",
      "global step 4230, epoch: 1, batch: 4230, loss: 0.36426, accu: 0.96686, speed: 0.86 step/s\n",
      "global step 4240, epoch: 1, batch: 4240, loss: 0.33814, accu: 0.96689, speed: 0.86 step/s\n",
      "global step 4250, epoch: 1, batch: 4250, loss: 0.31911, accu: 0.96692, speed: 0.86 step/s\n",
      "global step 4260, epoch: 1, batch: 4260, loss: 0.36324, accu: 0.96695, speed: 0.86 step/s\n",
      "global step 4270, epoch: 1, batch: 4270, loss: 0.33828, accu: 0.96700, speed: 0.86 step/s\n",
      "global step 4280, epoch: 1, batch: 4280, loss: 0.31328, accu: 0.96705, speed: 0.86 step/s\n",
      "global step 4290, epoch: 1, batch: 4290, loss: 0.33827, accu: 0.96706, speed: 0.86 step/s\n",
      "global step 4300, epoch: 1, batch: 4300, loss: 0.31327, accu: 0.96712, speed: 0.86 step/s\n",
      "global step 4310, epoch: 1, batch: 4310, loss: 0.33818, accu: 0.96715, speed: 0.86 step/s\n",
      "global step 4320, epoch: 1, batch: 4320, loss: 0.36332, accu: 0.96718, speed: 0.86 step/s\n",
      "global step 4330, epoch: 1, batch: 4330, loss: 0.31328, accu: 0.96719, speed: 0.86 step/s\n",
      "global step 4340, epoch: 1, batch: 4340, loss: 0.36334, accu: 0.96723, speed: 0.86 step/s\n",
      "global step 4350, epoch: 1, batch: 4350, loss: 0.31328, accu: 0.96725, speed: 0.86 step/s\n",
      "global step 4360, epoch: 1, batch: 4360, loss: 0.31328, accu: 0.96728, speed: 0.86 step/s\n",
      "global step 4370, epoch: 1, batch: 4370, loss: 0.31357, accu: 0.96731, speed: 0.86 step/s\n",
      "global step 4380, epoch: 1, batch: 4380, loss: 0.36327, accu: 0.96731, speed: 0.86 step/s\n",
      "global step 4390, epoch: 1, batch: 4390, loss: 0.36227, accu: 0.96734, speed: 0.86 step/s\n",
      "global step 4400, epoch: 1, batch: 4400, loss: 0.36343, accu: 0.96735, speed: 0.86 step/s\n",
      "global step 4410, epoch: 1, batch: 4410, loss: 0.31327, accu: 0.96738, speed: 0.86 step/s\n",
      "global step 4420, epoch: 1, batch: 4420, loss: 0.33827, accu: 0.96739, speed: 0.86 step/s\n",
      "global step 4430, epoch: 1, batch: 4430, loss: 0.36329, accu: 0.96742, speed: 0.86 step/s\n",
      "global step 4440, epoch: 1, batch: 4440, loss: 0.36325, accu: 0.96742, speed: 0.86 step/s\n",
      "global step 4450, epoch: 1, batch: 4450, loss: 0.31388, accu: 0.96746, speed: 0.86 step/s\n",
      "global step 4460, epoch: 1, batch: 4460, loss: 0.32576, accu: 0.96750, speed: 0.86 step/s\n",
      "global step 4470, epoch: 1, batch: 4470, loss: 0.36327, accu: 0.96752, speed: 0.86 step/s\n",
      "global step 4480, epoch: 1, batch: 4480, loss: 0.36327, accu: 0.96755, speed: 0.86 step/s\n",
      "global step 4490, epoch: 1, batch: 4490, loss: 0.33604, accu: 0.96758, speed: 0.86 step/s\n",
      "global step 4500, epoch: 1, batch: 4500, loss: 0.32826, accu: 0.96759, speed: 0.86 step/s\n",
      "global step 4510, epoch: 1, batch: 4510, loss: 0.36306, accu: 0.96762, speed: 0.86 step/s\n",
      "global step 4520, epoch: 1, batch: 4520, loss: 0.33812, accu: 0.96764, speed: 0.86 step/s\n",
      "global step 4530, epoch: 1, batch: 4530, loss: 0.32080, accu: 0.96768, speed: 0.86 step/s\n",
      "global step 4540, epoch: 1, batch: 4540, loss: 0.31771, accu: 0.96770, speed: 0.86 step/s\n",
      "global step 4550, epoch: 1, batch: 4550, loss: 0.31392, accu: 0.96775, speed: 0.86 step/s\n",
      "global step 4560, epoch: 1, batch: 4560, loss: 0.31327, accu: 0.96779, speed: 0.86 step/s\n",
      "global step 4570, epoch: 1, batch: 4570, loss: 0.31327, accu: 0.96783, speed: 0.86 step/s\n",
      "global step 4580, epoch: 1, batch: 4580, loss: 0.31463, accu: 0.96786, speed: 0.86 step/s\n",
      "global step 4590, epoch: 1, batch: 4590, loss: 0.37154, accu: 0.96788, speed: 0.86 step/s\n",
      "global step 4600, epoch: 1, batch: 4600, loss: 0.33830, accu: 0.96789, speed: 0.86 step/s\n",
      "global step 4610, epoch: 1, batch: 4610, loss: 0.36617, accu: 0.96792, speed: 0.86 step/s\n",
      "global step 4620, epoch: 1, batch: 4620, loss: 0.33827, accu: 0.96794, speed: 0.86 step/s\n",
      "global step 4630, epoch: 1, batch: 4630, loss: 0.31327, accu: 0.96797, speed: 0.86 step/s\n",
      "global step 4640, epoch: 1, batch: 4640, loss: 0.33848, accu: 0.96795, speed: 0.86 step/s\n",
      "global step 4650, epoch: 1, batch: 4650, loss: 0.33512, accu: 0.96798, speed: 0.86 step/s\n",
      "global step 4660, epoch: 1, batch: 4660, loss: 0.35969, accu: 0.96802, speed: 0.86 step/s\n",
      "global step 4670, epoch: 1, batch: 4670, loss: 0.32942, accu: 0.96802, speed: 0.86 step/s\n",
      "global step 4680, epoch: 1, batch: 4680, loss: 0.36693, accu: 0.96802, speed: 0.86 step/s\n",
      "global step 4690, epoch: 1, batch: 4690, loss: 0.33827, accu: 0.96805, speed: 0.86 step/s\n",
      "global step 4700, epoch: 1, batch: 4700, loss: 0.38797, accu: 0.96807, speed: 0.86 step/s\n",
      "global step 4710, epoch: 1, batch: 4710, loss: 0.31340, accu: 0.96808, speed: 0.86 step/s\n",
      "global step 4720, epoch: 1, batch: 4720, loss: 0.36327, accu: 0.96809, speed: 0.86 step/s\n",
      "global step 4730, epoch: 1, batch: 4730, loss: 0.36316, accu: 0.96808, speed: 0.86 step/s\n",
      "global step 4740, epoch: 1, batch: 4740, loss: 0.31795, accu: 0.96811, speed: 0.86 step/s\n",
      "global step 4750, epoch: 1, batch: 4750, loss: 0.38823, accu: 0.96812, speed: 0.86 step/s\n",
      "global step 4760, epoch: 1, batch: 4760, loss: 0.36320, accu: 0.96813, speed: 0.86 step/s\n",
      "global step 4770, epoch: 1, batch: 4770, loss: 0.31329, accu: 0.96816, speed: 0.86 step/s\n",
      "global step 4780, epoch: 1, batch: 4780, loss: 0.35828, accu: 0.96815, speed: 0.86 step/s\n",
      "global step 4790, epoch: 1, batch: 4790, loss: 0.34281, accu: 0.96817, speed: 0.86 step/s\n",
      "global step 4800, epoch: 1, batch: 4800, loss: 0.31328, accu: 0.96821, speed: 0.86 step/s\n",
      "global step 4810, epoch: 1, batch: 4810, loss: 0.31336, accu: 0.96824, speed: 0.86 step/s\n",
      "global step 4820, epoch: 1, batch: 4820, loss: 0.33784, accu: 0.96827, speed: 0.86 step/s\n",
      "global step 4830, epoch: 1, batch: 4830, loss: 0.34473, accu: 0.96829, speed: 0.86 step/s\n",
      "global step 4840, epoch: 1, batch: 4840, loss: 0.31413, accu: 0.96830, speed: 0.86 step/s\n",
      "global step 4850, epoch: 1, batch: 4850, loss: 0.31338, accu: 0.96832, speed: 0.86 step/s\n",
      "global step 4860, epoch: 1, batch: 4860, loss: 0.31327, accu: 0.96837, speed: 0.86 step/s\n",
      "global step 4870, epoch: 1, batch: 4870, loss: 0.31327, accu: 0.96839, speed: 0.86 step/s\n",
      "global step 4880, epoch: 1, batch: 4880, loss: 0.35536, accu: 0.96841, speed: 0.86 step/s\n",
      "global step 4890, epoch: 1, batch: 4890, loss: 0.31473, accu: 0.96844, speed: 0.86 step/s\n",
      "global step 4900, epoch: 1, batch: 4900, loss: 0.33795, accu: 0.96847, speed: 0.86 step/s\n",
      "global step 4910, epoch: 1, batch: 4910, loss: 0.33828, accu: 0.96852, speed: 0.86 step/s\n",
      "global step 4920, epoch: 1, batch: 4920, loss: 0.38765, accu: 0.96854, speed: 0.86 step/s\n",
      "global step 4930, epoch: 1, batch: 4930, loss: 0.33822, accu: 0.96855, speed: 0.86 step/s\n",
      "global step 4940, epoch: 1, batch: 4940, loss: 0.31327, accu: 0.96858, speed: 0.86 step/s\n",
      "global step 4950, epoch: 1, batch: 4950, loss: 0.31327, accu: 0.96860, speed: 0.86 step/s\n",
      "global step 4960, epoch: 1, batch: 4960, loss: 0.31328, accu: 0.96862, speed: 0.86 step/s\n",
      "global step 4970, epoch: 1, batch: 4970, loss: 0.34123, accu: 0.96867, speed: 0.86 step/s\n",
      "global step 4980, epoch: 1, batch: 4980, loss: 0.31402, accu: 0.96870, speed: 0.86 step/s\n",
      "global step 4990, epoch: 1, batch: 4990, loss: 0.33827, accu: 0.96874, speed: 0.86 step/s\n",
      "global step 5000, epoch: 1, batch: 5000, loss: 0.31328, accu: 0.96879, speed: 0.86 step/s\n",
      "global step 5010, epoch: 1, batch: 5010, loss: 0.38827, accu: 0.96881, speed: 0.86 step/s\n",
      "global step 5020, epoch: 1, batch: 5020, loss: 0.33842, accu: 0.96886, speed: 0.86 step/s\n",
      "global step 5030, epoch: 1, batch: 5030, loss: 0.31328, accu: 0.96890, speed: 0.86 step/s\n",
      "global step 5040, epoch: 1, batch: 5040, loss: 0.31337, accu: 0.96894, speed: 0.86 step/s\n",
      "global step 5050, epoch: 1, batch: 5050, loss: 0.31327, accu: 0.96897, speed: 0.86 step/s\n",
      "global step 5060, epoch: 1, batch: 5060, loss: 0.34351, accu: 0.96900, speed: 0.86 step/s\n",
      "global step 5070, epoch: 1, batch: 5070, loss: 0.31327, accu: 0.96904, speed: 0.86 step/s\n",
      "global step 5080, epoch: 1, batch: 5080, loss: 0.31334, accu: 0.96905, speed: 0.86 step/s\n",
      "global step 5090, epoch: 1, batch: 5090, loss: 0.31344, accu: 0.96910, speed: 0.86 step/s\n",
      "global step 5100, epoch: 1, batch: 5100, loss: 0.36327, accu: 0.96912, speed: 0.86 step/s\n",
      "global step 5110, epoch: 1, batch: 5110, loss: 0.32630, accu: 0.96914, speed: 0.86 step/s\n",
      "global step 5120, epoch: 1, batch: 5120, loss: 0.31333, accu: 0.96917, speed: 0.86 step/s\n",
      "global step 5130, epoch: 1, batch: 5130, loss: 0.31327, accu: 0.96922, speed: 0.86 step/s\n",
      "global step 5140, epoch: 1, batch: 5140, loss: 0.33827, accu: 0.96925, speed: 0.86 step/s\n",
      "global step 5150, epoch: 1, batch: 5150, loss: 0.36325, accu: 0.96926, speed: 0.86 step/s\n",
      "global step 5160, epoch: 1, batch: 5160, loss: 0.31327, accu: 0.96928, speed: 0.86 step/s\n",
      "global step 5170, epoch: 1, batch: 5170, loss: 0.36241, accu: 0.96931, speed: 0.86 step/s\n",
      "global step 5180, epoch: 1, batch: 5180, loss: 0.33845, accu: 0.96931, speed: 0.86 step/s\n",
      "global step 5190, epoch: 1, batch: 5190, loss: 0.31327, accu: 0.96934, speed: 0.86 step/s\n",
      "global step 5200, epoch: 1, batch: 5200, loss: 0.31331, accu: 0.96935, speed: 0.86 step/s\n",
      "global step 5210, epoch: 1, batch: 5210, loss: 0.31327, accu: 0.96940, speed: 0.86 step/s\n",
      "global step 5220, epoch: 1, batch: 5220, loss: 0.31331, accu: 0.96943, speed: 0.86 step/s\n",
      "global step 5230, epoch: 1, batch: 5230, loss: 0.31327, accu: 0.96946, speed: 0.86 step/s\n",
      "global step 5240, epoch: 1, batch: 5240, loss: 0.31327, accu: 0.96951, speed: 0.86 step/s\n",
      "global step 5250, epoch: 1, batch: 5250, loss: 0.33827, accu: 0.96953, speed: 0.86 step/s\n",
      "global step 5260, epoch: 1, batch: 5260, loss: 0.33827, accu: 0.96956, speed: 0.86 step/s\n",
      "global step 5270, epoch: 1, batch: 5270, loss: 0.31977, accu: 0.96960, speed: 0.86 step/s\n",
      "global step 5280, epoch: 1, batch: 5280, loss: 0.31327, accu: 0.96963, speed: 0.86 step/s\n",
      "global step 5290, epoch: 1, batch: 5290, loss: 0.33801, accu: 0.96965, speed: 0.86 step/s\n",
      "global step 5300, epoch: 1, batch: 5300, loss: 0.31327, accu: 0.96968, speed: 0.86 step/s\n",
      "global step 5310, epoch: 1, batch: 5310, loss: 0.31327, accu: 0.96972, speed: 0.86 step/s\n",
      "global step 5320, epoch: 1, batch: 5320, loss: 0.31328, accu: 0.96977, speed: 0.86 step/s\n",
      "global step 5330, epoch: 1, batch: 5330, loss: 0.35779, accu: 0.96979, speed: 0.86 step/s\n",
      "global step 5340, epoch: 1, batch: 5340, loss: 0.33781, accu: 0.96983, speed: 0.86 step/s\n",
      "global step 5350, epoch: 1, batch: 5350, loss: 0.31328, accu: 0.96986, speed: 0.86 step/s\n",
      "global step 5360, epoch: 1, batch: 5360, loss: 0.33826, accu: 0.96989, speed: 0.86 step/s\n",
      "global step 5370, epoch: 1, batch: 5370, loss: 0.31330, accu: 0.96992, speed: 0.86 step/s\n",
      "global step 5380, epoch: 1, batch: 5380, loss: 0.31327, accu: 0.96995, speed: 0.86 step/s\n",
      "global step 5390, epoch: 1, batch: 5390, loss: 0.33827, accu: 0.96997, speed: 0.86 step/s\n",
      "global step 5400, epoch: 1, batch: 5400, loss: 0.33822, accu: 0.97002, speed: 0.86 step/s\n",
      "global step 5410, epoch: 1, batch: 5410, loss: 0.31332, accu: 0.97003, speed: 0.86 step/s\n",
      "global step 5420, epoch: 1, batch: 5420, loss: 0.32301, accu: 0.97006, speed: 0.86 step/s\n",
      "global step 5430, epoch: 1, batch: 5430, loss: 0.31668, accu: 0.97010, speed: 0.86 step/s\n",
      "global step 5440, epoch: 1, batch: 5440, loss: 0.31327, accu: 0.97012, speed: 0.86 step/s\n",
      "global step 5450, epoch: 1, batch: 5450, loss: 0.38837, accu: 0.97014, speed: 0.86 step/s\n",
      "global step 5460, epoch: 1, batch: 5460, loss: 0.31328, accu: 0.97016, speed: 0.86 step/s\n",
      "global step 5470, epoch: 1, batch: 5470, loss: 0.38708, accu: 0.97018, speed: 0.86 step/s\n",
      "global step 5480, epoch: 1, batch: 5480, loss: 0.31332, accu: 0.97019, speed: 0.86 step/s\n",
      "global step 5490, epoch: 1, batch: 5490, loss: 0.33726, accu: 0.97021, speed: 0.86 step/s\n",
      "global step 5500, epoch: 1, batch: 5500, loss: 0.31327, accu: 0.97023, speed: 0.86 step/s\n",
      "global step 5510, epoch: 1, batch: 5510, loss: 0.31327, accu: 0.97026, speed: 0.86 step/s\n",
      "global step 5520, epoch: 1, batch: 5520, loss: 0.31328, accu: 0.97029, speed: 0.86 step/s\n",
      "global step 5530, epoch: 1, batch: 5530, loss: 0.31327, accu: 0.97033, speed: 0.86 step/s\n",
      "global step 5540, epoch: 1, batch: 5540, loss: 0.31329, accu: 0.97036, speed: 0.86 step/s\n",
      "global step 5550, epoch: 1, batch: 5550, loss: 0.31327, accu: 0.97038, speed: 0.86 step/s\n",
      "global step 5560, epoch: 1, batch: 5560, loss: 0.33827, accu: 0.97041, speed: 0.86 step/s\n",
      "global step 5570, epoch: 1, batch: 5570, loss: 0.31327, accu: 0.97044, speed: 0.86 step/s\n",
      "global step 5580, epoch: 1, batch: 5580, loss: 0.33504, accu: 0.97048, speed: 0.86 step/s\n",
      "global step 5590, epoch: 1, batch: 5590, loss: 0.31328, accu: 0.97050, speed: 0.86 step/s\n",
      "global step 5600, epoch: 1, batch: 5600, loss: 0.32896, accu: 0.97053, speed: 0.86 step/s\n",
      "global step 5610, epoch: 1, batch: 5610, loss: 0.36121, accu: 0.97056, speed: 0.86 step/s\n",
      "global step 5620, epoch: 1, batch: 5620, loss: 0.31477, accu: 0.97059, speed: 0.86 step/s\n",
      "global step 5630, epoch: 1, batch: 5630, loss: 0.33824, accu: 0.97062, speed: 0.86 step/s\n",
      "global step 5640, epoch: 1, batch: 5640, loss: 0.34662, accu: 0.97065, speed: 0.86 step/s\n",
      "global step 5650, epoch: 1, batch: 5650, loss: 0.31329, accu: 0.97069, speed: 0.86 step/s\n",
      "global step 5660, epoch: 1, batch: 5660, loss: 0.31327, accu: 0.97070, speed: 0.86 step/s\n",
      "global step 5670, epoch: 1, batch: 5670, loss: 0.33827, accu: 0.97071, speed: 0.86 step/s\n",
      "global step 5680, epoch: 1, batch: 5680, loss: 0.31647, accu: 0.97071, speed: 0.86 step/s\n",
      "global step 5690, epoch: 1, batch: 5690, loss: 0.36309, accu: 0.97074, speed: 0.86 step/s\n",
      "global step 5700, epoch: 1, batch: 5700, loss: 0.31990, accu: 0.97076, speed: 0.86 step/s\n",
      "global step 5710, epoch: 1, batch: 5710, loss: 0.31327, accu: 0.97079, speed: 0.86 step/s\n",
      "global step 5720, epoch: 1, batch: 5720, loss: 0.31327, accu: 0.97081, speed: 0.86 step/s\n",
      "global step 5730, epoch: 1, batch: 5730, loss: 0.31347, accu: 0.97083, speed: 0.86 step/s\n",
      "global step 5740, epoch: 1, batch: 5740, loss: 0.31328, accu: 0.97087, speed: 0.86 step/s\n",
      "global step 5750, epoch: 1, batch: 5750, loss: 0.31328, accu: 0.97088, speed: 0.86 step/s\n",
      "global step 5760, epoch: 1, batch: 5760, loss: 0.31331, accu: 0.97092, speed: 0.86 step/s\n",
      "global step 5770, epoch: 1, batch: 5770, loss: 0.34154, accu: 0.97093, speed: 0.86 step/s\n",
      "global step 5780, epoch: 1, batch: 5780, loss: 0.31537, accu: 0.97093, speed: 0.86 step/s\n",
      "global step 5790, epoch: 1, batch: 5790, loss: 0.31352, accu: 0.97096, speed: 0.86 step/s\n",
      "global step 5800, epoch: 1, batch: 5800, loss: 0.31327, accu: 0.97099, speed: 0.86 step/s\n",
      "global step 5810, epoch: 1, batch: 5810, loss: 0.31360, accu: 0.97101, speed: 0.86 step/s\n",
      "global step 5820, epoch: 1, batch: 5820, loss: 0.33823, accu: 0.97102, speed: 0.86 step/s\n",
      "global step 5830, epoch: 1, batch: 5830, loss: 0.31882, accu: 0.97106, speed: 0.86 step/s\n",
      "global step 5840, epoch: 1, batch: 5840, loss: 0.31327, accu: 0.97108, speed: 0.86 step/s\n",
      "global step 5850, epoch: 1, batch: 5850, loss: 0.31331, accu: 0.97108, speed: 0.86 step/s\n",
      "global step 5860, epoch: 1, batch: 5860, loss: 0.34795, accu: 0.97109, speed: 0.86 step/s\n",
      "global step 5870, epoch: 1, batch: 5870, loss: 0.31370, accu: 0.97113, speed: 0.86 step/s\n",
      "global step 5880, epoch: 1, batch: 5880, loss: 0.31427, accu: 0.97114, speed: 0.86 step/s\n",
      "global step 5890, epoch: 1, batch: 5890, loss: 0.31424, accu: 0.97115, speed: 0.86 step/s\n",
      "global step 5900, epoch: 1, batch: 5900, loss: 0.31327, accu: 0.97117, speed: 0.86 step/s\n",
      "global step 5910, epoch: 1, batch: 5910, loss: 0.34319, accu: 0.97118, speed: 0.86 step/s\n",
      "global step 5920, epoch: 1, batch: 5920, loss: 0.31331, accu: 0.97120, speed: 0.86 step/s\n",
      "global step 5930, epoch: 1, batch: 5930, loss: 0.33439, accu: 0.97123, speed: 0.86 step/s\n",
      "global step 5940, epoch: 1, batch: 5940, loss: 0.31328, accu: 0.97125, speed: 0.86 step/s\n",
      "global step 5950, epoch: 1, batch: 5950, loss: 0.31327, accu: 0.97128, speed: 0.86 step/s\n",
      "global step 5960, epoch: 1, batch: 5960, loss: 0.31327, accu: 0.97130, speed: 0.86 step/s\n",
      "global step 5970, epoch: 1, batch: 5970, loss: 0.33818, accu: 0.97132, speed: 0.86 step/s\n",
      "global step 5980, epoch: 1, batch: 5980, loss: 0.31401, accu: 0.97135, speed: 0.86 step/s\n",
      "global step 5990, epoch: 1, batch: 5990, loss: 0.35370, accu: 0.97137, speed: 0.86 step/s\n",
      "global step 6000, epoch: 1, batch: 6000, loss: 0.31327, accu: 0.97139, speed: 0.86 step/s\n",
      "global step 6010, epoch: 1, batch: 6010, loss: 0.31327, accu: 0.97142, speed: 0.86 step/s\n",
      "global step 6020, epoch: 1, batch: 6020, loss: 0.33827, accu: 0.97143, speed: 0.86 step/s\n",
      "global step 6030, epoch: 1, batch: 6030, loss: 0.33690, accu: 0.97143, speed: 0.86 step/s\n",
      "global step 6040, epoch: 1, batch: 6040, loss: 0.31444, accu: 0.97145, speed: 0.86 step/s\n",
      "global step 6050, epoch: 1, batch: 6050, loss: 0.31328, accu: 0.97148, speed: 0.86 step/s\n",
      "global step 6060, epoch: 1, batch: 6060, loss: 0.33821, accu: 0.97149, speed: 0.86 step/s\n",
      "global step 6070, epoch: 1, batch: 6070, loss: 0.31327, accu: 0.97151, speed: 0.86 step/s\n",
      "global step 6080, epoch: 1, batch: 6080, loss: 0.33826, accu: 0.97154, speed: 0.86 step/s\n",
      "global step 6090, epoch: 1, batch: 6090, loss: 0.31328, accu: 0.97155, speed: 0.86 step/s\n",
      "global step 6100, epoch: 1, batch: 6100, loss: 0.36326, accu: 0.97156, speed: 0.86 step/s\n",
      "global step 6110, epoch: 1, batch: 6110, loss: 0.31328, accu: 0.97158, speed: 0.86 step/s\n",
      "global step 6120, epoch: 1, batch: 6120, loss: 0.33831, accu: 0.97161, speed: 0.86 step/s\n",
      "global step 6130, epoch: 1, batch: 6130, loss: 0.31424, accu: 0.97163, speed: 0.86 step/s\n",
      "global step 6140, epoch: 1, batch: 6140, loss: 0.31327, accu: 0.97163, speed: 0.86 step/s\n",
      "global step 6150, epoch: 1, batch: 6150, loss: 0.35317, accu: 0.97166, speed: 0.86 step/s\n",
      "global step 6160, epoch: 1, batch: 6160, loss: 0.36327, accu: 0.97167, speed: 0.86 step/s\n",
      "global step 6170, epoch: 1, batch: 6170, loss: 0.31327, accu: 0.97171, speed: 0.86 step/s\n",
      "global step 6180, epoch: 1, batch: 6180, loss: 0.31328, accu: 0.97172, speed: 0.86 step/s\n",
      "global step 6190, epoch: 1, batch: 6190, loss: 0.31329, accu: 0.97174, speed: 0.86 step/s\n",
      "global step 6200, epoch: 1, batch: 6200, loss: 0.38923, accu: 0.97174, speed: 0.86 step/s\n",
      "global step 6210, epoch: 1, batch: 6210, loss: 0.31327, accu: 0.97177, speed: 0.86 step/s\n",
      "global step 6220, epoch: 1, batch: 6220, loss: 0.31327, accu: 0.97178, speed: 0.86 step/s\n",
      "global step 6230, epoch: 1, batch: 6230, loss: 0.33830, accu: 0.97180, speed: 0.86 step/s\n",
      "global step 6240, epoch: 1, batch: 6240, loss: 0.31332, accu: 0.97181, speed: 0.86 step/s\n",
      "global step 6250, epoch: 1, batch: 6250, loss: 0.31330, accu: 0.97184, speed: 0.86 step/s\n",
      "global step 6260, epoch: 1, batch: 6260, loss: 0.31329, accu: 0.97187, speed: 0.86 step/s\n",
      "global step 6270, epoch: 1, batch: 6270, loss: 0.31328, accu: 0.97189, speed: 0.86 step/s\n",
      "global step 6280, epoch: 1, batch: 6280, loss: 0.31330, accu: 0.97191, speed: 0.86 step/s\n",
      "global step 6290, epoch: 1, batch: 6290, loss: 0.31327, accu: 0.97194, speed: 0.86 step/s\n",
      "global step 6300, epoch: 1, batch: 6300, loss: 0.31330, accu: 0.97196, speed: 0.86 step/s\n",
      "global step 6310, epoch: 1, batch: 6310, loss: 0.32928, accu: 0.97199, speed: 0.86 step/s\n",
      "global step 6320, epoch: 1, batch: 6320, loss: 0.31394, accu: 0.97202, speed: 0.86 step/s\n",
      "global step 6330, epoch: 1, batch: 6330, loss: 0.36348, accu: 0.97203, speed: 0.86 step/s\n",
      "global step 6340, epoch: 1, batch: 6340, loss: 0.31327, accu: 0.97204, speed: 0.86 step/s\n",
      "global step 6350, epoch: 1, batch: 6350, loss: 0.33893, accu: 0.97206, speed: 0.86 step/s\n",
      "global step 6360, epoch: 1, batch: 6360, loss: 0.31327, accu: 0.97208, speed: 0.86 step/s\n",
      "global step 6370, epoch: 1, batch: 6370, loss: 0.33827, accu: 0.97211, speed: 0.86 step/s\n",
      "global step 6380, epoch: 1, batch: 6380, loss: 0.31327, accu: 0.97214, speed: 0.86 step/s\n",
      "global step 6390, epoch: 1, batch: 6390, loss: 0.33827, accu: 0.97214, speed: 0.86 step/s\n",
      "global step 6400, epoch: 1, batch: 6400, loss: 0.33839, accu: 0.97216, speed: 0.86 step/s\n",
      "global step 6410, epoch: 1, batch: 6410, loss: 0.33831, accu: 0.97218, speed: 0.86 step/s\n",
      "global step 6420, epoch: 1, batch: 6420, loss: 0.31331, accu: 0.97220, speed: 0.86 step/s\n",
      "global step 6430, epoch: 1, batch: 6430, loss: 0.31330, accu: 0.97221, speed: 0.86 step/s\n",
      "global step 6440, epoch: 1, batch: 6440, loss: 0.36326, accu: 0.97222, speed: 0.86 step/s\n",
      "global step 6450, epoch: 1, batch: 6450, loss: 0.35208, accu: 0.97221, speed: 0.86 step/s\n",
      "global step 6460, epoch: 1, batch: 6460, loss: 0.31417, accu: 0.97221, speed: 0.86 step/s\n",
      "global step 6470, epoch: 1, batch: 6470, loss: 0.33827, accu: 0.97224, speed: 0.86 step/s\n",
      "global step 6480, epoch: 1, batch: 6480, loss: 0.33827, accu: 0.97225, speed: 0.86 step/s\n",
      "global step 6490, epoch: 1, batch: 6490, loss: 0.31328, accu: 0.97227, speed: 0.86 step/s\n",
      "global step 6500, epoch: 1, batch: 6500, loss: 0.33637, accu: 0.97229, speed: 0.86 step/s\n",
      "global step 6510, epoch: 1, batch: 6510, loss: 0.31330, accu: 0.97230, speed: 0.86 step/s\n",
      "global step 6520, epoch: 1, batch: 6520, loss: 0.33828, accu: 0.97231, speed: 0.86 step/s\n",
      "global step 6530, epoch: 1, batch: 6530, loss: 0.33741, accu: 0.97233, speed: 0.86 step/s\n",
      "global step 6540, epoch: 1, batch: 6540, loss: 0.33834, accu: 0.97234, speed: 0.86 step/s\n",
      "global step 6550, epoch: 1, batch: 6550, loss: 0.38827, accu: 0.97236, speed: 0.86 step/s\n",
      "global step 6560, epoch: 1, batch: 6560, loss: 0.33826, accu: 0.97237, speed: 0.86 step/s\n",
      "global step 6570, epoch: 1, batch: 6570, loss: 0.31326, accu: 0.97240, speed: 0.86 step/s\n",
      "global step 6580, epoch: 1, batch: 6580, loss: 0.31327, accu: 0.97243, speed: 0.86 step/s\n",
      "global step 6590, epoch: 1, batch: 6590, loss: 0.31359, accu: 0.97246, speed: 0.86 step/s\n",
      "global step 6600, epoch: 1, batch: 6600, loss: 0.33828, accu: 0.97248, speed: 0.86 step/s\n",
      "global step 6610, epoch: 1, batch: 6610, loss: 0.31326, accu: 0.97250, speed: 0.86 step/s\n",
      "global step 6620, epoch: 1, batch: 6620, loss: 0.34098, accu: 0.97251, speed: 0.86 step/s\n",
      "global step 6630, epoch: 1, batch: 6630, loss: 0.31327, accu: 0.97252, speed: 0.86 step/s\n",
      "global step 6640, epoch: 1, batch: 6640, loss: 0.31330, accu: 0.97254, speed: 0.86 step/s\n",
      "global step 6650, epoch: 1, batch: 6650, loss: 0.31329, accu: 0.97256, speed: 0.86 step/s\n",
      "global step 6660, epoch: 1, batch: 6660, loss: 0.36335, accu: 0.97256, speed: 0.86 step/s\n",
      "global step 6670, epoch: 1, batch: 6670, loss: 0.36327, accu: 0.97257, speed: 0.86 step/s\n",
      "global step 6680, epoch: 1, batch: 6680, loss: 0.33826, accu: 0.97260, speed: 0.86 step/s\n",
      "global step 6690, epoch: 1, batch: 6690, loss: 0.31328, accu: 0.97262, speed: 0.86 step/s\n",
      "global step 6700, epoch: 1, batch: 6700, loss: 0.31334, accu: 0.97264, speed: 0.86 step/s\n",
      "global step 6710, epoch: 1, batch: 6710, loss: 0.33828, accu: 0.97267, speed: 0.86 step/s\n",
      "global step 6720, epoch: 1, batch: 6720, loss: 0.34064, accu: 0.97269, speed: 0.86 step/s\n",
      "global step 6730, epoch: 1, batch: 6730, loss: 0.31330, accu: 0.97271, speed: 0.86 step/s\n",
      "global step 6740, epoch: 1, batch: 6740, loss: 0.33844, accu: 0.97271, speed: 0.86 step/s\n",
      "global step 6750, epoch: 1, batch: 6750, loss: 0.31328, accu: 0.97274, speed: 0.86 step/s\n",
      "global step 6760, epoch: 1, batch: 6760, loss: 0.33915, accu: 0.97274, speed: 0.86 step/s\n",
      "global step 6770, epoch: 1, batch: 6770, loss: 0.33057, accu: 0.97275, speed: 0.86 step/s\n",
      "global step 6780, epoch: 1, batch: 6780, loss: 0.31327, accu: 0.97278, speed: 0.86 step/s\n",
      "global step 6790, epoch: 1, batch: 6790, loss: 0.36327, accu: 0.97280, speed: 0.86 step/s\n",
      "global step 6800, epoch: 1, batch: 6800, loss: 0.31360, accu: 0.97283, speed: 0.86 step/s\n",
      "global step 6810, epoch: 1, batch: 6810, loss: 0.31327, accu: 0.97287, speed: 0.86 step/s\n",
      "global step 6820, epoch: 1, batch: 6820, loss: 0.31344, accu: 0.97289, speed: 0.86 step/s\n",
      "global step 6830, epoch: 1, batch: 6830, loss: 0.31327, accu: 0.97292, speed: 0.86 step/s\n",
      "global step 6840, epoch: 1, batch: 6840, loss: 0.31327, accu: 0.97294, speed: 0.86 step/s\n",
      "global step 6850, epoch: 1, batch: 6850, loss: 0.33801, accu: 0.97296, speed: 0.86 step/s\n",
      "global step 6860, epoch: 1, batch: 6860, loss: 0.31327, accu: 0.97299, speed: 0.86 step/s\n",
      "global step 6870, epoch: 1, batch: 6870, loss: 0.31328, accu: 0.97301, speed: 0.86 step/s\n",
      "global step 6880, epoch: 1, batch: 6880, loss: 0.31327, accu: 0.97303, speed: 0.86 step/s\n",
      "global step 6890, epoch: 1, batch: 6890, loss: 0.31327, accu: 0.97306, speed: 0.86 step/s\n",
      "global step 6900, epoch: 1, batch: 6900, loss: 0.33827, accu: 0.97307, speed: 0.86 step/s\n",
      "global step 6910, epoch: 1, batch: 6910, loss: 0.33819, accu: 0.97308, speed: 0.86 step/s\n",
      "global step 6920, epoch: 1, batch: 6920, loss: 0.31335, accu: 0.97311, speed: 0.86 step/s\n",
      "global step 6930, epoch: 1, batch: 6930, loss: 0.31327, accu: 0.97312, speed: 0.86 step/s\n",
      "global step 6940, epoch: 1, batch: 6940, loss: 0.31328, accu: 0.97315, speed: 0.86 step/s\n",
      "global step 6950, epoch: 1, batch: 6950, loss: 0.33827, accu: 0.97315, speed: 0.86 step/s\n",
      "global step 6960, epoch: 1, batch: 6960, loss: 0.31353, accu: 0.97317, speed: 0.86 step/s\n",
      "global step 6970, epoch: 1, batch: 6970, loss: 0.31530, accu: 0.97319, speed: 0.86 step/s\n",
      "global step 6980, epoch: 1, batch: 6980, loss: 0.38825, accu: 0.97320, speed: 0.86 step/s\n",
      "global step 6990, epoch: 1, batch: 6990, loss: 0.33836, accu: 0.97322, speed: 0.86 step/s\n",
      "global step 7000, epoch: 1, batch: 7000, loss: 0.33861, accu: 0.97323, speed: 0.86 step/s\n",
      "global step 7010, epoch: 1, batch: 7010, loss: 0.31327, accu: 0.97325, speed: 0.86 step/s\n",
      "global step 7020, epoch: 1, batch: 7020, loss: 0.31328, accu: 0.97327, speed: 0.86 step/s\n",
      "global step 7030, epoch: 1, batch: 7030, loss: 0.31329, accu: 0.97326, speed: 0.86 step/s\n",
      "global step 7040, epoch: 1, batch: 7040, loss: 0.31326, accu: 0.97327, speed: 0.86 step/s\n",
      "global step 7050, epoch: 1, batch: 7050, loss: 0.33829, accu: 0.97328, speed: 0.86 step/s\n",
      "global step 7060, epoch: 1, batch: 7060, loss: 0.33227, accu: 0.97331, speed: 0.86 step/s\n",
      "global step 7070, epoch: 1, batch: 7070, loss: 0.33866, accu: 0.97333, speed: 0.86 step/s\n",
      "global step 7080, epoch: 1, batch: 7080, loss: 0.31759, accu: 0.97334, speed: 0.86 step/s\n",
      "global step 7090, epoch: 1, batch: 7090, loss: 0.31327, accu: 0.97337, speed: 0.86 step/s\n",
      "global step 7100, epoch: 1, batch: 7100, loss: 0.33827, accu: 0.97338, speed: 0.86 step/s\n",
      "global step 7110, epoch: 1, batch: 7110, loss: 0.35766, accu: 0.97340, speed: 0.86 step/s\n",
      "global step 7120, epoch: 1, batch: 7120, loss: 0.33813, accu: 0.97342, speed: 0.86 step/s\n",
      "global step 7130, epoch: 1, batch: 7130, loss: 0.32183, accu: 0.97343, speed: 0.86 step/s\n",
      "global step 7140, epoch: 1, batch: 7140, loss: 0.31328, accu: 0.97343, speed: 0.86 step/s\n",
      "global step 7150, epoch: 1, batch: 7150, loss: 0.31329, accu: 0.97345, speed: 0.86 step/s\n",
      "global step 7160, epoch: 1, batch: 7160, loss: 0.31327, accu: 0.97347, speed: 0.86 step/s\n",
      "global step 7170, epoch: 1, batch: 7170, loss: 0.31327, accu: 0.97349, speed: 0.86 step/s\n",
      "global step 7180, epoch: 1, batch: 7180, loss: 0.33823, accu: 0.97350, speed: 0.86 step/s\n",
      "global step 7190, epoch: 1, batch: 7190, loss: 0.33827, accu: 0.97352, speed: 0.86 step/s\n",
      "global step 7200, epoch: 1, batch: 7200, loss: 0.33826, accu: 0.97353, speed: 0.86 step/s\n",
      "global step 7210, epoch: 1, batch: 7210, loss: 0.31327, accu: 0.97356, speed: 0.86 step/s\n",
      "global step 7220, epoch: 1, batch: 7220, loss: 0.31606, accu: 0.97359, speed: 0.86 step/s\n",
      "global step 7230, epoch: 1, batch: 7230, loss: 0.31327, accu: 0.97359, speed: 0.86 step/s\n",
      "global step 7240, epoch: 1, batch: 7240, loss: 0.33829, accu: 0.97360, speed: 0.86 step/s\n",
      "global step 7250, epoch: 1, batch: 7250, loss: 0.31878, accu: 0.97361, speed: 0.86 step/s\n",
      "global step 7260, epoch: 1, batch: 7260, loss: 0.33941, accu: 0.97364, speed: 0.86 step/s\n",
      "global step 7270, epoch: 1, batch: 7270, loss: 0.33826, accu: 0.97366, speed: 0.86 step/s\n",
      "global step 7280, epoch: 1, batch: 7280, loss: 0.31327, accu: 0.97367, speed: 0.86 step/s\n",
      "global step 7290, epoch: 1, batch: 7290, loss: 0.33828, accu: 0.97369, speed: 0.86 step/s\n",
      "global step 7300, epoch: 1, batch: 7300, loss: 0.31457, accu: 0.97372, speed: 0.86 step/s\n",
      "global step 7310, epoch: 1, batch: 7310, loss: 0.35641, accu: 0.97373, speed: 0.86 step/s\n",
      "global step 7320, epoch: 1, batch: 7320, loss: 0.31331, accu: 0.97376, speed: 0.86 step/s\n",
      "global step 7330, epoch: 1, batch: 7330, loss: 0.31328, accu: 0.97379, speed: 0.86 step/s\n",
      "global step 7340, epoch: 1, batch: 7340, loss: 0.33761, accu: 0.97380, speed: 0.86 step/s\n",
      "global step 7350, epoch: 1, batch: 7350, loss: 0.33817, accu: 0.97381, speed: 0.86 step/s\n",
      "global step 7360, epoch: 1, batch: 7360, loss: 0.35386, accu: 0.97383, speed: 0.86 step/s\n",
      "global step 7370, epoch: 1, batch: 7370, loss: 0.33826, accu: 0.97385, speed: 0.86 step/s\n",
      "global step 7380, epoch: 1, batch: 7380, loss: 0.31327, accu: 0.97387, speed: 0.86 step/s\n",
      "global step 7390, epoch: 1, batch: 7390, loss: 0.31327, accu: 0.97389, speed: 0.86 step/s\n",
      "global step 7400, epoch: 1, batch: 7400, loss: 0.31328, accu: 0.97391, speed: 0.86 step/s\n",
      "global step 7410, epoch: 1, batch: 7410, loss: 0.33815, accu: 0.97393, speed: 0.86 step/s\n",
      "global step 7420, epoch: 1, batch: 7420, loss: 0.31791, accu: 0.97395, speed: 0.86 step/s\n",
      "global step 7430, epoch: 1, batch: 7430, loss: 0.31407, accu: 0.97396, speed: 0.86 step/s\n",
      "global step 7440, epoch: 1, batch: 7440, loss: 0.38869, accu: 0.97398, speed: 0.86 step/s\n",
      "global step 7450, epoch: 1, batch: 7450, loss: 0.31327, accu: 0.97400, speed: 0.86 step/s\n",
      "global step 7460, epoch: 1, batch: 7460, loss: 0.36429, accu: 0.97400, speed: 0.86 step/s\n",
      "global step 7470, epoch: 1, batch: 7470, loss: 0.33828, accu: 0.97401, speed: 0.86 step/s\n",
      "global step 7480, epoch: 1, batch: 7480, loss: 0.36326, accu: 0.97402, speed: 0.86 step/s\n",
      "global step 7490, epoch: 1, batch: 7490, loss: 0.36327, accu: 0.97402, speed: 0.86 step/s\n",
      "global step 7500, epoch: 1, batch: 7500, loss: 0.31339, accu: 0.97401, speed: 0.86 step/s\n",
      "global step 7510, epoch: 1, batch: 7510, loss: 0.36325, accu: 0.97401, speed: 0.86 step/s\n",
      "global step 7520, epoch: 1, batch: 7520, loss: 0.39074, accu: 0.97403, speed: 0.86 step/s\n",
      "global step 7530, epoch: 1, batch: 7530, loss: 0.31326, accu: 0.97404, speed: 0.86 step/s\n",
      "global step 7540, epoch: 1, batch: 7540, loss: 0.31327, accu: 0.97406, speed: 0.86 step/s\n",
      "global step 7550, epoch: 1, batch: 7550, loss: 0.36327, accu: 0.97408, speed: 0.86 step/s\n",
      "global step 7560, epoch: 1, batch: 7560, loss: 0.33664, accu: 0.97409, speed: 0.86 step/s\n",
      "global step 7570, epoch: 1, batch: 7570, loss: 0.31336, accu: 0.97412, speed: 0.86 step/s\n",
      "global step 7580, epoch: 1, batch: 7580, loss: 0.31327, accu: 0.97414, speed: 0.86 step/s\n",
      "global step 7590, epoch: 1, batch: 7590, loss: 0.31334, accu: 0.97414, speed: 0.86 step/s\n",
      "global step 7600, epoch: 1, batch: 7600, loss: 0.33827, accu: 0.97415, speed: 0.86 step/s\n",
      "global step 7610, epoch: 1, batch: 7610, loss: 0.31327, accu: 0.97417, speed: 0.86 step/s\n",
      "global step 7620, epoch: 1, batch: 7620, loss: 0.31326, accu: 0.97418, speed: 0.86 step/s\n",
      "global step 7630, epoch: 1, batch: 7630, loss: 0.31327, accu: 0.97421, speed: 0.86 step/s\n",
      "global step 7640, epoch: 1, batch: 7640, loss: 0.31839, accu: 0.97423, speed: 0.86 step/s\n",
      "global step 7650, epoch: 1, batch: 7650, loss: 0.33828, accu: 0.97424, speed: 0.86 step/s\n",
      "global step 7660, epoch: 1, batch: 7660, loss: 0.36288, accu: 0.97425, speed: 0.86 step/s\n",
      "global step 7670, epoch: 1, batch: 7670, loss: 0.31326, accu: 0.97427, speed: 0.86 step/s\n",
      "global step 7680, epoch: 1, batch: 7680, loss: 0.33708, accu: 0.97427, speed: 0.86 step/s\n",
      "global step 7690, epoch: 1, batch: 7690, loss: 0.33827, accu: 0.97430, speed: 0.86 step/s\n",
      "global step 7700, epoch: 1, batch: 7700, loss: 0.36304, accu: 0.97431, speed: 0.86 step/s\n",
      "global step 7710, epoch: 1, batch: 7710, loss: 0.36325, accu: 0.97431, speed: 0.86 step/s\n",
      "global step 7720, epoch: 1, batch: 7720, loss: 0.31327, accu: 0.97433, speed: 0.86 step/s\n",
      "global step 7730, epoch: 1, batch: 7730, loss: 0.31327, accu: 0.97435, speed: 0.86 step/s\n",
      "global step 7740, epoch: 1, batch: 7740, loss: 0.36324, accu: 0.97436, speed: 0.86 step/s\n",
      "global step 7750, epoch: 1, batch: 7750, loss: 0.33838, accu: 0.97436, speed: 0.86 step/s\n",
      "global step 7760, epoch: 1, batch: 7760, loss: 0.33854, accu: 0.97437, speed: 0.86 step/s\n",
      "global step 7770, epoch: 1, batch: 7770, loss: 0.31327, accu: 0.97438, speed: 0.86 step/s\n",
      "global step 7780, epoch: 1, batch: 7780, loss: 0.31643, accu: 0.97439, speed: 0.86 step/s\n",
      "global step 7790, epoch: 1, batch: 7790, loss: 0.33493, accu: 0.97441, speed: 0.86 step/s\n",
      "global step 7800, epoch: 1, batch: 7800, loss: 0.31360, accu: 0.97442, speed: 0.86 step/s\n",
      "global step 7810, epoch: 1, batch: 7810, loss: 0.31328, accu: 0.97443, speed: 0.86 step/s\n",
      "global step 7820, epoch: 1, batch: 7820, loss: 0.31326, accu: 0.97444, speed: 0.86 step/s\n",
      "global step 7830, epoch: 1, batch: 7830, loss: 0.31329, accu: 0.97446, speed: 0.86 step/s\n",
      "global step 7840, epoch: 1, batch: 7840, loss: 0.31327, accu: 0.97448, speed: 0.86 step/s\n",
      "global step 7850, epoch: 1, batch: 7850, loss: 0.31471, accu: 0.97450, speed: 0.86 step/s\n",
      "global step 7860, epoch: 1, batch: 7860, loss: 0.33352, accu: 0.97452, speed: 0.86 step/s\n",
      "global step 7870, epoch: 1, batch: 7870, loss: 0.31851, accu: 0.97454, speed: 0.86 step/s\n",
      "global step 7880, epoch: 1, batch: 7880, loss: 0.31327, accu: 0.97455, speed: 0.86 step/s\n",
      "global step 7890, epoch: 1, batch: 7890, loss: 0.31326, accu: 0.97456, speed: 0.86 step/s\n",
      "global step 7900, epoch: 1, batch: 7900, loss: 0.33827, accu: 0.97458, speed: 0.86 step/s\n",
      "global step 7910, epoch: 1, batch: 7910, loss: 0.31327, accu: 0.97460, speed: 0.86 step/s\n",
      "global step 7920, epoch: 1, batch: 7920, loss: 0.31384, accu: 0.97461, speed: 0.86 step/s\n",
      "global step 7930, epoch: 1, batch: 7930, loss: 0.38821, accu: 0.97461, speed: 0.86 step/s\n",
      "global step 7940, epoch: 1, batch: 7940, loss: 0.31328, accu: 0.97463, speed: 0.86 step/s\n",
      "global step 7950, epoch: 1, batch: 7950, loss: 0.36317, accu: 0.97464, speed: 0.86 step/s\n",
      "global step 7960, epoch: 1, batch: 7960, loss: 0.33827, accu: 0.97465, speed: 0.86 step/s\n",
      "global step 7970, epoch: 1, batch: 7970, loss: 0.33826, accu: 0.97467, speed: 0.86 step/s\n",
      "global step 7980, epoch: 1, batch: 7980, loss: 0.31326, accu: 0.97469, speed: 0.86 step/s\n",
      "global step 7990, epoch: 1, batch: 7990, loss: 0.31326, accu: 0.97470, speed: 0.86 step/s\n",
      "global step 8000, epoch: 1, batch: 8000, loss: 0.33802, accu: 0.97471, speed: 0.86 step/s\n",
      "global step 8010, epoch: 1, batch: 8010, loss: 0.31326, accu: 0.97472, speed: 0.86 step/s\n",
      "global step 8020, epoch: 1, batch: 8020, loss: 0.31333, accu: 0.97474, speed: 0.86 step/s\n",
      "global step 8030, epoch: 1, batch: 8030, loss: 0.31327, accu: 0.97475, speed: 0.86 step/s\n",
      "global step 8040, epoch: 1, batch: 8040, loss: 0.31371, accu: 0.97477, speed: 0.86 step/s\n",
      "global step 8050, epoch: 1, batch: 8050, loss: 0.31327, accu: 0.97479, speed: 0.86 step/s\n",
      "global step 8060, epoch: 1, batch: 8060, loss: 0.33739, accu: 0.97480, speed: 0.86 step/s\n",
      "global step 8070, epoch: 1, batch: 8070, loss: 0.31414, accu: 0.97483, speed: 0.86 step/s\n",
      "global step 8080, epoch: 1, batch: 8080, loss: 0.31411, accu: 0.97485, speed: 0.86 step/s\n",
      "global step 8090, epoch: 1, batch: 8090, loss: 0.31326, accu: 0.97486, speed: 0.86 step/s\n",
      "global step 8100, epoch: 1, batch: 8100, loss: 0.31326, accu: 0.97487, speed: 0.86 step/s\n",
      "global step 8110, epoch: 1, batch: 8110, loss: 0.33828, accu: 0.97489, speed: 0.86 step/s\n",
      "global step 8120, epoch: 1, batch: 8120, loss: 0.31399, accu: 0.97489, speed: 0.86 step/s\n",
      "global step 8130, epoch: 1, batch: 8130, loss: 0.33885, accu: 0.97491, speed: 0.86 step/s\n",
      "global step 8140, epoch: 1, batch: 8140, loss: 0.31464, accu: 0.97494, speed: 0.86 step/s\n",
      "global step 8150, epoch: 1, batch: 8150, loss: 0.37669, accu: 0.97494, speed: 0.86 step/s\n",
      "global step 8160, epoch: 1, batch: 8160, loss: 0.31327, accu: 0.97494, speed: 0.86 step/s\n",
      "global step 8170, epoch: 1, batch: 8170, loss: 0.33826, accu: 0.97496, speed: 0.86 step/s\n",
      "global step 8180, epoch: 1, batch: 8180, loss: 0.31327, accu: 0.97497, speed: 0.86 step/s\n",
      "global step 8190, epoch: 1, batch: 8190, loss: 0.31327, accu: 0.97498, speed: 0.86 step/s\n",
      "global step 8200, epoch: 1, batch: 8200, loss: 0.31341, accu: 0.97499, speed: 0.86 step/s\n",
      "global step 8210, epoch: 1, batch: 8210, loss: 0.31327, accu: 0.97499, speed: 0.86 step/s\n",
      "global step 8220, epoch: 1, batch: 8220, loss: 0.35670, accu: 0.97499, speed: 0.86 step/s\n",
      "global step 8230, epoch: 1, batch: 8230, loss: 0.31330, accu: 0.97501, speed: 0.86 step/s\n",
      "global step 8240, epoch: 1, batch: 8240, loss: 0.31326, accu: 0.97502, speed: 0.86 step/s\n",
      "global step 8250, epoch: 1, batch: 8250, loss: 0.33752, accu: 0.97503, speed: 0.86 step/s\n",
      "global step 8260, epoch: 1, batch: 8260, loss: 0.33826, accu: 0.97503, speed: 0.86 step/s\n",
      "global step 8270, epoch: 1, batch: 8270, loss: 0.33833, accu: 0.97504, speed: 0.86 step/s\n",
      "global step 8280, epoch: 1, batch: 8280, loss: 0.36326, accu: 0.97505, speed: 0.86 step/s\n",
      "global step 8290, epoch: 1, batch: 8290, loss: 0.36394, accu: 0.97506, speed: 0.86 step/s\n",
      "global step 8300, epoch: 1, batch: 8300, loss: 0.33829, accu: 0.97507, speed: 0.86 step/s\n",
      "global step 8310, epoch: 1, batch: 8310, loss: 0.33852, accu: 0.97508, speed: 0.86 step/s\n",
      "global step 8320, epoch: 1, batch: 8320, loss: 0.33837, accu: 0.97509, speed: 0.86 step/s\n",
      "global step 8330, epoch: 1, batch: 8330, loss: 0.31326, accu: 0.97508, speed: 0.86 step/s\n",
      "global step 8340, epoch: 1, batch: 8340, loss: 0.31326, accu: 0.97509, speed: 0.86 step/s\n",
      "global step 8350, epoch: 1, batch: 8350, loss: 0.31330, accu: 0.97510, speed: 0.86 step/s\n",
      "global step 8360, epoch: 1, batch: 8360, loss: 0.33826, accu: 0.97512, speed: 0.86 step/s\n",
      "global step 8370, epoch: 1, batch: 8370, loss: 0.31328, accu: 0.97514, speed: 0.86 step/s\n",
      "global step 8380, epoch: 1, batch: 8380, loss: 0.33826, accu: 0.97514, speed: 0.86 step/s\n",
      "global step 8390, epoch: 1, batch: 8390, loss: 0.31327, accu: 0.97515, speed: 0.86 step/s\n",
      "global step 8400, epoch: 1, batch: 8400, loss: 0.31465, accu: 0.97518, speed: 0.86 step/s\n",
      "global step 8410, epoch: 1, batch: 8410, loss: 0.31326, accu: 0.97520, speed: 0.86 step/s\n",
      "global step 8420, epoch: 1, batch: 8420, loss: 0.31327, accu: 0.97522, speed: 0.86 step/s\n",
      "global step 8430, epoch: 1, batch: 8430, loss: 0.31402, accu: 0.97524, speed: 0.86 step/s\n",
      "global step 8440, epoch: 1, batch: 8440, loss: 0.31327, accu: 0.97525, speed: 0.86 step/s\n",
      "global step 8450, epoch: 1, batch: 8450, loss: 0.31326, accu: 0.97528, speed: 0.86 step/s\n",
      "global step 8460, epoch: 1, batch: 8460, loss: 0.36327, accu: 0.97528, speed: 0.86 step/s\n",
      "global step 8470, epoch: 1, batch: 8470, loss: 0.38826, accu: 0.97529, speed: 0.86 step/s\n",
      "global step 8480, epoch: 1, batch: 8480, loss: 0.31326, accu: 0.97531, speed: 0.86 step/s\n",
      "global step 8490, epoch: 1, batch: 8490, loss: 0.31624, accu: 0.97533, speed: 0.86 step/s\n",
      "global step 8500, epoch: 1, batch: 8500, loss: 0.31326, accu: 0.97534, speed: 0.86 step/s\n",
      "global step 8510, epoch: 1, batch: 8510, loss: 0.31326, accu: 0.97536, speed: 0.86 step/s\n",
      "global step 8520, epoch: 1, batch: 8520, loss: 0.33806, accu: 0.97537, speed: 0.86 step/s\n",
      "global step 8530, epoch: 1, batch: 8530, loss: 0.31326, accu: 0.97537, speed: 0.86 step/s\n",
      "global step 8540, epoch: 1, batch: 8540, loss: 0.33825, accu: 0.97537, speed: 0.86 step/s\n",
      "global step 8550, epoch: 1, batch: 8550, loss: 0.31326, accu: 0.97538, speed: 0.86 step/s\n",
      "global step 8560, epoch: 1, batch: 8560, loss: 0.31327, accu: 0.97539, speed: 0.86 step/s\n",
      "global step 8570, epoch: 1, batch: 8570, loss: 0.31327, accu: 0.97541, speed: 0.86 step/s\n",
      "global step 8580, epoch: 1, batch: 8580, loss: 0.33334, accu: 0.97542, speed: 0.86 step/s\n",
      "global step 8590, epoch: 1, batch: 8590, loss: 0.31386, accu: 0.97544, speed: 0.86 step/s\n",
      "global step 8600, epoch: 1, batch: 8600, loss: 0.31328, accu: 0.97545, speed: 0.86 step/s\n",
      "global step 8610, epoch: 1, batch: 8610, loss: 0.33826, accu: 0.97546, speed: 0.86 step/s\n",
      "global step 8620, epoch: 1, batch: 8620, loss: 0.31326, accu: 0.97548, speed: 0.86 step/s\n",
      "global step 8630, epoch: 1, batch: 8630, loss: 0.31332, accu: 0.97550, speed: 0.86 step/s\n",
      "global step 8640, epoch: 1, batch: 8640, loss: 0.31340, accu: 0.97552, speed: 0.86 step/s\n",
      "global step 8650, epoch: 1, batch: 8650, loss: 0.33827, accu: 0.97554, speed: 0.86 step/s\n",
      "global step 8660, epoch: 1, batch: 8660, loss: 0.31326, accu: 0.97555, speed: 0.86 step/s\n",
      "global step 8670, epoch: 1, batch: 8670, loss: 0.33863, accu: 0.97557, speed: 0.86 step/s\n",
      "global step 8680, epoch: 1, batch: 8680, loss: 0.36326, accu: 0.97557, speed: 0.86 step/s\n",
      "global step 8690, epoch: 1, batch: 8690, loss: 0.33826, accu: 0.97558, speed: 0.86 step/s\n",
      "global step 8700, epoch: 1, batch: 8700, loss: 0.31326, accu: 0.97559, speed: 0.86 step/s\n",
      "global step 8710, epoch: 1, batch: 8710, loss: 0.31557, accu: 0.97561, speed: 0.86 step/s\n",
      "global step 8720, epoch: 1, batch: 8720, loss: 0.36325, accu: 0.97562, speed: 0.86 step/s\n",
      "global step 8730, epoch: 1, batch: 8730, loss: 0.31326, accu: 0.97563, speed: 0.86 step/s\n",
      "global step 8740, epoch: 1, batch: 8740, loss: 0.31326, accu: 0.97565, speed: 0.86 step/s\n",
      "global step 8750, epoch: 1, batch: 8750, loss: 0.33837, accu: 0.97566, speed: 0.86 step/s\n",
      "global step 8760, epoch: 1, batch: 8760, loss: 0.31326, accu: 0.97566, speed: 0.86 step/s\n",
      "global step 8770, epoch: 1, batch: 8770, loss: 0.31327, accu: 0.97568, speed: 0.86 step/s\n",
      "global step 8780, epoch: 1, batch: 8780, loss: 0.33826, accu: 0.97568, speed: 0.86 step/s\n",
      "global step 8790, epoch: 1, batch: 8790, loss: 0.31327, accu: 0.97570, speed: 0.86 step/s\n",
      "global step 8800, epoch: 1, batch: 8800, loss: 0.31326, accu: 0.97570, speed: 0.86 step/s\n",
      "global step 8810, epoch: 1, batch: 8810, loss: 0.31343, accu: 0.97569, speed: 0.86 step/s\n",
      "global step 8820, epoch: 1, batch: 8820, loss: 0.31327, accu: 0.97570, speed: 0.86 step/s\n",
      "global step 8830, epoch: 1, batch: 8830, loss: 0.33826, accu: 0.97570, speed: 0.86 step/s\n",
      "global step 8840, epoch: 1, batch: 8840, loss: 0.33826, accu: 0.97570, speed: 0.86 step/s\n",
      "global step 8850, epoch: 1, batch: 8850, loss: 0.36326, accu: 0.97570, speed: 0.86 step/s\n",
      "global step 8860, epoch: 1, batch: 8860, loss: 0.36250, accu: 0.97571, speed: 0.86 step/s\n",
      "global step 8870, epoch: 1, batch: 8870, loss: 0.31326, accu: 0.97572, speed: 0.86 step/s\n",
      "global step 8880, epoch: 1, batch: 8880, loss: 0.31326, accu: 0.97574, speed: 0.86 step/s\n",
      "global step 8890, epoch: 1, batch: 8890, loss: 0.31326, accu: 0.97576, speed: 0.86 step/s\n",
      "global step 8900, epoch: 1, batch: 8900, loss: 0.31327, accu: 0.97577, speed: 0.86 step/s\n",
      "global step 8910, epoch: 1, batch: 8910, loss: 0.31327, accu: 0.97578, speed: 0.86 step/s\n",
      "global step 8920, epoch: 1, batch: 8920, loss: 0.31327, accu: 0.97579, speed: 0.86 step/s\n",
      "global step 8930, epoch: 1, batch: 8930, loss: 0.31667, accu: 0.97581, speed: 0.86 step/s\n",
      "global step 8940, epoch: 1, batch: 8940, loss: 0.31327, accu: 0.97583, speed: 0.86 step/s\n",
      "global step 8950, epoch: 1, batch: 8950, loss: 0.31327, accu: 0.97585, speed: 0.86 step/s\n",
      "global step 8960, epoch: 1, batch: 8960, loss: 0.33826, accu: 0.97585, speed: 0.86 step/s\n",
      "global step 8970, epoch: 1, batch: 8970, loss: 0.31326, accu: 0.97587, speed: 0.86 step/s\n",
      "global step 8980, epoch: 1, batch: 8980, loss: 0.31326, accu: 0.97589, speed: 0.86 step/s\n",
      "global step 8990, epoch: 1, batch: 8990, loss: 0.31326, accu: 0.97590, speed: 0.86 step/s\n",
      "global step 9000, epoch: 1, batch: 9000, loss: 0.33826, accu: 0.97591, speed: 0.86 step/s\n",
      "global step 9010, epoch: 1, batch: 9010, loss: 0.31327, accu: 0.97592, speed: 0.86 step/s\n",
      "global step 9020, epoch: 1, batch: 9020, loss: 0.31329, accu: 0.97593, speed: 0.86 step/s\n",
      "global step 9030, epoch: 1, batch: 9030, loss: 0.31326, accu: 0.97595, speed: 0.86 step/s\n",
      "global step 9040, epoch: 1, batch: 9040, loss: 0.31446, accu: 0.97597, speed: 0.86 step/s\n",
      "global step 9050, epoch: 1, batch: 9050, loss: 0.31327, accu: 0.97599, speed: 0.86 step/s\n",
      "global step 9060, epoch: 1, batch: 9060, loss: 0.33795, accu: 0.97601, speed: 0.86 step/s\n",
      "global step 9070, epoch: 1, batch: 9070, loss: 0.33828, accu: 0.97602, speed: 0.86 step/s\n",
      "global step 9080, epoch: 1, batch: 9080, loss: 0.33827, accu: 0.97603, speed: 0.86 step/s\n",
      "global step 9090, epoch: 1, batch: 9090, loss: 0.31326, accu: 0.97605, speed: 0.86 step/s\n",
      "global step 9100, epoch: 1, batch: 9100, loss: 0.31326, accu: 0.97607, speed: 0.86 step/s\n",
      "global step 9110, epoch: 1, batch: 9110, loss: 0.31326, accu: 0.97608, speed: 0.86 step/s\n",
      "global step 9120, epoch: 1, batch: 9120, loss: 0.31326, accu: 0.97609, speed: 0.86 step/s\n",
      "global step 9130, epoch: 1, batch: 9130, loss: 0.31326, accu: 0.97611, speed: 0.86 step/s\n",
      "global step 9140, epoch: 1, batch: 9140, loss: 0.33827, accu: 0.97612, speed: 0.86 step/s\n",
      "global step 9150, epoch: 1, batch: 9150, loss: 0.31360, accu: 0.97613, speed: 0.86 step/s\n",
      "global step 9160, epoch: 1, batch: 9160, loss: 0.31327, accu: 0.97615, speed: 0.86 step/s\n",
      "global step 9170, epoch: 1, batch: 9170, loss: 0.33826, accu: 0.97615, speed: 0.86 step/s\n",
      "global step 9180, epoch: 1, batch: 9180, loss: 0.31733, accu: 0.97617, speed: 0.86 step/s\n",
      "global step 9190, epoch: 1, batch: 9190, loss: 0.34442, accu: 0.97618, speed: 0.86 step/s\n",
      "global step 9200, epoch: 1, batch: 9200, loss: 0.32124, accu: 0.97619, speed: 0.86 step/s\n",
      "global step 9210, epoch: 1, batch: 9210, loss: 0.33826, accu: 0.97620, speed: 0.86 step/s\n",
      "global step 9220, epoch: 1, batch: 9220, loss: 0.31327, accu: 0.97622, speed: 0.86 step/s\n",
      "global step 9230, epoch: 1, batch: 9230, loss: 0.31326, accu: 0.97624, speed: 0.86 step/s\n",
      "global step 9240, epoch: 1, batch: 9240, loss: 0.33709, accu: 0.97625, speed: 0.86 step/s\n",
      "global step 9250, epoch: 1, batch: 9250, loss: 0.33825, accu: 0.97627, speed: 0.86 step/s\n",
      "global step 9260, epoch: 1, batch: 9260, loss: 0.31327, accu: 0.97628, speed: 0.86 step/s\n",
      "global step 9270, epoch: 1, batch: 9270, loss: 0.31326, accu: 0.97630, speed: 0.86 step/s\n",
      "global step 9280, epoch: 1, batch: 9280, loss: 0.31327, accu: 0.97631, speed: 0.86 step/s\n",
      "global step 9290, epoch: 1, batch: 9290, loss: 0.31326, accu: 0.97632, speed: 0.86 step/s\n",
      "global step 9300, epoch: 1, batch: 9300, loss: 0.33827, accu: 0.97633, speed: 0.86 step/s\n",
      "global step 9310, epoch: 1, batch: 9310, loss: 0.33349, accu: 0.97633, speed: 0.86 step/s\n",
      "global step 9320, epoch: 1, batch: 9320, loss: 0.33837, accu: 0.97635, speed: 0.86 step/s\n",
      "global step 9330, epoch: 1, batch: 9330, loss: 0.31327, accu: 0.97636, speed: 0.86 step/s\n",
      "global step 9340, epoch: 1, batch: 9340, loss: 0.31326, accu: 0.97638, speed: 0.86 step/s\n",
      "global step 9350, epoch: 1, batch: 9350, loss: 0.31327, accu: 0.97639, speed: 0.86 step/s\n",
      "global step 9360, epoch: 1, batch: 9360, loss: 0.31326, accu: 0.97640, speed: 0.86 step/s\n",
      "global step 9370, epoch: 1, batch: 9370, loss: 0.31326, accu: 0.97640, speed: 0.86 step/s\n",
      "global step 9380, epoch: 1, batch: 9380, loss: 0.33827, accu: 0.97641, speed: 0.86 step/s\n",
      "global step 9390, epoch: 1, batch: 9390, loss: 0.38834, accu: 0.97642, speed: 0.86 step/s\n",
      "global step 9400, epoch: 1, batch: 9400, loss: 0.33834, accu: 0.97642, speed: 0.86 step/s\n",
      "global step 9410, epoch: 1, batch: 9410, loss: 0.31326, accu: 0.97643, speed: 0.86 step/s\n",
      "global step 9420, epoch: 1, batch: 9420, loss: 0.31326, accu: 0.97644, speed: 0.86 step/s\n",
      "global step 9430, epoch: 1, batch: 9430, loss: 0.31438, accu: 0.97646, speed: 0.86 step/s\n",
      "global step 9440, epoch: 1, batch: 9440, loss: 0.31329, accu: 0.97648, speed: 0.86 step/s\n",
      "global step 9450, epoch: 1, batch: 9450, loss: 0.31327, accu: 0.97649, speed: 0.86 step/s\n",
      "global step 9460, epoch: 1, batch: 9460, loss: 0.36074, accu: 0.97651, speed: 0.86 step/s\n",
      "global step 9470, epoch: 1, batch: 9470, loss: 0.31326, accu: 0.97653, speed: 0.86 step/s\n",
      "global step 9480, epoch: 1, batch: 9480, loss: 0.36327, accu: 0.97653, speed: 0.86 step/s\n",
      "global step 9490, epoch: 1, batch: 9490, loss: 0.31326, accu: 0.97655, speed: 0.86 step/s\n",
      "global step 9500, epoch: 1, batch: 9500, loss: 0.33827, accu: 0.97657, speed: 0.86 step/s\n",
      "global step 9510, epoch: 1, batch: 9510, loss: 0.31338, accu: 0.97659, speed: 0.86 step/s\n",
      "global step 9520, epoch: 1, batch: 9520, loss: 0.31383, accu: 0.97660, speed: 0.86 step/s\n",
      "global step 9530, epoch: 1, batch: 9530, loss: 0.31327, accu: 0.97662, speed: 0.86 step/s\n",
      "global step 9540, epoch: 1, batch: 9540, loss: 0.31326, accu: 0.97663, speed: 0.86 step/s\n",
      "global step 9550, epoch: 1, batch: 9550, loss: 0.31326, accu: 0.97665, speed: 0.86 step/s\n",
      "global step 9560, epoch: 1, batch: 9560, loss: 0.31327, accu: 0.97666, speed: 0.86 step/s\n",
      "global step 9570, epoch: 1, batch: 9570, loss: 0.31326, accu: 0.97666, speed: 0.86 step/s\n",
      "global step 9580, epoch: 1, batch: 9580, loss: 0.31329, accu: 0.97667, speed: 0.86 step/s\n",
      "global step 9590, epoch: 1, batch: 9590, loss: 0.31326, accu: 0.97668, speed: 0.86 step/s\n",
      "global step 9600, epoch: 1, batch: 9600, loss: 0.31340, accu: 0.97670, speed: 0.86 step/s\n",
      "global step 9610, epoch: 1, batch: 9610, loss: 0.33882, accu: 0.97671, speed: 0.86 step/s\n",
      "global step 9620, epoch: 1, batch: 9620, loss: 0.31327, accu: 0.97674, speed: 0.86 step/s\n",
      "global step 9630, epoch: 1, batch: 9630, loss: 0.33790, accu: 0.97675, speed: 0.86 step/s\n",
      "global step 9640, epoch: 1, batch: 9640, loss: 0.33826, accu: 0.97676, speed: 0.86 step/s\n",
      "global step 9650, epoch: 1, batch: 9650, loss: 0.31326, accu: 0.97678, speed: 0.86 step/s\n",
      "global step 9660, epoch: 1, batch: 9660, loss: 0.31359, accu: 0.97678, speed: 0.86 step/s\n",
      "global step 9670, epoch: 1, batch: 9670, loss: 0.33826, accu: 0.97679, speed: 0.86 step/s\n",
      "global step 9680, epoch: 1, batch: 9680, loss: 0.33826, accu: 0.97681, speed: 0.86 step/s\n",
      "global step 9690, epoch: 1, batch: 9690, loss: 0.33826, accu: 0.97682, speed: 0.86 step/s\n",
      "global step 9700, epoch: 1, batch: 9700, loss: 0.31327, accu: 0.97682, speed: 0.86 step/s\n",
      "global step 9710, epoch: 1, batch: 9710, loss: 0.33827, accu: 0.97682, speed: 0.86 step/s\n",
      "global step 9720, epoch: 1, batch: 9720, loss: 0.31326, accu: 0.97684, speed: 0.86 step/s\n",
      "global step 9730, epoch: 1, batch: 9730, loss: 0.33826, accu: 0.97685, speed: 0.86 step/s\n",
      "global step 9740, epoch: 1, batch: 9740, loss: 0.33826, accu: 0.97686, speed: 0.86 step/s\n",
      "global step 9750, epoch: 1, batch: 9750, loss: 0.33879, accu: 0.97687, speed: 0.86 step/s\n",
      "global step 9760, epoch: 1, batch: 9760, loss: 0.31437, accu: 0.97689, speed: 0.86 step/s\n",
      "global step 9770, epoch: 1, batch: 9770, loss: 0.31326, accu: 0.97689, speed: 0.86 step/s\n",
      "global step 9780, epoch: 1, batch: 9780, loss: 0.31327, accu: 0.97690, speed: 0.86 step/s\n",
      "global step 9790, epoch: 1, batch: 9790, loss: 0.33826, accu: 0.97692, speed: 0.86 step/s\n",
      "global step 9800, epoch: 1, batch: 9800, loss: 0.33826, accu: 0.97693, speed: 0.86 step/s\n",
      "global step 9810, epoch: 1, batch: 9810, loss: 0.31326, accu: 0.97694, speed: 0.86 step/s\n",
      "global step 9820, epoch: 1, batch: 9820, loss: 0.31327, accu: 0.97695, speed: 0.86 step/s\n",
      "global step 9830, epoch: 1, batch: 9830, loss: 0.33826, accu: 0.97696, speed: 0.86 step/s\n",
      "global step 9840, epoch: 1, batch: 9840, loss: 0.33587, accu: 0.97697, speed: 0.86 step/s\n",
      "global step 9850, epoch: 1, batch: 9850, loss: 0.35967, accu: 0.97698, speed: 0.86 step/s\n",
      "global step 9860, epoch: 1, batch: 9860, loss: 0.31326, accu: 0.97700, speed: 0.86 step/s\n",
      "global step 9870, epoch: 1, batch: 9870, loss: 0.35552, accu: 0.97701, speed: 0.86 step/s\n",
      "global step 9880, epoch: 1, batch: 9880, loss: 0.33805, accu: 0.97701, speed: 0.86 step/s\n",
      "global step 9890, epoch: 1, batch: 9890, loss: 0.34649, accu: 0.97702, speed: 0.86 step/s\n",
      "global step 9900, epoch: 1, batch: 9900, loss: 0.33827, accu: 0.97704, speed: 0.86 step/s\n",
      "global step 9910, epoch: 1, batch: 9910, loss: 0.33832, accu: 0.97704, speed: 0.86 step/s\n",
      "global step 9920, epoch: 1, batch: 9920, loss: 0.31326, accu: 0.97705, speed: 0.86 step/s\n",
      "global step 9930, epoch: 1, batch: 9930, loss: 0.31326, accu: 0.97706, speed: 0.86 step/s\n",
      "global step 9940, epoch: 1, batch: 9940, loss: 0.31326, accu: 0.97707, speed: 0.86 step/s\n",
      "global step 9950, epoch: 1, batch: 9950, loss: 0.31329, accu: 0.97709, speed: 0.86 step/s\n",
      "global step 9960, epoch: 1, batch: 9960, loss: 0.31326, accu: 0.97710, speed: 0.86 step/s\n",
      "global step 9970, epoch: 1, batch: 9970, loss: 0.31326, accu: 0.97712, speed: 0.86 step/s\n",
      "global step 9980, epoch: 1, batch: 9980, loss: 0.33826, accu: 0.97712, speed: 0.86 step/s\n",
      "global step 9990, epoch: 1, batch: 9990, loss: 0.31346, accu: 0.97712, speed: 0.86 step/s\n",
      "global step 10000, epoch: 1, batch: 10000, loss: 0.33826, accu: 0.97713, speed: 0.86 step/s\n",
      "global step 10010, epoch: 1, batch: 10010, loss: 0.31326, accu: 0.97715, speed: 0.86 step/s\n",
      "global step 10020, epoch: 1, batch: 10020, loss: 0.31326, accu: 0.97717, speed: 0.86 step/s\n",
      "global step 10030, epoch: 1, batch: 10030, loss: 0.31329, accu: 0.97717, speed: 0.86 step/s\n",
      "global step 10040, epoch: 1, batch: 10040, loss: 0.33827, accu: 0.97717, speed: 0.86 step/s\n",
      "global step 10050, epoch: 1, batch: 10050, loss: 0.31331, accu: 0.97718, speed: 0.86 step/s\n",
      "global step 10060, epoch: 1, batch: 10060, loss: 0.31327, accu: 0.97719, speed: 0.86 step/s\n",
      "global step 10070, epoch: 1, batch: 10070, loss: 0.31327, accu: 0.97720, speed: 0.86 step/s\n",
      "global step 10080, epoch: 1, batch: 10080, loss: 0.36327, accu: 0.97720, speed: 0.86 step/s\n",
      "global step 10090, epoch: 1, batch: 10090, loss: 0.31327, accu: 0.97720, speed: 0.86 step/s\n",
      "global step 10100, epoch: 1, batch: 10100, loss: 0.31334, accu: 0.97721, speed: 0.86 step/s\n",
      "global step 10110, epoch: 1, batch: 10110, loss: 0.31333, accu: 0.97722, speed: 0.86 step/s\n",
      "global step 10120, epoch: 1, batch: 10120, loss: 0.33677, accu: 0.97722, speed: 0.86 step/s\n",
      "global step 10130, epoch: 1, batch: 10130, loss: 0.33828, accu: 0.97722, speed: 0.86 step/s\n",
      "global step 10140, epoch: 1, batch: 10140, loss: 0.31329, accu: 0.97724, speed: 0.86 step/s\n",
      "global step 10150, epoch: 1, batch: 10150, loss: 0.33827, accu: 0.97723, speed: 0.86 step/s\n",
      "global step 10160, epoch: 1, batch: 10160, loss: 0.33903, accu: 0.97724, speed: 0.86 step/s\n",
      "global step 10170, epoch: 1, batch: 10170, loss: 0.31327, accu: 0.97725, speed: 0.86 step/s\n",
      "global step 10180, epoch: 1, batch: 10180, loss: 0.31326, accu: 0.97726, speed: 0.86 step/s\n",
      "global step 10190, epoch: 1, batch: 10190, loss: 0.31326, accu: 0.97727, speed: 0.86 step/s\n",
      "global step 10200, epoch: 1, batch: 10200, loss: 0.33827, accu: 0.97727, speed: 0.86 step/s\n",
      "global step 10210, epoch: 1, batch: 10210, loss: 0.31332, accu: 0.97729, speed: 0.86 step/s\n",
      "global step 10220, epoch: 1, batch: 10220, loss: 0.31327, accu: 0.97730, speed: 0.86 step/s\n",
      "global step 10230, epoch: 1, batch: 10230, loss: 0.33828, accu: 0.97731, speed: 0.86 step/s\n",
      "global step 10240, epoch: 1, batch: 10240, loss: 0.33828, accu: 0.97731, speed: 0.86 step/s\n",
      "global step 10250, epoch: 1, batch: 10250, loss: 0.31327, accu: 0.97732, speed: 0.86 step/s\n",
      "global step 10260, epoch: 1, batch: 10260, loss: 0.33827, accu: 0.97734, speed: 0.86 step/s\n",
      "global step 10270, epoch: 1, batch: 10270, loss: 0.31326, accu: 0.97735, speed: 0.86 step/s\n",
      "global step 10280, epoch: 1, batch: 10280, loss: 0.33826, accu: 0.97736, speed: 0.86 step/s\n",
      "global step 10290, epoch: 1, batch: 10290, loss: 0.36326, accu: 0.97737, speed: 0.86 step/s\n",
      "global step 10300, epoch: 1, batch: 10300, loss: 0.31327, accu: 0.97737, speed: 0.86 step/s\n",
      "global step 10310, epoch: 1, batch: 10310, loss: 0.31326, accu: 0.97738, speed: 0.86 step/s\n",
      "global step 10320, epoch: 1, batch: 10320, loss: 0.33827, accu: 0.97739, speed: 0.86 step/s\n",
      "global step 10330, epoch: 1, batch: 10330, loss: 0.31326, accu: 0.97740, speed: 0.86 step/s\n",
      "global step 10340, epoch: 1, batch: 10340, loss: 0.33827, accu: 0.97741, speed: 0.86 step/s\n",
      "global step 10350, epoch: 1, batch: 10350, loss: 0.31326, accu: 0.97742, speed: 0.86 step/s\n",
      "global step 10360, epoch: 1, batch: 10360, loss: 0.31327, accu: 0.97743, speed: 0.86 step/s\n",
      "global step 10370, epoch: 1, batch: 10370, loss: 0.31326, accu: 0.97744, speed: 0.86 step/s\n",
      "global step 10380, epoch: 1, batch: 10380, loss: 0.31327, accu: 0.97745, speed: 0.86 step/s\n",
      "global step 10390, epoch: 1, batch: 10390, loss: 0.33879, accu: 0.97747, speed: 0.86 step/s\n",
      "global step 10400, epoch: 1, batch: 10400, loss: 0.31326, accu: 0.97748, speed: 0.86 step/s\n",
      "global step 10410, epoch: 1, batch: 10410, loss: 0.31329, accu: 0.97749, speed: 0.86 step/s\n",
      "global step 10420, epoch: 1, batch: 10420, loss: 0.31326, accu: 0.97751, speed: 0.86 step/s\n",
      "global step 10430, epoch: 1, batch: 10430, loss: 0.31326, accu: 0.97753, speed: 0.86 step/s\n",
      "global step 10440, epoch: 1, batch: 10440, loss: 0.31326, accu: 0.97752, speed: 0.86 step/s\n",
      "global step 10450, epoch: 1, batch: 10450, loss: 0.33831, accu: 0.97753, speed: 0.86 step/s\n",
      "global step 10460, epoch: 1, batch: 10460, loss: 0.33826, accu: 0.97754, speed: 0.86 step/s\n",
      "global step 10470, epoch: 1, batch: 10470, loss: 0.31326, accu: 0.97755, speed: 0.86 step/s\n",
      "global step 10480, epoch: 1, batch: 10480, loss: 0.31333, accu: 0.97756, speed: 0.86 step/s\n",
      "global step 10490, epoch: 1, batch: 10490, loss: 0.31417, accu: 0.97757, speed: 0.86 step/s\n",
      "global step 10500, epoch: 1, batch: 10500, loss: 0.31327, accu: 0.97758, speed: 0.86 step/s\n",
      "global step 10510, epoch: 1, batch: 10510, loss: 0.31945, accu: 0.97756, speed: 0.86 step/s\n",
      "global step 10520, epoch: 1, batch: 10520, loss: 0.31329, accu: 0.97758, speed: 0.86 step/s\n",
      "global step 10530, epoch: 1, batch: 10530, loss: 0.31327, accu: 0.97759, speed: 0.86 step/s\n",
      "global step 10540, epoch: 1, batch: 10540, loss: 0.31326, accu: 0.97760, speed: 0.86 step/s\n",
      "global step 10550, epoch: 1, batch: 10550, loss: 0.33826, accu: 0.97762, speed: 0.86 step/s\n",
      "global step 10560, epoch: 1, batch: 10560, loss: 0.33823, accu: 0.97762, speed: 0.86 step/s\n",
      "global step 10570, epoch: 1, batch: 10570, loss: 0.31333, accu: 0.97763, speed: 0.86 step/s\n",
      "global step 10580, epoch: 1, batch: 10580, loss: 0.31327, accu: 0.97764, speed: 0.86 step/s\n",
      "global step 10590, epoch: 1, batch: 10590, loss: 0.31326, accu: 0.97765, speed: 0.86 step/s\n",
      "global step 10600, epoch: 1, batch: 10600, loss: 0.33608, accu: 0.97767, speed: 0.86 step/s\n",
      "global step 10610, epoch: 1, batch: 10610, loss: 0.31326, accu: 0.97768, speed: 0.86 step/s\n",
      "global step 10620, epoch: 1, batch: 10620, loss: 0.33178, accu: 0.97769, speed: 0.86 step/s\n",
      "global step 10630, epoch: 1, batch: 10630, loss: 0.31327, accu: 0.97770, speed: 0.86 step/s\n",
      "global step 10640, epoch: 1, batch: 10640, loss: 0.31326, accu: 0.97771, speed: 0.86 step/s\n",
      "global step 10650, epoch: 1, batch: 10650, loss: 0.31326, accu: 0.97772, speed: 0.86 step/s\n",
      "global step 10660, epoch: 1, batch: 10660, loss: 0.31854, accu: 0.97773, speed: 0.86 step/s\n",
      "global step 10670, epoch: 1, batch: 10670, loss: 0.33829, accu: 0.97773, speed: 0.86 step/s\n",
      "global step 10680, epoch: 1, batch: 10680, loss: 0.31327, accu: 0.97775, speed: 0.86 step/s\n",
      "global step 10690, epoch: 1, batch: 10690, loss: 0.33987, accu: 0.97776, speed: 0.86 step/s\n",
      "global step 10700, epoch: 1, batch: 10700, loss: 0.31326, accu: 0.97777, speed: 0.86 step/s\n",
      "global step 10710, epoch: 1, batch: 10710, loss: 0.31326, accu: 0.97778, speed: 0.86 step/s\n",
      "global step 10720, epoch: 1, batch: 10720, loss: 0.31326, accu: 0.97780, speed: 0.86 step/s\n",
      "global step 10730, epoch: 1, batch: 10730, loss: 0.31326, accu: 0.97781, speed: 0.87 step/s\n",
      "global step 10740, epoch: 1, batch: 10740, loss: 0.31326, accu: 0.97781, speed: 0.87 step/s\n",
      "global step 10750, epoch: 1, batch: 10750, loss: 0.31326, accu: 0.97783, speed: 0.87 step/s\n",
      "global step 10760, epoch: 1, batch: 10760, loss: 0.33826, accu: 0.97784, speed: 0.87 step/s\n",
      "global step 10770, epoch: 1, batch: 10770, loss: 0.31326, accu: 0.97786, speed: 0.87 step/s\n",
      "global step 10780, epoch: 1, batch: 10780, loss: 0.31343, accu: 0.97787, speed: 0.87 step/s\n",
      "global step 10790, epoch: 1, batch: 10790, loss: 0.33827, accu: 0.97788, speed: 0.87 step/s\n",
      "global step 10800, epoch: 1, batch: 10800, loss: 0.33826, accu: 0.97788, speed: 0.87 step/s\n",
      "global step 10810, epoch: 1, batch: 10810, loss: 0.31326, accu: 0.97788, speed: 0.87 step/s\n",
      "global step 10820, epoch: 1, batch: 10820, loss: 0.31329, accu: 0.97789, speed: 0.87 step/s\n",
      "global step 10830, epoch: 1, batch: 10830, loss: 0.31326, accu: 0.97790, speed: 0.87 step/s\n",
      "global step 10840, epoch: 1, batch: 10840, loss: 0.31335, accu: 0.97791, speed: 0.86 step/s\n",
      "global step 10850, epoch: 1, batch: 10850, loss: 0.32913, accu: 0.97792, speed: 0.87 step/s\n",
      "global step 10860, epoch: 1, batch: 10860, loss: 0.31327, accu: 0.97793, speed: 0.86 step/s\n",
      "global step 10870, epoch: 1, batch: 10870, loss: 0.31327, accu: 0.97795, speed: 0.86 step/s\n",
      "global step 10880, epoch: 1, batch: 10880, loss: 0.31342, accu: 0.97796, speed: 0.86 step/s\n",
      "global step 10890, epoch: 1, batch: 10890, loss: 0.31326, accu: 0.97797, speed: 0.86 step/s\n",
      "global step 10900, epoch: 1, batch: 10900, loss: 0.31326, accu: 0.97798, speed: 0.86 step/s\n",
      "global step 10910, epoch: 1, batch: 10910, loss: 0.31327, accu: 0.97799, speed: 0.86 step/s\n",
      "global step 10920, epoch: 1, batch: 10920, loss: 0.33826, accu: 0.97800, speed: 0.86 step/s\n",
      "global step 10930, epoch: 1, batch: 10930, loss: 0.31331, accu: 0.97802, speed: 0.86 step/s\n",
      "global step 10940, epoch: 1, batch: 10940, loss: 0.31326, accu: 0.97803, speed: 0.87 step/s\n",
      "global step 10950, epoch: 1, batch: 10950, loss: 0.31802, accu: 0.97804, speed: 0.86 step/s\n",
      "global step 10960, epoch: 1, batch: 10960, loss: 0.31327, accu: 0.97805, speed: 0.86 step/s\n",
      "global step 10970, epoch: 1, batch: 10970, loss: 0.31326, accu: 0.97806, speed: 0.87 step/s\n",
      "global step 10980, epoch: 1, batch: 10980, loss: 0.31326, accu: 0.97807, speed: 0.86 step/s\n",
      "global step 10990, epoch: 1, batch: 10990, loss: 0.31326, accu: 0.97808, speed: 0.86 step/s\n",
      "global step 11000, epoch: 1, batch: 11000, loss: 0.31327, accu: 0.97810, speed: 0.86 step/s\n",
      "global step 11010, epoch: 1, batch: 11010, loss: 0.31326, accu: 0.97811, speed: 0.86 step/s\n",
      "global step 11020, epoch: 1, batch: 11020, loss: 0.33826, accu: 0.97812, speed: 0.86 step/s\n",
      "global step 11030, epoch: 1, batch: 11030, loss: 0.33826, accu: 0.97813, speed: 0.86 step/s\n",
      "global step 11040, epoch: 1, batch: 11040, loss: 0.31327, accu: 0.97813, speed: 0.86 step/s\n",
      "global step 11050, epoch: 1, batch: 11050, loss: 0.33729, accu: 0.97814, speed: 0.86 step/s\n",
      "global step 11060, epoch: 1, batch: 11060, loss: 0.34897, accu: 0.97814, speed: 0.86 step/s\n",
      "global step 11070, epoch: 1, batch: 11070, loss: 0.33826, accu: 0.97814, speed: 0.86 step/s\n",
      "global step 11080, epoch: 1, batch: 11080, loss: 0.31326, accu: 0.97816, speed: 0.86 step/s\n",
      "global step 11090, epoch: 1, batch: 11090, loss: 0.36328, accu: 0.97817, speed: 0.86 step/s\n",
      "global step 11100, epoch: 1, batch: 11100, loss: 0.31326, accu: 0.97817, speed: 0.86 step/s\n",
      "global step 11110, epoch: 1, batch: 11110, loss: 0.31327, accu: 0.97818, speed: 0.86 step/s\n",
      "global step 11120, epoch: 1, batch: 11120, loss: 0.31326, accu: 0.97819, speed: 0.86 step/s\n",
      "global step 11130, epoch: 1, batch: 11130, loss: 0.31326, accu: 0.97820, speed: 0.86 step/s\n",
      "global step 11140, epoch: 1, batch: 11140, loss: 0.31364, accu: 0.97822, speed: 0.86 step/s\n",
      "global step 11150, epoch: 1, batch: 11150, loss: 0.33826, accu: 0.97823, speed: 0.86 step/s\n",
      "global step 11160, epoch: 1, batch: 11160, loss: 0.31326, accu: 0.97824, speed: 0.86 step/s\n",
      "global step 11170, epoch: 1, batch: 11170, loss: 0.33465, accu: 0.97826, speed: 0.86 step/s\n",
      "global step 11180, epoch: 1, batch: 11180, loss: 0.31329, accu: 0.97827, speed: 0.86 step/s\n",
      "global step 11190, epoch: 1, batch: 11190, loss: 0.31326, accu: 0.97828, speed: 0.86 step/s\n",
      "global step 11200, epoch: 1, batch: 11200, loss: 0.31329, accu: 0.97829, speed: 0.86 step/s\n",
      "global step 11210, epoch: 1, batch: 11210, loss: 0.31326, accu: 0.97831, speed: 0.86 step/s\n",
      "global step 11220, epoch: 1, batch: 11220, loss: 0.31326, accu: 0.97831, speed: 0.86 step/s\n",
      "global step 11230, epoch: 1, batch: 11230, loss: 0.31326, accu: 0.97833, speed: 0.86 step/s\n",
      "global step 11240, epoch: 1, batch: 11240, loss: 0.31352, accu: 0.97834, speed: 0.86 step/s\n",
      "global step 11250, epoch: 1, batch: 11250, loss: 0.33826, accu: 0.97835, speed: 0.86 step/s\n",
      "global step 11260, epoch: 1, batch: 11260, loss: 0.31327, accu: 0.97836, speed: 0.86 step/s\n",
      "global step 11270, epoch: 1, batch: 11270, loss: 0.31363, accu: 0.97838, speed: 0.86 step/s\n",
      "global step 11280, epoch: 1, batch: 11280, loss: 0.31326, accu: 0.97839, speed: 0.86 step/s\n",
      "global step 11290, epoch: 1, batch: 11290, loss: 0.31326, accu: 0.97840, speed: 0.86 step/s\n",
      "global step 11300, epoch: 1, batch: 11300, loss: 0.33830, accu: 0.97841, speed: 0.86 step/s\n",
      "global step 11310, epoch: 1, batch: 11310, loss: 0.33061, accu: 0.97842, speed: 0.86 step/s\n",
      "global step 11320, epoch: 1, batch: 11320, loss: 0.31328, accu: 0.97843, speed: 0.86 step/s\n",
      "global step 11330, epoch: 1, batch: 11330, loss: 0.31326, accu: 0.97845, speed: 0.86 step/s\n",
      "global step 11340, epoch: 1, batch: 11340, loss: 0.33749, accu: 0.97845, speed: 0.86 step/s\n",
      "global step 11350, epoch: 1, batch: 11350, loss: 0.31327, accu: 0.97846, speed: 0.87 step/s\n",
      "global step 11360, epoch: 1, batch: 11360, loss: 0.31326, accu: 0.97847, speed: 0.86 step/s\n",
      "global step 11370, epoch: 1, batch: 11370, loss: 0.31326, accu: 0.97848, speed: 0.86 step/s\n",
      "global step 11380, epoch: 1, batch: 11380, loss: 0.31734, accu: 0.97850, speed: 0.86 step/s\n",
      "global step 11390, epoch: 1, batch: 11390, loss: 0.33506, accu: 0.97850, speed: 0.86 step/s\n",
      "global step 11400, epoch: 1, batch: 11400, loss: 0.33864, accu: 0.97850, speed: 0.86 step/s\n",
      "global step 11410, epoch: 1, batch: 11410, loss: 0.33826, accu: 0.97851, speed: 0.86 step/s\n",
      "global step 11420, epoch: 1, batch: 11420, loss: 0.33905, accu: 0.97850, speed: 0.86 step/s\n",
      "global step 11430, epoch: 1, batch: 11430, loss: 0.31326, accu: 0.97852, speed: 0.86 step/s\n",
      "global step 11440, epoch: 1, batch: 11440, loss: 0.33827, accu: 0.97853, speed: 0.86 step/s\n",
      "global step 11450, epoch: 1, batch: 11450, loss: 0.31807, accu: 0.97853, speed: 0.86 step/s\n",
      "global step 11460, epoch: 1, batch: 11460, loss: 0.31326, accu: 0.97854, speed: 0.86 step/s\n",
      "global step 11470, epoch: 1, batch: 11470, loss: 0.33826, accu: 0.97854, speed: 0.86 step/s\n",
      "global step 11480, epoch: 1, batch: 11480, loss: 0.31326, accu: 0.97856, speed: 0.86 step/s\n",
      "global step 11490, epoch: 1, batch: 11490, loss: 0.33820, accu: 0.97857, speed: 0.86 step/s\n",
      "global step 11500, epoch: 1, batch: 11500, loss: 0.33830, accu: 0.97857, speed: 0.86 step/s\n",
      "global step 11510, epoch: 1, batch: 11510, loss: 0.31328, accu: 0.97858, speed: 0.86 step/s\n",
      "global step 11520, epoch: 1, batch: 11520, loss: 0.31327, accu: 0.97859, speed: 0.86 step/s\n",
      "global step 11530, epoch: 1, batch: 11530, loss: 0.33826, accu: 0.97860, speed: 0.86 step/s\n",
      "global step 11540, epoch: 1, batch: 11540, loss: 0.33826, accu: 0.97860, speed: 0.86 step/s\n",
      "global step 11550, epoch: 1, batch: 11550, loss: 0.31327, accu: 0.97861, speed: 0.86 step/s\n",
      "global step 11560, epoch: 1, batch: 11560, loss: 0.34970, accu: 0.97862, speed: 0.86 step/s\n",
      "global step 11570, epoch: 1, batch: 11570, loss: 0.33826, accu: 0.97863, speed: 0.86 step/s\n",
      "global step 11580, epoch: 1, batch: 11580, loss: 0.31328, accu: 0.97864, speed: 0.86 step/s\n",
      "global step 11590, epoch: 1, batch: 11590, loss: 0.31328, accu: 0.97865, speed: 0.86 step/s\n",
      "global step 11600, epoch: 1, batch: 11600, loss: 0.33826, accu: 0.97866, speed: 0.86 step/s\n",
      "global step 11610, epoch: 1, batch: 11610, loss: 0.36327, accu: 0.97867, speed: 0.86 step/s\n",
      "global step 11620, epoch: 1, batch: 11620, loss: 0.31327, accu: 0.97868, speed: 0.86 step/s\n",
      "global step 11630, epoch: 1, batch: 11630, loss: 0.31326, accu: 0.97868, speed: 0.86 step/s\n",
      "global step 11640, epoch: 1, batch: 11640, loss: 0.31327, accu: 0.97869, speed: 0.86 step/s\n",
      "global step 11650, epoch: 1, batch: 11650, loss: 0.31326, accu: 0.97870, speed: 0.86 step/s\n",
      "global step 11660, epoch: 1, batch: 11660, loss: 0.31327, accu: 0.97871, speed: 0.86 step/s\n",
      "global step 11670, epoch: 1, batch: 11670, loss: 0.33826, accu: 0.97872, speed: 0.86 step/s\n",
      "global step 11680, epoch: 1, batch: 11680, loss: 0.31327, accu: 0.97873, speed: 0.86 step/s\n",
      "global step 11690, epoch: 1, batch: 11690, loss: 0.33826, accu: 0.97874, speed: 0.86 step/s\n",
      "global step 11700, epoch: 1, batch: 11700, loss: 0.31343, accu: 0.97875, speed: 0.86 step/s\n",
      "global step 11710, epoch: 1, batch: 11710, loss: 0.31328, accu: 0.97876, speed: 0.86 step/s\n",
      "global step 11720, epoch: 1, batch: 11720, loss: 0.31326, accu: 0.97876, speed: 0.86 step/s\n",
      "global step 11730, epoch: 1, batch: 11730, loss: 0.33864, accu: 0.97877, speed: 0.86 step/s\n",
      "global step 11740, epoch: 1, batch: 11740, loss: 0.33826, accu: 0.97879, speed: 0.86 step/s\n",
      "global step 11750, epoch: 1, batch: 11750, loss: 0.31328, accu: 0.97880, speed: 0.86 step/s\n",
      "global step 11760, epoch: 1, batch: 11760, loss: 0.33826, accu: 0.97881, speed: 0.86 step/s\n",
      "global step 11770, epoch: 1, batch: 11770, loss: 0.31326, accu: 0.97882, speed: 0.86 step/s\n",
      "global step 11780, epoch: 1, batch: 11780, loss: 0.31331, accu: 0.97883, speed: 0.86 step/s\n",
      "global step 11790, epoch: 1, batch: 11790, loss: 0.31331, accu: 0.97884, speed: 0.87 step/s\n",
      "global step 11800, epoch: 1, batch: 11800, loss: 0.31326, accu: 0.97885, speed: 0.86 step/s\n",
      "global step 11810, epoch: 1, batch: 11810, loss: 0.31327, accu: 0.97886, speed: 0.86 step/s\n",
      "global step 11820, epoch: 1, batch: 11820, loss: 0.31326, accu: 0.97888, speed: 0.86 step/s\n",
      "global step 11830, epoch: 1, batch: 11830, loss: 0.31326, accu: 0.97888, speed: 0.86 step/s\n",
      "global step 11840, epoch: 1, batch: 11840, loss: 0.31326, accu: 0.97889, speed: 0.86 step/s\n",
      "global step 11850, epoch: 1, batch: 11850, loss: 0.31326, accu: 0.97889, speed: 0.86 step/s\n",
      "global step 11860, epoch: 1, batch: 11860, loss: 0.31327, accu: 0.97890, speed: 0.86 step/s\n",
      "global step 11870, epoch: 1, batch: 11870, loss: 0.31327, accu: 0.97892, speed: 0.86 step/s\n",
      "global step 11880, epoch: 1, batch: 11880, loss: 0.33827, accu: 0.97892, speed: 0.86 step/s\n",
      "global step 11890, epoch: 1, batch: 11890, loss: 0.31328, accu: 0.97893, speed: 0.86 step/s\n",
      "global step 11900, epoch: 1, batch: 11900, loss: 0.31327, accu: 0.97893, speed: 0.86 step/s\n",
      "global step 11910, epoch: 1, batch: 11910, loss: 0.32110, accu: 0.97894, speed: 0.86 step/s\n",
      "global step 11920, epoch: 1, batch: 11920, loss: 0.33826, accu: 0.97894, speed: 0.86 step/s\n",
      "global step 11930, epoch: 1, batch: 11930, loss: 0.32797, accu: 0.97896, speed: 0.86 step/s\n",
      "global step 11940, epoch: 1, batch: 11940, loss: 0.31327, accu: 0.97897, speed: 0.86 step/s\n",
      "global step 11950, epoch: 1, batch: 11950, loss: 0.33826, accu: 0.97898, speed: 0.86 step/s\n",
      "global step 11960, epoch: 1, batch: 11960, loss: 0.31328, accu: 0.97899, speed: 0.86 step/s\n",
      "global step 11970, epoch: 1, batch: 11970, loss: 0.31326, accu: 0.97899, speed: 0.86 step/s\n",
      "global step 11980, epoch: 1, batch: 11980, loss: 0.33826, accu: 0.97900, speed: 0.86 step/s\n",
      "global step 11990, epoch: 1, batch: 11990, loss: 0.36328, accu: 0.97900, speed: 0.86 step/s\n",
      "global step 12000, epoch: 1, batch: 12000, loss: 0.31932, accu: 0.97901, speed: 0.86 step/s\n",
      "global step 12010, epoch: 1, batch: 12010, loss: 0.33827, accu: 0.97902, speed: 0.86 step/s\n",
      "global step 12020, epoch: 1, batch: 12020, loss: 0.31334, accu: 0.97901, speed: 0.86 step/s\n",
      "global step 12030, epoch: 1, batch: 12030, loss: 0.36059, accu: 0.97901, speed: 0.86 step/s\n",
      "global step 12040, epoch: 1, batch: 12040, loss: 0.31869, accu: 0.97901, speed: 0.86 step/s\n",
      "global step 12050, epoch: 1, batch: 12050, loss: 0.33826, accu: 0.97901, speed: 0.86 step/s\n",
      "global step 12060, epoch: 1, batch: 12060, loss: 0.32571, accu: 0.97903, speed: 0.86 step/s\n",
      "global step 12070, epoch: 1, batch: 12070, loss: 0.31433, accu: 0.97904, speed: 0.86 step/s\n",
      "global step 12080, epoch: 1, batch: 12080, loss: 0.33826, accu: 0.97904, speed: 0.86 step/s\n",
      "global step 12090, epoch: 1, batch: 12090, loss: 0.31327, accu: 0.97906, speed: 0.86 step/s\n",
      "global step 12100, epoch: 1, batch: 12100, loss: 0.31326, accu: 0.97907, speed: 0.86 step/s\n",
      "global step 12110, epoch: 1, batch: 12110, loss: 0.31327, accu: 0.97908, speed: 0.86 step/s\n",
      "global step 12120, epoch: 1, batch: 12120, loss: 0.31326, accu: 0.97908, speed: 0.86 step/s\n",
      "global step 12130, epoch: 1, batch: 12130, loss: 0.31644, accu: 0.97909, speed: 0.86 step/s\n",
      "global step 12140, epoch: 1, batch: 12140, loss: 0.33827, accu: 0.97910, speed: 0.86 step/s\n",
      "global step 12150, epoch: 1, batch: 12150, loss: 0.33826, accu: 0.97910, speed: 0.87 step/s\n",
      "global step 12160, epoch: 1, batch: 12160, loss: 0.33826, accu: 0.97910, speed: 0.86 step/s\n",
      "global step 12170, epoch: 1, batch: 12170, loss: 0.31326, accu: 0.97910, speed: 0.86 step/s\n",
      "global step 12180, epoch: 1, batch: 12180, loss: 0.31326, accu: 0.97911, speed: 0.86 step/s\n",
      "global step 12190, epoch: 1, batch: 12190, loss: 0.31326, accu: 0.97911, speed: 0.87 step/s\n",
      "global step 12200, epoch: 1, batch: 12200, loss: 0.31326, accu: 0.97912, speed: 0.86 step/s\n",
      "global step 12210, epoch: 1, batch: 12210, loss: 0.31326, accu: 0.97913, speed: 0.87 step/s\n",
      "global step 12220, epoch: 1, batch: 12220, loss: 0.31326, accu: 0.97914, speed: 0.87 step/s\n",
      "global step 12230, epoch: 1, batch: 12230, loss: 0.33827, accu: 0.97915, speed: 0.86 step/s\n",
      "global step 12240, epoch: 1, batch: 12240, loss: 0.36327, accu: 0.97915, speed: 0.86 step/s\n",
      "global step 12250, epoch: 1, batch: 12250, loss: 0.33827, accu: 0.97916, speed: 0.86 step/s\n",
      "global step 12260, epoch: 1, batch: 12260, loss: 0.33757, accu: 0.97917, speed: 0.86 step/s\n",
      "global step 12270, epoch: 1, batch: 12270, loss: 0.31326, accu: 0.97918, speed: 0.86 step/s\n",
      "global step 12280, epoch: 1, batch: 12280, loss: 0.33827, accu: 0.97919, speed: 0.86 step/s\n",
      "global step 12290, epoch: 1, batch: 12290, loss: 0.31327, accu: 0.97920, speed: 0.86 step/s\n",
      "global step 12300, epoch: 1, batch: 12300, loss: 0.33823, accu: 0.97920, speed: 0.86 step/s\n",
      "global step 12310, epoch: 1, batch: 12310, loss: 0.33827, accu: 0.97921, speed: 0.86 step/s\n",
      "global step 12320, epoch: 1, batch: 12320, loss: 0.33826, accu: 0.97922, speed: 0.86 step/s\n",
      "global step 12330, epoch: 1, batch: 12330, loss: 0.33826, accu: 0.97923, speed: 0.86 step/s\n",
      "global step 12340, epoch: 1, batch: 12340, loss: 0.31326, accu: 0.97924, speed: 0.86 step/s\n",
      "global step 12350, epoch: 1, batch: 12350, loss: 0.31327, accu: 0.97925, speed: 0.86 step/s\n",
      "global step 12360, epoch: 1, batch: 12360, loss: 0.33826, accu: 0.97926, speed: 0.86 step/s\n",
      "global step 12370, epoch: 1, batch: 12370, loss: 0.31326, accu: 0.97927, speed: 0.86 step/s\n",
      "global step 12380, epoch: 1, batch: 12380, loss: 0.33826, accu: 0.97928, speed: 0.86 step/s\n",
      "global step 12390, epoch: 1, batch: 12390, loss: 0.31413, accu: 0.97929, speed: 0.86 step/s\n",
      "global step 12400, epoch: 1, batch: 12400, loss: 0.31327, accu: 0.97929, speed: 0.86 step/s\n",
      "global step 12410, epoch: 1, batch: 12410, loss: 0.31327, accu: 0.97930, speed: 0.86 step/s\n",
      "global step 12420, epoch: 1, batch: 12420, loss: 0.33826, accu: 0.97931, speed: 0.86 step/s\n",
      "global step 12430, epoch: 1, batch: 12430, loss: 0.31327, accu: 0.97932, speed: 0.86 step/s\n",
      "global step 12440, epoch: 1, batch: 12440, loss: 0.33825, accu: 0.97933, speed: 0.86 step/s\n",
      "global step 12450, epoch: 1, batch: 12450, loss: 0.31328, accu: 0.97934, speed: 0.86 step/s\n",
      "global step 12460, epoch: 1, batch: 12460, loss: 0.34109, accu: 0.97935, speed: 0.86 step/s\n",
      "global step 12470, epoch: 1, batch: 12470, loss: 0.31337, accu: 0.97935, speed: 0.86 step/s\n",
      "global step 12480, epoch: 1, batch: 12480, loss: 0.31333, accu: 0.97936, speed: 0.86 step/s\n",
      "global step 12490, epoch: 1, batch: 12490, loss: 0.33827, accu: 0.97937, speed: 0.86 step/s\n",
      "global step 12500, epoch: 1, batch: 12500, loss: 0.31345, accu: 0.97938, speed: 0.86 step/s\n",
      "global step 12510, epoch: 1, batch: 12510, loss: 0.31326, accu: 0.97938, speed: 0.86 step/s\n",
      "global step 12520, epoch: 1, batch: 12520, loss: 0.31326, accu: 0.97940, speed: 0.86 step/s\n",
      "global step 12530, epoch: 1, batch: 12530, loss: 0.31327, accu: 0.97940, speed: 0.86 step/s\n",
      "global step 12540, epoch: 1, batch: 12540, loss: 0.31327, accu: 0.97941, speed: 0.87 step/s\n",
      "global step 12550, epoch: 1, batch: 12550, loss: 0.31326, accu: 0.97942, speed: 0.86 step/s\n",
      "global step 12560, epoch: 1, batch: 12560, loss: 0.31327, accu: 0.97943, speed: 0.86 step/s\n",
      "global step 12570, epoch: 1, batch: 12570, loss: 0.31341, accu: 0.97944, speed: 0.86 step/s\n",
      "global step 12580, epoch: 1, batch: 12580, loss: 0.31327, accu: 0.97945, speed: 0.87 step/s\n",
      "global step 12590, epoch: 1, batch: 12590, loss: 0.31326, accu: 0.97946, speed: 0.86 step/s\n",
      "global step 12600, epoch: 1, batch: 12600, loss: 0.31326, accu: 0.97947, speed: 0.86 step/s\n",
      "global step 12610, epoch: 1, batch: 12610, loss: 0.33553, accu: 0.97948, speed: 0.86 step/s\n",
      "global step 12620, epoch: 1, batch: 12620, loss: 0.31326, accu: 0.97948, speed: 0.86 step/s\n",
      "global step 12630, epoch: 1, batch: 12630, loss: 0.31329, accu: 0.97950, speed: 0.87 step/s\n",
      "global step 12640, epoch: 1, batch: 12640, loss: 0.31326, accu: 0.97950, speed: 0.86 step/s\n",
      "global step 12650, epoch: 1, batch: 12650, loss: 0.31327, accu: 0.97951, speed: 0.87 step/s\n",
      "global step 12660, epoch: 1, batch: 12660, loss: 0.31327, accu: 0.97952, speed: 0.87 step/s\n",
      "global step 12670, epoch: 1, batch: 12670, loss: 0.31326, accu: 0.97953, speed: 0.86 step/s\n",
      "global step 12680, epoch: 1, batch: 12680, loss: 0.31392, accu: 0.97953, speed: 0.87 step/s\n",
      "global step 12690, epoch: 1, batch: 12690, loss: 0.33826, accu: 0.97954, speed: 0.86 step/s\n",
      "global step 12700, epoch: 1, batch: 12700, loss: 0.33389, accu: 0.97955, speed: 0.87 step/s\n",
      "global step 12710, epoch: 1, batch: 12710, loss: 0.31329, accu: 0.97956, speed: 0.87 step/s\n",
      "global step 12720, epoch: 1, batch: 12720, loss: 0.31327, accu: 0.97957, speed: 0.86 step/s\n",
      "global step 12730, epoch: 1, batch: 12730, loss: 0.31327, accu: 0.97958, speed: 0.87 step/s\n",
      "global step 12740, epoch: 1, batch: 12740, loss: 0.33827, accu: 0.97958, speed: 0.86 step/s\n",
      "global step 12750, epoch: 1, batch: 12750, loss: 0.31326, accu: 0.97959, speed: 0.86 step/s\n",
      "global step 12760, epoch: 1, batch: 12760, loss: 0.33828, accu: 0.97959, speed: 0.86 step/s\n",
      "global step 12770, epoch: 1, batch: 12770, loss: 0.31326, accu: 0.97959, speed: 0.86 step/s\n",
      "global step 12780, epoch: 1, batch: 12780, loss: 0.31328, accu: 0.97960, speed: 0.86 step/s\n",
      "global step 12790, epoch: 1, batch: 12790, loss: 0.31326, accu: 0.97961, speed: 0.86 step/s\n",
      "global step 12800, epoch: 1, batch: 12800, loss: 0.33826, accu: 0.97962, speed: 0.86 step/s\n",
      "global step 12810, epoch: 1, batch: 12810, loss: 0.33831, accu: 0.97963, speed: 0.86 step/s\n",
      "global step 12820, epoch: 1, batch: 12820, loss: 0.34181, accu: 0.97963, speed: 0.86 step/s\n",
      "global step 12830, epoch: 1, batch: 12830, loss: 0.31327, accu: 0.97964, speed: 0.86 step/s\n",
      "global step 12840, epoch: 1, batch: 12840, loss: 0.31327, accu: 0.97966, speed: 0.86 step/s\n",
      "global step 12850, epoch: 1, batch: 12850, loss: 0.36317, accu: 0.97965, speed: 0.87 step/s\n",
      "global step 12860, epoch: 1, batch: 12860, loss: 0.31334, accu: 0.97966, speed: 0.86 step/s\n",
      "global step 12870, epoch: 1, batch: 12870, loss: 0.31347, accu: 0.97967, speed: 0.87 step/s\n",
      "global step 12880, epoch: 1, batch: 12880, loss: 0.31326, accu: 0.97968, speed: 0.86 step/s\n",
      "global step 12890, epoch: 1, batch: 12890, loss: 0.31326, accu: 0.97969, speed: 0.87 step/s\n",
      "global step 12900, epoch: 1, batch: 12900, loss: 0.33833, accu: 0.97969, speed: 0.86 step/s\n",
      "global step 12910, epoch: 1, batch: 12910, loss: 0.31327, accu: 0.97971, speed: 0.86 step/s\n",
      "global step 12920, epoch: 1, batch: 12920, loss: 0.31327, accu: 0.97971, speed: 0.86 step/s\n",
      "global step 12930, epoch: 1, batch: 12930, loss: 0.31326, accu: 0.97972, speed: 0.86 step/s\n",
      "global step 12940, epoch: 1, batch: 12940, loss: 0.31326, accu: 0.97972, speed: 0.86 step/s\n",
      "global step 12950, epoch: 1, batch: 12950, loss: 0.31327, accu: 0.97973, speed: 0.86 step/s\n",
      "global step 12960, epoch: 1, batch: 12960, loss: 0.33826, accu: 0.97974, speed: 0.86 step/s\n",
      "global step 12970, epoch: 1, batch: 12970, loss: 0.31326, accu: 0.97975, speed: 0.86 step/s\n",
      "global step 12980, epoch: 1, batch: 12980, loss: 0.31327, accu: 0.97975, speed: 0.86 step/s\n",
      "global step 12990, epoch: 1, batch: 12990, loss: 0.31326, accu: 0.97976, speed: 0.86 step/s\n",
      "global step 13000, epoch: 1, batch: 13000, loss: 0.31328, accu: 0.97976, speed: 0.87 step/s\n",
      "global step 13010, epoch: 1, batch: 13010, loss: 0.31326, accu: 0.97977, speed: 0.86 step/s\n",
      "global step 13020, epoch: 1, batch: 13020, loss: 0.31328, accu: 0.97979, speed: 0.86 step/s\n",
      "global step 13030, epoch: 1, batch: 13030, loss: 0.31326, accu: 0.97979, speed: 0.86 step/s\n",
      "global step 13040, epoch: 1, batch: 13040, loss: 0.31327, accu: 0.97981, speed: 0.86 step/s\n",
      "global step 13050, epoch: 1, batch: 13050, loss: 0.31329, accu: 0.97982, speed: 0.87 step/s\n",
      "global step 13060, epoch: 1, batch: 13060, loss: 0.31326, accu: 0.97983, speed: 0.86 step/s\n",
      "global step 13070, epoch: 1, batch: 13070, loss: 0.33829, accu: 0.97984, speed: 0.87 step/s\n",
      "global step 13080, epoch: 1, batch: 13080, loss: 0.31326, accu: 0.97984, speed: 0.86 step/s\n",
      "global step 13090, epoch: 1, batch: 13090, loss: 0.31771, accu: 0.97986, speed: 0.86 step/s\n",
      "global step 13100, epoch: 1, batch: 13100, loss: 0.31326, accu: 0.97987, speed: 0.86 step/s\n",
      "global step 13110, epoch: 1, batch: 13110, loss: 0.33825, accu: 0.97988, speed: 0.87 step/s\n",
      "global step 13120, epoch: 1, batch: 13120, loss: 0.31326, accu: 0.97988, speed: 0.87 step/s\n",
      "global step 13130, epoch: 1, batch: 13130, loss: 0.31326, accu: 0.97990, speed: 0.87 step/s\n",
      "global step 13140, epoch: 1, batch: 13140, loss: 0.33772, accu: 0.97991, speed: 0.86 step/s\n",
      "global step 13150, epoch: 1, batch: 13150, loss: 0.31327, accu: 0.97992, speed: 0.87 step/s\n",
      "global step 13160, epoch: 1, batch: 13160, loss: 0.31330, accu: 0.97992, speed: 0.87 step/s\n",
      "global step 13170, epoch: 1, batch: 13170, loss: 0.31327, accu: 0.97993, speed: 0.86 step/s\n",
      "global step 13180, epoch: 1, batch: 13180, loss: 0.33826, accu: 0.97994, speed: 0.86 step/s\n",
      "global step 13190, epoch: 1, batch: 13190, loss: 0.31326, accu: 0.97995, speed: 0.86 step/s\n",
      "global step 13200, epoch: 1, batch: 13200, loss: 0.31331, accu: 0.97996, speed: 0.87 step/s\n",
      "global step 13210, epoch: 1, batch: 13210, loss: 0.31326, accu: 0.97997, speed: 0.87 step/s\n",
      "global step 13220, epoch: 1, batch: 13220, loss: 0.36326, accu: 0.97998, speed: 0.86 step/s\n",
      "global step 13230, epoch: 1, batch: 13230, loss: 0.31326, accu: 0.97998, speed: 0.86 step/s\n",
      "global step 13240, epoch: 1, batch: 13240, loss: 0.31326, accu: 0.97999, speed: 0.86 step/s\n",
      "global step 13250, epoch: 1, batch: 13250, loss: 0.31327, accu: 0.98000, speed: 0.86 step/s\n",
      "global step 13260, epoch: 1, batch: 13260, loss: 0.36326, accu: 0.98001, speed: 0.86 step/s\n",
      "global step 13270, epoch: 1, batch: 13270, loss: 0.31329, accu: 0.98002, speed: 0.86 step/s\n",
      "global step 13280, epoch: 1, batch: 13280, loss: 0.31326, accu: 0.98003, speed: 0.86 step/s\n",
      "global step 13290, epoch: 1, batch: 13290, loss: 0.31327, accu: 0.98004, speed: 0.87 step/s\n",
      "global step 13300, epoch: 1, batch: 13300, loss: 0.33607, accu: 0.98005, speed: 0.86 step/s\n",
      "global step 13310, epoch: 1, batch: 13310, loss: 0.31326, accu: 0.98006, speed: 0.86 step/s\n",
      "global step 13320, epoch: 1, batch: 13320, loss: 0.31326, accu: 0.98006, speed: 0.86 step/s\n",
      "global step 13330, epoch: 1, batch: 13330, loss: 0.33840, accu: 0.98007, speed: 0.87 step/s\n",
      "global step 13340, epoch: 1, batch: 13340, loss: 0.31326, accu: 0.98007, speed: 0.86 step/s\n",
      "global step 13350, epoch: 1, batch: 13350, loss: 0.36239, accu: 0.98008, speed: 0.87 step/s\n",
      "global step 13360, epoch: 1, batch: 13360, loss: 0.33826, accu: 0.98008, speed: 0.86 step/s\n",
      "global step 13370, epoch: 1, batch: 13370, loss: 0.31326, accu: 0.98009, speed: 0.87 step/s\n",
      "global step 13380, epoch: 1, batch: 13380, loss: 0.31326, accu: 0.98010, speed: 0.86 step/s\n",
      "global step 13390, epoch: 1, batch: 13390, loss: 0.36326, accu: 0.98011, speed: 0.86 step/s\n",
      "global step 13400, epoch: 1, batch: 13400, loss: 0.33827, accu: 0.98011, speed: 0.86 step/s\n",
      "global step 13410, epoch: 1, batch: 13410, loss: 0.31327, accu: 0.98012, speed: 0.86 step/s\n",
      "global step 13420, epoch: 1, batch: 13420, loss: 0.33826, accu: 0.98013, speed: 0.86 step/s\n",
      "global step 13430, epoch: 1, batch: 13430, loss: 0.31326, accu: 0.98014, speed: 0.86 step/s\n",
      "global step 13440, epoch: 1, batch: 13440, loss: 0.33826, accu: 0.98015, speed: 0.86 step/s\n",
      "global step 13450, epoch: 1, batch: 13450, loss: 0.31327, accu: 0.98016, speed: 0.86 step/s\n",
      "global step 13460, epoch: 1, batch: 13460, loss: 0.31327, accu: 0.98016, speed: 0.86 step/s\n",
      "global step 13470, epoch: 1, batch: 13470, loss: 0.33826, accu: 0.98017, speed: 0.87 step/s\n",
      "global step 13480, epoch: 1, batch: 13480, loss: 0.31327, accu: 0.98018, speed: 0.87 step/s\n",
      "global step 13490, epoch: 1, batch: 13490, loss: 0.33826, accu: 0.98018, speed: 0.87 step/s\n",
      "global step 13500, epoch: 1, batch: 13500, loss: 0.31327, accu: 0.98020, speed: 0.86 step/s\n",
      "global step 13510, epoch: 1, batch: 13510, loss: 0.31326, accu: 0.98020, speed: 0.86 step/s\n",
      "global step 13520, epoch: 1, batch: 13520, loss: 0.31327, accu: 0.98021, speed: 0.87 step/s\n",
      "global step 13530, epoch: 1, batch: 13530, loss: 0.31328, accu: 0.98021, speed: 0.86 step/s\n",
      "global step 13540, epoch: 1, batch: 13540, loss: 0.31329, accu: 0.98021, speed: 0.86 step/s\n",
      "global step 13550, epoch: 1, batch: 13550, loss: 0.31326, accu: 0.98023, speed: 0.87 step/s\n",
      "global step 13560, epoch: 1, batch: 13560, loss: 0.31355, accu: 0.98023, speed: 0.87 step/s\n",
      "global step 13570, epoch: 1, batch: 13570, loss: 0.33336, accu: 0.98024, speed: 0.86 step/s\n",
      "global step 13580, epoch: 1, batch: 13580, loss: 0.31326, accu: 0.98025, speed: 0.87 step/s\n",
      "global step 13590, epoch: 1, batch: 13590, loss: 0.31326, accu: 0.98025, speed: 0.87 step/s\n",
      "global step 13600, epoch: 1, batch: 13600, loss: 0.31327, accu: 0.98026, speed: 0.86 step/s\n",
      "global step 13610, epoch: 1, batch: 13610, loss: 0.31326, accu: 0.98027, speed: 0.87 step/s\n",
      "global step 13620, epoch: 1, batch: 13620, loss: 0.31326, accu: 0.98028, speed: 0.86 step/s\n",
      "global step 13630, epoch: 1, batch: 13630, loss: 0.33827, accu: 0.98029, speed: 0.86 step/s\n",
      "global step 13640, epoch: 1, batch: 13640, loss: 0.31326, accu: 0.98030, speed: 0.86 step/s\n",
      "global step 13650, epoch: 1, batch: 13650, loss: 0.31327, accu: 0.98031, speed: 0.87 step/s\n",
      "global step 13660, epoch: 1, batch: 13660, loss: 0.33832, accu: 0.98032, speed: 0.86 step/s\n",
      "global step 13670, epoch: 1, batch: 13670, loss: 0.31327, accu: 0.98033, speed: 0.87 step/s\n",
      "global step 13680, epoch: 1, batch: 13680, loss: 0.31327, accu: 0.98033, speed: 0.86 step/s\n",
      "global step 13690, epoch: 1, batch: 13690, loss: 0.31327, accu: 0.98034, speed: 0.86 step/s\n",
      "global step 13700, epoch: 1, batch: 13700, loss: 0.31329, accu: 0.98035, speed: 0.87 step/s\n",
      "global step 13710, epoch: 1, batch: 13710, loss: 0.31326, accu: 0.98036, speed: 0.86 step/s\n",
      "global step 13720, epoch: 1, batch: 13720, loss: 0.31326, accu: 0.98038, speed: 0.86 step/s\n",
      "global step 13730, epoch: 1, batch: 13730, loss: 0.31330, accu: 0.98039, speed: 0.86 step/s\n",
      "global step 13740, epoch: 1, batch: 13740, loss: 0.31332, accu: 0.98040, speed: 0.86 step/s\n",
      "global step 13750, epoch: 1, batch: 13750, loss: 0.31326, accu: 0.98041, speed: 0.87 step/s\n",
      "global step 13760, epoch: 1, batch: 13760, loss: 0.31327, accu: 0.98041, speed: 0.87 step/s\n",
      "global step 13770, epoch: 1, batch: 13770, loss: 0.31328, accu: 0.98042, speed: 0.86 step/s\n",
      "global step 13780, epoch: 1, batch: 13780, loss: 0.31350, accu: 0.98043, speed: 0.87 step/s\n",
      "global step 13790, epoch: 1, batch: 13790, loss: 0.31326, accu: 0.98044, speed: 0.87 step/s\n",
      "global step 13800, epoch: 1, batch: 13800, loss: 0.33812, accu: 0.98045, speed: 0.86 step/s\n",
      "global step 13810, epoch: 1, batch: 13810, loss: 0.31329, accu: 0.98046, speed: 0.87 step/s\n",
      "global step 13820, epoch: 1, batch: 13820, loss: 0.31326, accu: 0.98047, speed: 0.87 step/s\n",
      "global step 13830, epoch: 1, batch: 13830, loss: 0.31326, accu: 0.98048, speed: 0.86 step/s\n",
      "global step 13840, epoch: 1, batch: 13840, loss: 0.37833, accu: 0.98049, speed: 0.87 step/s\n",
      "global step 13850, epoch: 1, batch: 13850, loss: 0.33826, accu: 0.98050, speed: 0.87 step/s\n",
      "global step 13860, epoch: 1, batch: 13860, loss: 0.38317, accu: 0.98050, speed: 0.86 step/s\n",
      "global step 13870, epoch: 1, batch: 13870, loss: 0.33824, accu: 0.98050, speed: 0.87 step/s\n",
      "global step 13880, epoch: 1, batch: 13880, loss: 0.31326, accu: 0.98051, speed: 0.86 step/s\n",
      "global step 13890, epoch: 1, batch: 13890, loss: 0.31327, accu: 0.98052, speed: 0.87 step/s\n",
      "global step 13900, epoch: 1, batch: 13900, loss: 0.31327, accu: 0.98053, speed: 0.87 step/s\n",
      "global step 13910, epoch: 1, batch: 13910, loss: 0.31418, accu: 0.98054, speed: 0.87 step/s\n",
      "global step 13920, epoch: 1, batch: 13920, loss: 0.33826, accu: 0.98054, speed: 0.87 step/s\n",
      "global step 13930, epoch: 1, batch: 13930, loss: 0.31336, accu: 0.98056, speed: 0.86 step/s\n",
      "global step 13940, epoch: 1, batch: 13940, loss: 0.31330, accu: 0.98056, speed: 0.87 step/s\n",
      "global step 13950, epoch: 1, batch: 13950, loss: 0.31329, accu: 0.98057, speed: 0.87 step/s\n",
      "global step 13960, epoch: 1, batch: 13960, loss: 0.33826, accu: 0.98057, speed: 0.87 step/s\n",
      "global step 13970, epoch: 1, batch: 13970, loss: 0.36326, accu: 0.98058, speed: 0.86 step/s\n",
      "global step 13980, epoch: 1, batch: 13980, loss: 0.33826, accu: 0.98058, speed: 0.86 step/s\n",
      "global step 13990, epoch: 1, batch: 13990, loss: 0.31327, accu: 0.98060, speed: 0.87 step/s\n",
      "global step 14000, epoch: 1, batch: 14000, loss: 0.31327, accu: 0.98060, speed: 0.87 step/s\n",
      "global step 14010, epoch: 1, batch: 14010, loss: 0.31326, accu: 0.98061, speed: 0.87 step/s\n",
      "global step 14020, epoch: 1, batch: 14020, loss: 0.38829, accu: 0.98061, speed: 0.86 step/s\n",
      "global step 14030, epoch: 1, batch: 14030, loss: 0.31328, accu: 0.98061, speed: 0.87 step/s\n",
      "global step 14040, epoch: 1, batch: 14040, loss: 0.34434, accu: 0.98062, speed: 0.87 step/s\n",
      "global step 14050, epoch: 1, batch: 14050, loss: 0.31326, accu: 0.98063, speed: 0.87 step/s\n",
      "global step 14060, epoch: 1, batch: 14060, loss: 0.31326, accu: 0.98064, speed: 0.87 step/s\n",
      "global step 14070, epoch: 1, batch: 14070, loss: 0.31326, accu: 0.98064, speed: 0.87 step/s\n",
      "global step 14080, epoch: 1, batch: 14080, loss: 0.31326, accu: 0.98065, speed: 0.87 step/s\n",
      "global step 14090, epoch: 1, batch: 14090, loss: 0.33827, accu: 0.98065, speed: 0.87 step/s\n",
      "global step 14100, epoch: 1, batch: 14100, loss: 0.31326, accu: 0.98066, speed: 0.87 step/s\n",
      "global step 14110, epoch: 1, batch: 14110, loss: 0.31326, accu: 0.98066, speed: 0.87 step/s\n",
      "global step 14120, epoch: 1, batch: 14120, loss: 0.31333, accu: 0.98066, speed: 0.87 step/s\n",
      "global step 14130, epoch: 1, batch: 14130, loss: 0.31326, accu: 0.98067, speed: 0.87 step/s\n",
      "global step 14140, epoch: 1, batch: 14140, loss: 0.33827, accu: 0.98067, speed: 0.86 step/s\n",
      "global step 14150, epoch: 1, batch: 14150, loss: 0.33826, accu: 0.98068, speed: 0.86 step/s\n",
      "global step 14160, epoch: 1, batch: 14160, loss: 0.31326, accu: 0.98068, speed: 0.87 step/s\n",
      "global step 14170, epoch: 1, batch: 14170, loss: 0.31326, accu: 0.98069, speed: 0.87 step/s\n",
      "global step 14180, epoch: 1, batch: 14180, loss: 0.33826, accu: 0.98069, speed: 0.86 step/s\n",
      "global step 14190, epoch: 1, batch: 14190, loss: 0.31326, accu: 0.98070, speed: 0.86 step/s\n",
      "global step 14200, epoch: 1, batch: 14200, loss: 0.33822, accu: 0.98071, speed: 0.86 step/s\n",
      "global step 14210, epoch: 1, batch: 14210, loss: 0.31328, accu: 0.98072, speed: 0.87 step/s\n",
      "global step 14220, epoch: 1, batch: 14220, loss: 0.31376, accu: 0.98073, speed: 0.87 step/s\n",
      "global step 14230, epoch: 1, batch: 14230, loss: 0.31326, accu: 0.98075, speed: 0.87 step/s\n",
      "global step 14240, epoch: 1, batch: 14240, loss: 0.31327, accu: 0.98076, speed: 0.86 step/s\n",
      "global step 14250, epoch: 1, batch: 14250, loss: 0.33879, accu: 0.98077, speed: 0.87 step/s\n",
      "global step 14260, epoch: 1, batch: 14260, loss: 0.31327, accu: 0.98077, speed: 0.87 step/s\n",
      "global step 14270, epoch: 1, batch: 14270, loss: 0.33829, accu: 0.98078, speed: 0.87 step/s\n",
      "global step 14280, epoch: 1, batch: 14280, loss: 0.31358, accu: 0.98079, speed: 0.86 step/s\n",
      "global step 14290, epoch: 1, batch: 14290, loss: 0.31326, accu: 0.98079, speed: 0.86 step/s\n",
      "global step 14300, epoch: 1, batch: 14300, loss: 0.31326, accu: 0.98081, speed: 0.86 step/s\n",
      "global step 14310, epoch: 1, batch: 14310, loss: 0.31327, accu: 0.98081, speed: 0.86 step/s\n",
      "global step 14320, epoch: 1, batch: 14320, loss: 0.31326, accu: 0.98082, speed: 0.87 step/s\n",
      "global step 14330, epoch: 1, batch: 14330, loss: 0.36331, accu: 0.98083, speed: 0.86 step/s\n",
      "global step 14340, epoch: 1, batch: 14340, loss: 0.33812, accu: 0.98083, speed: 0.87 step/s\n",
      "global step 14350, epoch: 1, batch: 14350, loss: 0.31326, accu: 0.98084, speed: 0.87 step/s\n",
      "global step 14360, epoch: 1, batch: 14360, loss: 0.31327, accu: 0.98085, speed: 0.87 step/s\n",
      "global step 14370, epoch: 1, batch: 14370, loss: 0.31329, accu: 0.98086, speed: 0.86 step/s\n",
      "global step 14380, epoch: 1, batch: 14380, loss: 0.38826, accu: 0.98086, speed: 0.87 step/s\n",
      "global step 14390, epoch: 1, batch: 14390, loss: 0.31326, accu: 0.98087, speed: 0.87 step/s\n",
      "global step 14400, epoch: 1, batch: 14400, loss: 0.31326, accu: 0.98088, speed: 0.87 step/s\n",
      "global step 14410, epoch: 1, batch: 14410, loss: 0.31327, accu: 0.98089, speed: 0.87 step/s\n",
      "global step 14420, epoch: 1, batch: 14420, loss: 0.36326, accu: 0.98089, speed: 0.86 step/s\n",
      "global step 14430, epoch: 1, batch: 14430, loss: 0.33826, accu: 0.98090, speed: 0.87 step/s\n",
      "global step 14440, epoch: 1, batch: 14440, loss: 0.31326, accu: 0.98091, speed: 0.86 step/s\n",
      "global step 14450, epoch: 1, batch: 14450, loss: 0.31332, accu: 0.98092, speed: 0.87 step/s\n",
      "global step 14460, epoch: 1, batch: 14460, loss: 0.32020, accu: 0.98093, speed: 0.86 step/s\n",
      "global step 14470, epoch: 1, batch: 14470, loss: 0.31359, accu: 0.98094, speed: 0.87 step/s\n",
      "global step 14480, epoch: 1, batch: 14480, loss: 0.31327, accu: 0.98095, speed: 0.87 step/s\n",
      "global step 14490, epoch: 1, batch: 14490, loss: 0.33826, accu: 0.98096, speed: 0.86 step/s\n",
      "global step 14500, epoch: 1, batch: 14500, loss: 0.33827, accu: 0.98096, speed: 0.87 step/s\n",
      "global step 14510, epoch: 1, batch: 14510, loss: 0.31326, accu: 0.98097, speed: 0.86 step/s\n",
      "global step 14520, epoch: 1, batch: 14520, loss: 0.31326, accu: 0.98097, speed: 0.87 step/s\n",
      "global step 14530, epoch: 1, batch: 14530, loss: 0.31326, accu: 0.98099, speed: 0.86 step/s\n",
      "global step 14540, epoch: 1, batch: 14540, loss: 0.31326, accu: 0.98100, speed: 0.86 step/s\n",
      "global step 14550, epoch: 1, batch: 14550, loss: 0.31329, accu: 0.98101, speed: 0.86 step/s\n",
      "global step 14560, epoch: 1, batch: 14560, loss: 0.31326, accu: 0.98101, speed: 0.87 step/s\n",
      "global step 14570, epoch: 1, batch: 14570, loss: 0.31326, accu: 0.98102, speed: 0.87 step/s\n",
      "global step 14580, epoch: 1, batch: 14580, loss: 0.33827, accu: 0.98103, speed: 0.87 step/s\n",
      "global step 14590, epoch: 1, batch: 14590, loss: 0.33831, accu: 0.98103, speed: 0.86 step/s\n",
      "global step 14600, epoch: 1, batch: 14600, loss: 0.31327, accu: 0.98104, speed: 0.86 step/s\n",
      "global step 14610, epoch: 1, batch: 14610, loss: 0.31327, accu: 0.98104, speed: 0.87 step/s\n",
      "global step 14620, epoch: 1, batch: 14620, loss: 0.33826, accu: 0.98104, speed: 0.87 step/s\n",
      "global step 14630, epoch: 1, batch: 14630, loss: 0.33827, accu: 0.98104, speed: 0.86 step/s\n",
      "global step 14640, epoch: 1, batch: 14640, loss: 0.31326, accu: 0.98105, speed: 0.87 step/s\n",
      "global step 14650, epoch: 1, batch: 14650, loss: 0.33826, accu: 0.98105, speed: 0.87 step/s\n",
      "global step 14660, epoch: 1, batch: 14660, loss: 0.31329, accu: 0.98106, speed: 0.87 step/s\n",
      "global step 14670, epoch: 1, batch: 14670, loss: 0.31326, accu: 0.98107, speed: 0.86 step/s\n",
      "global step 14680, epoch: 1, batch: 14680, loss: 0.31326, accu: 0.98107, speed: 0.86 step/s\n",
      "global step 14690, epoch: 1, batch: 14690, loss: 0.31326, accu: 0.98107, speed: 0.87 step/s\n",
      "global step 14700, epoch: 1, batch: 14700, loss: 0.31328, accu: 0.98108, speed: 0.86 step/s\n",
      "global step 14710, epoch: 1, batch: 14710, loss: 0.33826, accu: 0.98108, speed: 0.86 step/s\n",
      "global step 14720, epoch: 1, batch: 14720, loss: 0.31326, accu: 0.98109, speed: 0.86 step/s\n",
      "global step 14730, epoch: 1, batch: 14730, loss: 0.31327, accu: 0.98110, speed: 0.87 step/s\n",
      "global step 14740, epoch: 1, batch: 14740, loss: 0.33826, accu: 0.98111, speed: 0.86 step/s\n",
      "global step 14750, epoch: 1, batch: 14750, loss: 0.31367, accu: 0.98112, speed: 0.86 step/s\n",
      "global step 14760, epoch: 1, batch: 14760, loss: 0.31326, accu: 0.98111, speed: 0.86 step/s\n",
      "global step 14770, epoch: 1, batch: 14770, loss: 0.31327, accu: 0.98112, speed: 0.87 step/s\n",
      "global step 14780, epoch: 1, batch: 14780, loss: 0.33503, accu: 0.98112, speed: 0.87 step/s\n",
      "global step 14790, epoch: 1, batch: 14790, loss: 0.31327, accu: 0.98113, speed: 0.86 step/s\n",
      "global step 14800, epoch: 1, batch: 14800, loss: 0.31326, accu: 0.98114, speed: 0.86 step/s\n",
      "global step 14810, epoch: 1, batch: 14810, loss: 0.31326, accu: 0.98114, speed: 0.87 step/s\n",
      "global step 14820, epoch: 1, batch: 14820, loss: 0.31401, accu: 0.98115, speed: 0.86 step/s\n",
      "global step 14830, epoch: 1, batch: 14830, loss: 0.31328, accu: 0.98116, speed: 0.87 step/s\n",
      "global step 14840, epoch: 1, batch: 14840, loss: 0.33826, accu: 0.98117, speed: 0.87 step/s\n",
      "global step 14850, epoch: 1, batch: 14850, loss: 0.33827, accu: 0.98117, speed: 0.87 step/s\n",
      "global step 14860, epoch: 1, batch: 14860, loss: 0.31326, accu: 0.98118, speed: 0.86 step/s\n",
      "global step 14870, epoch: 1, batch: 14870, loss: 0.33824, accu: 0.98119, speed: 0.87 step/s\n",
      "global step 14880, epoch: 1, batch: 14880, loss: 0.31334, accu: 0.98120, speed: 0.86 step/s\n",
      "global step 14890, epoch: 1, batch: 14890, loss: 0.31631, accu: 0.98121, speed: 0.87 step/s\n",
      "global step 14900, epoch: 1, batch: 14900, loss: 0.31326, accu: 0.98122, speed: 0.86 step/s\n",
      "global step 14910, epoch: 1, batch: 14910, loss: 0.31327, accu: 0.98123, speed: 0.86 step/s\n",
      "global step 14920, epoch: 1, batch: 14920, loss: 0.34311, accu: 0.98124, speed: 0.87 step/s\n",
      "global step 14930, epoch: 1, batch: 14930, loss: 0.31327, accu: 0.98124, speed: 0.87 step/s\n",
      "global step 14940, epoch: 1, batch: 14940, loss: 0.31375, accu: 0.98125, speed: 0.86 step/s\n",
      "global step 14950, epoch: 1, batch: 14950, loss: 0.33836, accu: 0.98126, speed: 0.87 step/s\n",
      "global step 14960, epoch: 1, batch: 14960, loss: 0.31326, accu: 0.98127, speed: 0.86 step/s\n",
      "global step 14970, epoch: 1, batch: 14970, loss: 0.31326, accu: 0.98128, speed: 0.87 step/s\n",
      "global step 14980, epoch: 1, batch: 14980, loss: 0.31326, accu: 0.98129, speed: 0.86 step/s\n",
      "global step 14990, epoch: 1, batch: 14990, loss: 0.31326, accu: 0.98129, speed: 0.86 step/s\n",
      "global step 15000, epoch: 1, batch: 15000, loss: 0.31327, accu: 0.98130, speed: 0.87 step/s\n",
      "global step 15010, epoch: 1, batch: 15010, loss: 0.31326, accu: 0.98131, speed: 0.87 step/s\n",
      "global step 15020, epoch: 1, batch: 15020, loss: 0.33687, accu: 0.98131, speed: 0.86 step/s\n",
      "global step 15030, epoch: 1, batch: 15030, loss: 0.31327, accu: 0.98132, speed: 0.87 step/s\n",
      "global step 15040, epoch: 1, batch: 15040, loss: 0.33826, accu: 0.98133, speed: 0.87 step/s\n",
      "global step 15050, epoch: 1, batch: 15050, loss: 0.31327, accu: 0.98133, speed: 0.87 step/s\n",
      "global step 15060, epoch: 1, batch: 15060, loss: 0.33826, accu: 0.98133, speed: 0.87 step/s\n",
      "global step 15070, epoch: 1, batch: 15070, loss: 0.31326, accu: 0.98134, speed: 0.87 step/s\n",
      "global step 15080, epoch: 1, batch: 15080, loss: 0.31326, accu: 0.98134, speed: 0.86 step/s\n",
      "global step 15090, epoch: 1, batch: 15090, loss: 0.31334, accu: 0.98135, speed: 0.86 step/s\n",
      "global step 15100, epoch: 1, batch: 15100, loss: 0.31338, accu: 0.98136, speed: 0.87 step/s\n",
      "global step 15110, epoch: 1, batch: 15110, loss: 0.31327, accu: 0.98137, speed: 0.87 step/s\n",
      "global step 15120, epoch: 1, batch: 15120, loss: 0.31326, accu: 0.98138, speed: 0.86 step/s\n",
      "global step 15130, epoch: 1, batch: 15130, loss: 0.31333, accu: 0.98139, speed: 0.87 step/s\n",
      "global step 15140, epoch: 1, batch: 15140, loss: 0.31329, accu: 0.98139, speed: 0.86 step/s\n",
      "global step 15150, epoch: 1, batch: 15150, loss: 0.33826, accu: 0.98140, speed: 0.87 step/s\n",
      "global step 15160, epoch: 1, batch: 15160, loss: 0.33826, accu: 0.98140, speed: 0.86 step/s\n",
      "global step 15170, epoch: 1, batch: 15170, loss: 0.31394, accu: 0.98141, speed: 0.86 step/s\n",
      "global step 15180, epoch: 1, batch: 15180, loss: 0.31327, accu: 0.98141, speed: 0.87 step/s\n",
      "global step 15190, epoch: 1, batch: 15190, loss: 0.31326, accu: 0.98142, speed: 0.87 step/s\n",
      "global step 15200, epoch: 1, batch: 15200, loss: 0.31326, accu: 0.98143, speed: 0.87 step/s\n",
      "global step 15210, epoch: 1, batch: 15210, loss: 0.31326, accu: 0.98144, speed: 0.86 step/s\n",
      "global step 15220, epoch: 1, batch: 15220, loss: 0.33826, accu: 0.98144, speed: 0.87 step/s\n",
      "global step 15230, epoch: 1, batch: 15230, loss: 0.33826, accu: 0.98145, speed: 0.87 step/s\n",
      "global step 15240, epoch: 1, batch: 15240, loss: 0.31326, accu: 0.98145, speed: 0.87 step/s\n",
      "global step 15250, epoch: 1, batch: 15250, loss: 0.31326, accu: 0.98145, speed: 0.87 step/s\n",
      "global step 15260, epoch: 1, batch: 15260, loss: 0.33827, accu: 0.98146, speed: 0.86 step/s\n",
      "global step 15270, epoch: 1, batch: 15270, loss: 0.31326, accu: 0.98147, speed: 0.86 step/s\n",
      "global step 15280, epoch: 1, batch: 15280, loss: 0.38145, accu: 0.98147, speed: 0.87 step/s\n",
      "global step 15290, epoch: 1, batch: 15290, loss: 0.32273, accu: 0.98147, speed: 0.87 step/s\n",
      "global step 15300, epoch: 1, batch: 15300, loss: 0.31326, accu: 0.98148, speed: 0.87 step/s\n",
      "global step 15310, epoch: 1, batch: 15310, loss: 0.33826, accu: 0.98149, speed: 0.86 step/s\n",
      "global step 15320, epoch: 1, batch: 15320, loss: 0.31327, accu: 0.98149, speed: 0.87 step/s\n",
      "global step 15330, epoch: 1, batch: 15330, loss: 0.31327, accu: 0.98150, speed: 0.87 step/s\n",
      "global step 15340, epoch: 1, batch: 15340, loss: 0.31326, accu: 0.98151, speed: 0.87 step/s\n",
      "global step 15350, epoch: 1, batch: 15350, loss: 0.31329, accu: 0.98152, speed: 0.86 step/s\n",
      "global step 15360, epoch: 1, batch: 15360, loss: 0.33827, accu: 0.98153, speed: 0.87 step/s\n",
      "global step 15370, epoch: 1, batch: 15370, loss: 0.31326, accu: 0.98153, speed: 0.87 step/s\n",
      "global step 15380, epoch: 1, batch: 15380, loss: 0.31371, accu: 0.98154, speed: 0.86 step/s\n",
      "global step 15390, epoch: 1, batch: 15390, loss: 0.31327, accu: 0.98154, speed: 0.87 step/s\n",
      "global step 15400, epoch: 1, batch: 15400, loss: 0.31327, accu: 0.98155, speed: 0.86 step/s\n",
      "global step 15410, epoch: 1, batch: 15410, loss: 0.31326, accu: 0.98155, speed: 0.86 step/s\n",
      "global step 15420, epoch: 1, batch: 15420, loss: 0.31327, accu: 0.98156, speed: 0.86 step/s\n",
      "global step 15430, epoch: 1, batch: 15430, loss: 0.31326, accu: 0.98156, speed: 0.87 step/s\n",
      "global step 15440, epoch: 1, batch: 15440, loss: 0.36326, accu: 0.98157, speed: 0.86 step/s\n",
      "global step 15450, epoch: 1, batch: 15450, loss: 0.33827, accu: 0.98158, speed: 0.86 step/s\n",
      "global step 15460, epoch: 1, batch: 15460, loss: 0.31327, accu: 0.98158, speed: 0.87 step/s\n",
      "global step 15470, epoch: 1, batch: 15470, loss: 0.33826, accu: 0.98158, speed: 0.86 step/s\n",
      "global step 15480, epoch: 1, batch: 15480, loss: 0.31326, accu: 0.98159, speed: 0.86 step/s\n",
      "global step 15490, epoch: 1, batch: 15490, loss: 0.31712, accu: 0.98160, speed: 0.86 step/s\n",
      "CPU times: user 4h 55min 55s, sys: 1h 24min 57s, total: 6h 20min 53s\n",
      "Wall time: 4h 59min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# 接下来，开始正式训练模型，训练时间较长，可注释掉这部分\n",
    "global_step = 0\n",
    "tic_train = time.time()\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    for step, batch in enumerate(train_data_loader, start=1):\n",
    "        # print(step)\n",
    "        input_ids, token_type_ids, labels = batch\n",
    "        probs = model(input_ids=input_ids, token_type_ids=token_type_ids)\n",
    "        loss = criterion(probs, labels)\n",
    "        correct = metric.compute(probs, labels)\n",
    "        metric.update(correct)\n",
    "        acc = metric.accumulate()\n",
    "\n",
    "        global_step += 1\n",
    "        \n",
    "        # 每间隔 10 step 输出训练指标\n",
    "        if global_step % 10 == 0:\n",
    "            print(\"global step %d, epoch: %d, batch: %d, loss: %.5f, accu: %.5f, speed: %.2f step/s\"\n",
    "                % (global_step, epoch, step, loss, acc, 10 / (time.time() - tic_train)))\n",
    "            tic_train = time.time()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.clear_grad()\n",
    "\n",
    "        # 每间隔 100 step 在验证集和测试集上进行评估\n",
    "        if EVAL:\n",
    "            if global_step % EVAL_STEP == 0:\n",
    "                evaluate(model, criterion, metric, dev_data_loader, \"dev\")\n",
    "            \n",
    "# 训练结束后，存储模型参数\n",
    "save_dir = os.path.join(\"checkpoint\", \"model_%d\" % global_step)\n",
    "os.makedirs(save_dir)\n",
    "\n",
    "save_param_path = os.path.join(save_dir, 'model_state.pdparams')\n",
    "paddle.save(model.state_dict(), save_param_path)\n",
    "tokenizer.save_pretrained(save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "基于默认参数配置进行单卡训练大概要持续 4 个小时左右，会训练完成 3 个 Epoch, 模型最终的收敛指标结果如下:\n",
    "\n",
    "\n",
    "| 数据集 | Accuracy |\n",
    "| -------- | -------- |\n",
    "| dev.tsv     | 89.62  |\n",
    "\n",
    "可以看到: 我们基于 PaddleNLP ，利用 ERNIE-Gram 预训练模型使用非常简洁的代码，就在权威语义匹配数据集上取得了很不错的效果."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 模型预测\n",
    "\n",
    "接下来我们使用已经训练好的语义匹配模型对一些预测数据进行预测。待预测数据为每行都是文本对的 tsv 文件，我们使用 Lcqmc 数据集的测试集作为我们的预测数据，进行预测并提交预测结果到 [千言文本相似度竞赛](https://aistudio.baidu.com/aistudio/competition/detail/45)\n",
    "\n",
    "下载我们已经训练好的语义匹配模型, 并解压"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 定义预测函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2021-11-23T21:34:41.009373Z",
     "iopub.status.busy": "2021-11-23T21:34:41.008908Z",
     "iopub.status.idle": "2021-11-23T21:34:41.014316Z",
     "shell.execute_reply": "2021-11-23T21:34:41.013793Z",
     "shell.execute_reply.started": "2021-11-23T21:34:41.009345Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def predict(model, data_loader):\n",
    "    batch_probs = []\n",
    "\n",
    "    # 预测阶段打开 eval 模式，模型中的 dropout 等操作会关掉\n",
    "    model.eval()\n",
    "    n_len = len(data_loader)\n",
    "    with paddle.no_grad():\n",
    "        for idx, batch_data in enumerate(data_loader):\n",
    "            input_ids, token_type_ids = batch_data\n",
    "            input_ids = paddle.to_tensor(input_ids)\n",
    "            token_type_ids = paddle.to_tensor(token_type_ids)\n",
    "            \n",
    "            # 获取每个样本的预测概率: [BATCH_SIZE, 2] 的矩阵\n",
    "            batch_prob = model(input_ids=input_ids, token_type_ids=token_type_ids).numpy()\n",
    "            batch_probs.append(batch_prob)\n",
    "            print(f'\\r{idx+1}/{n_len}', end='')\n",
    "            \n",
    "        batch_probs = np.concatenate(batch_probs, axis=0)\n",
    "        return batch_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 定义预测数据的 data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2021-11-23T21:34:41.015532Z",
     "iopub.status.busy": "2021-11-23T21:34:41.015108Z",
     "iopub.status.idle": "2021-11-23T21:34:41.019494Z",
     "shell.execute_reply": "2021-11-23T21:34:41.018891Z",
     "shell.execute_reply.started": "2021-11-23T21:34:41.015509Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# 预测数据的转换函数\n",
    "# predict 数据没有 label, 因此 convert_exmaple 的 is_test 参数设为 True\n",
    "trans_func = partial(convert_example, tokenizer=tokenizer, max_seq_length=MAX_SEQ_LENGTH, is_test=True)\n",
    "\n",
    "# 预测数据的组 batch 操作\n",
    "# predict 数据只返回 input_ids 和 token_type_ids，因此只需要 2 个 Pad 对象作为 batchify_fn\n",
    "batchify_fn = lambda samples, fn=Tuple(\n",
    "    Pad(axis=0, pad_val=tokenizer.pad_token_id),  # input_ids\n",
    "    Pad(axis=0, pad_val=tokenizer.pad_token_type_id),  # segment_ids\n",
    "): [data for data in fn(samples)]\n",
    "\n",
    "# 加载预测数据\n",
    "# test_ds = load_dataset(\"lcqmc\", splits=[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-23T21:34:41.020459Z",
     "iopub.status.busy": "2021-11-23T21:34:41.020199Z",
     "iopub.status.idle": "2021-11-23T21:34:57.376624Z",
     "shell.execute_reply": "2021-11-23T21:34:57.376085Z",
     "shell.execute_reply.started": "2021-11-23T21:34:41.020438Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "176820"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read(data_path):\n",
    "    for idx, row in data_path.iterrows():\n",
    "        yield {'query': row.Test_text, 'title': row.Reference_text, 'label': ''}\n",
    "\n",
    "\n",
    "# data_path为read()方法的参数\n",
    "test_df = pd.read_csv(f'data/data117130/{TEST_CSV}')\n",
    "test_ds = load_dataset(read, data_path=test_df, lazy=False)\n",
    "\n",
    "len(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2021-11-23T21:34:57.377849Z",
     "iopub.status.busy": "2021-11-23T21:34:57.377632Z",
     "iopub.status.idle": "2021-11-23T21:34:57.381579Z",
     "shell.execute_reply": "2021-11-23T21:34:57.381125Z",
     "shell.execute_reply.started": "2021-11-23T21:34:57.377817Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "batch_sampler = paddle.io.BatchSampler(test_ds, batch_size=512, shuffle=False) # batch_size=32\n",
    "\n",
    "# 生成预测数据 data_loader\n",
    "predict_data_loader = paddle.io.DataLoader(\n",
    "        dataset=test_ds.map(trans_func),\n",
    "        batch_sampler=batch_sampler,\n",
    "        collate_fn=batchify_fn,\n",
    "        return_list=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 开始预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-23T21:34:57.382745Z",
     "iopub.status.busy": "2021-11-23T21:34:57.382322Z",
     "iopub.status.idle": "2021-11-23T22:18:40.566459Z",
     "shell.execute_reply": "2021-11-23T22:18:40.565646Z",
     "shell.execute_reply.started": "2021-11-23T21:34:57.382723Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346/346CPU times: user 39min 28s, sys: 4min 35s, total: 44min 3s\n",
      "Wall time: 43min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# 执行预测函数\n",
    "y_probs = predict(model, predict_data_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 输出预测结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-23T22:18:40.567803Z",
     "iopub.status.busy": "2021-11-23T22:18:40.567604Z",
     "iopub.status.idle": "2021-11-23T22:18:40.590710Z",
     "shell.execute_reply": "2021-11-23T22:18:40.590065Z",
     "shell.execute_reply.started": "2021-11-23T22:18:40.567778Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2098\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test</th>\n",
       "      <th>Reference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>1053</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708</th>\n",
       "      <td>1084</td>\n",
       "      <td>1014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>1084</td>\n",
       "      <td>345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>825</th>\n",
       "      <td>1084</td>\n",
       "      <td>440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>538</td>\n",
       "      <td>1091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Test  Reference\n",
       "295  1053         52\n",
       "708  1084       1014\n",
       "720  1084        345\n",
       "825  1084        440\n",
       "866   538       1091"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Threshold = 0\n",
    "# Threshold = 0.5\n",
    "\n",
    "y_probs_new = y_probs.copy()\n",
    "# for idx, i in enumerate(y_probs_new[:, 1]):\n",
    "#     if i > Threshold:\n",
    "#         pass\n",
    "#     else:\n",
    "#         y_probs_new[idx, 1] = 0\n",
    "\n",
    "# 根据预测概率获取预测 label\n",
    "y_probs_new = np.argmax(y_probs_new, axis=1)\n",
    "\n",
    "df_submission = pd.DataFrame({\"Test\": test_df.Test.values,\n",
    "                              \"Reference\": test_df.Reference.values,\n",
    "#                               \"Test_text\": test_df.Test_text.values,\n",
    "#                               \"Reference_text\": test_df.Reference_text.values,\n",
    "                              \"sentiment\": y_probs_new})\n",
    "\n",
    "df_submission = df_submission[df_submission.sentiment == 1]\n",
    "df_submission = df_submission.drop(['sentiment'], axis=1)\n",
    "df_submission.to_csv(\"submission.csv\", index=False)\n",
    "\n",
    "print(len(df_submission))\n",
    "df_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
